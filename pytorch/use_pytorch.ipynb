{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "加载最优模型\n",
      "inference测试集\n",
      "生成测试集评估文件\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "\n",
    "\n",
    "\n",
    "class GlobalAvgPool2d(nn.Module):\n",
    "    \"\"\"\n",
    "    全局平均池化层\n",
    "    可通过将普通的平均池化的窗口形状设置成输入的高和宽实现\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        super(GlobalAvgPool2d, self).__init__()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return F.avg_pool2d(x, kernel_size=x.size()[2:])\n",
    "\n",
    "\n",
    "class FlattenLayer(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(FlattenLayer, self).__init__()\n",
    "\n",
    "    def forward(self, x):  # x shape: (batch, *, *, ...)\n",
    "        return x.view(x.shape[0], -1)\n",
    "\n",
    "\n",
    "class Residual(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, use_1x1conv=False, stride=1):\n",
    "        \"\"\"\n",
    "            use_1×1conv: 是否使用额外的1x1卷积层来修改通道数\n",
    "            stride: 卷积层的步幅, resnet使用步长为2的卷积来替代pooling的作用，是个很赞的idea\n",
    "        \"\"\"\n",
    "        super(Residual, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1, stride=stride)\n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1)\n",
    "        if use_1x1conv:\n",
    "            self.conv3 = nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=stride)\n",
    "        else:\n",
    "            self.conv3 = None\n",
    "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "\n",
    "    def forward(self, X):\n",
    "        Y = F.relu(self.bn1(self.conv1(X)))\n",
    "        Y = self.bn2(self.conv2(Y))\n",
    "        if self.conv3:\n",
    "            X = self.conv3(X)\n",
    "        return F.relu(Y + X)\n",
    "\n",
    "\n",
    "def resnet_block(in_channels, out_channels, num_residuals, first_block=False):\n",
    "    '''\n",
    "    resnet block\n",
    "    num_residuals: 当前block包含多少个残差块\n",
    "    first_block: 是否为第一个block\n",
    "    一个resnet block由num_residuals个残差块组成\n",
    "    其中第一个残差块起到了通道数的转换和pooling的作用\n",
    "    后面的若干残差块就是完成正常的特征提取\n",
    "    '''\n",
    "    if first_block:\n",
    "        assert in_channels == out_channels  # 第一个模块的输出通道数同输入通道数一致\n",
    "    blk = []\n",
    "    for i in range(num_residuals):\n",
    "        if i == 0 and not first_block:\n",
    "            blk.append(Residual(in_channels, out_channels, use_1x1conv=True, stride=2))\n",
    "        else:\n",
    "            blk.append(Residual(out_channels, out_channels))\n",
    "    return nn.Sequential(*blk)\n",
    "\n",
    "\n",
    "# 定义resnet模型结构\n",
    "net = nn.Sequential(\n",
    "    nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1),  # TODO: 缩小感受野, 缩channel\n",
    "    nn.BatchNorm2d(32),\n",
    "    nn.ReLU())\n",
    "# nn.ReLU(),\n",
    "# nn.MaxPool2d(kernel_size=2, stride=2))   # TODO：去掉maxpool缩小感受野\n",
    "\n",
    "# 然后是连续4个block\n",
    "net.add_module(\"resnet_block1\", resnet_block(32, 32, 2, first_block=True))  # TODO: channel统一减半\n",
    "net.add_module(\"resnet_block2\", resnet_block(32, 64, 2))\n",
    "net.add_module(\"resnet_block3\", resnet_block(64, 128, 2))\n",
    "net.add_module(\"resnet_block4\", resnet_block(128, 256, 2))\n",
    "# global average pooling\n",
    "net.add_module(\"global_avg_pool\", GlobalAvgPool2d())\n",
    "# fc layer\n",
    "net.add_module(\"fc\", nn.Sequential(FlattenLayer(), nn.Linear(256, 10)))\n",
    "\n",
    "\n",
    "def load_data_fashion_mnist(batch_size, root='../data'):\n",
    "    \"\"\"Download the fashion mnist dataset and then load into memory.\"\"\"\n",
    "\n",
    "    normalize = transforms.Normalize(mean=[0.28], std=[0.35])\n",
    "    train_augs = transforms.Compose([\n",
    "        transforms.RandomCrop(28, padding=2),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        normalize\n",
    "    ])\n",
    "\n",
    "    test_augs = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        normalize\n",
    "    ])\n",
    "\n",
    "    mnist_train = torchvision.datasets.FashionMNIST(root=root, train=True, download=True, transform=train_augs)\n",
    "    mnist_test = torchvision.datasets.FashionMNIST(root=root, train=False, download=True, transform=test_augs)\n",
    "    if sys.platform.startswith('win'):\n",
    "        num_workers = 0  # 0表示不用额外的进程来加速读取数据\n",
    "    else:\n",
    "        num_workers = 4\n",
    "    train_iter = torch.utils.data.DataLoader(mnist_train, batch_size=batch_size, shuffle=True, num_workers=num_workers)\n",
    "    test_iter = torch.utils.data.DataLoader(mnist_test, batch_size=batch_size, shuffle=False, num_workers=num_workers)\n",
    "\n",
    "    return train_iter, test_iter\n",
    "\n",
    "batch_size = 1\n",
    "train_iter, test_iter = load_data_fashion_mnist(batch_size, root='/root/.pytorch/F_MNIST_data')\n",
    "lr, num_epochs, lr_period, lr_decay = 0.01, 50, 5, 0.1\n",
    "#optimizer = optim.Adam(net.parameters(), lr=lr)\n",
    "optimizer = optim.SGD(net.parameters(), lr=lr, momentum=0.9, weight_decay=5e-4)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "\n",
    "print('加载最优模型')\n",
    "net.load_state_dict(torch.load('model/best.pth'))\n",
    "net = net.to(device)\n",
    "\n",
    "print('inference测试集')\n",
    "net.eval()\n",
    "id = 0\n",
    "preds_list = []\n",
    "with torch.no_grad():\n",
    "    for X, y in test_iter:\n",
    "        batch_pred = list(net(X.to(device)).argmax(dim=1).cpu().numpy())\n",
    "#         print(batch_pred)\n",
    "        for y_pred in batch_pred:\n",
    "#             print(y_pred)\n",
    "            preds_list.append((id, y_pred))\n",
    "            id += 1\n",
    "\n",
    "print('生成测试集评估文件')\n",
    "with open('result.csv', 'w') as f:\n",
    "    f.write('ID,Prediction\\n')\n",
    "    for id, pred in preds_list:\n",
    "        f.write('{},{}\\n'.format(id, pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(test_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[-0.8000, -0.8000, -0.8000, -0.8000, -0.8000, -0.8000, -0.8000,\n",
      "           -0.8000, -0.8000, -0.8000, -0.8000, -0.8000, -0.8000, -0.8000,\n",
      "           -0.8000, -0.8000, -0.8000, -0.8000, -0.8000, -0.8000, -0.8000,\n",
      "           -0.8000, -0.8000, -0.8000, -0.8000, -0.8000, -0.8000, -0.8000],\n",
      "          [-0.8000, -0.8000, -0.8000, -0.8000, -0.8000, -0.8000, -0.8000,\n",
      "           -0.8000, -0.8000, -0.8000, -0.8000, -0.8000, -0.8000, -0.8000,\n",
      "           -0.8000, -0.8000, -0.8000, -0.8000, -0.8000, -0.8000, -0.8000,\n",
      "           -0.8000, -0.8000, -0.8000, -0.8000, -0.8000, -0.8000, -0.8000],\n",
      "          [-0.8000, -0.8000, -0.8000, -0.8000, -0.8000, -0.8000, -0.8000,\n",
      "           -0.8000, -0.8000, -0.8000, -0.8000, -0.8000, -0.8000, -0.8000,\n",
      "           -0.8000, -0.8000, -0.8000, -0.8000, -0.8000, -0.8000, -0.8000,\n",
      "           -0.8000, -0.8000, -0.8000, -0.8000, -0.8000, -0.8000, -0.8000],\n",
      "          [-0.8000, -0.8000, -0.8000, -0.8000, -0.8000, -0.8000, -0.8000,\n",
      "           -0.8000, -0.8000, -0.8000, -0.8000, -0.8000, -0.8000, -0.8000,\n",
      "           -0.8000, -0.8000, -0.8000, -0.8000, -0.8000, -0.8000, -0.8000,\n",
      "           -0.8000, -0.8000, -0.8000, -0.8000, -0.8000, -0.8000, -0.8000],\n",
      "          [-0.8000, -0.8000, -0.8000, -0.8000, -0.8000, -0.8000, -0.8000,\n",
      "           -0.8000, -0.8000, -0.8000, -0.8000, -0.8000, -0.8000, -0.8000,\n",
      "           -0.8000, -0.8000, -0.8000, -0.8000, -0.8000, -0.8000, -0.8000,\n",
      "           -0.8000, -0.8000, -0.8000, -0.8000, -0.8000, -0.8000, -0.8000],\n",
      "          [-0.8000, -0.8000, -0.8000, -0.8000, -0.8000, -0.8000, -0.8000,\n",
      "           -0.8000, -0.8000, -0.8000, -0.8000, -0.8000, -0.8000, -0.8000,\n",
      "           -0.8000, -0.8000, -0.8000, -0.8000, -0.8000, -0.8000, -0.8000,\n",
      "           -0.8000, -0.8000, -0.8000, -0.8000, -0.8000, -0.8000, -0.8000],\n",
      "          [-0.8000, -0.8000, -0.8000, -0.8000, -0.8000, -0.8000, -0.8000,\n",
      "           -0.8000, -0.8000, -0.8000, -0.8000, -0.8000, -0.8000, -0.8000,\n",
      "           -0.8000, -0.8000, -0.8000, -0.8000, -0.8000, -0.8000, -0.8000,\n",
      "           -0.8000, -0.8000, -0.8000, -0.8000, -0.8000, -0.8000, -0.8000],\n",
      "          [-0.8000, -0.8000, -0.8000, -0.8000, -0.8000, -0.8000, -0.8000,\n",
      "           -0.8000, -0.8000, -0.8000, -0.8000, -0.8000, -0.8000, -0.8000,\n",
      "           -0.8000, -0.8000, -0.8000, -0.8000, -0.8000, -0.7664, -0.7888,\n",
      "           -0.8000, -0.8000, -0.7216, -0.8000, -0.3854, -0.8000, -0.8000],\n",
      "          [-0.8000, -0.8000, -0.8000, -0.8000, -0.8000, -0.8000, -0.8000,\n",
      "           -0.8000, -0.8000, -0.8000, -0.8000, -0.8000, -0.8000, -0.7888,\n",
      "           -0.7776, -0.8000, -0.4975,  0.1412, -0.6768, -0.8000, -0.8000,\n",
      "           -0.8000, -0.8000, -0.8000, -0.8000,  0.5333, -0.8000, -0.8000],\n",
      "          [-0.8000, -0.8000, -0.8000, -0.8000, -0.8000, -0.8000, -0.8000,\n",
      "           -0.8000, -0.8000, -0.8000, -0.8000, -0.8000, -0.8000, -0.7888,\n",
      "           -0.8000, -0.8000,  0.1860,  0.8022,  0.4325, -0.8000, -0.8000,\n",
      "           -0.8000, -0.8000, -0.5535,  0.2420,  0.3877, -0.8000, -0.8000],\n",
      "          [-0.8000, -0.8000, -0.8000, -0.8000, -0.8000, -0.8000, -0.8000,\n",
      "           -0.8000, -0.8000, -0.8000, -0.8000, -0.8000, -0.8000, -0.7552,\n",
      "           -0.8000, -0.2062,  0.6454,  0.5445,  0.8471,  1.1608,  0.9591,\n",
      "            1.0599,  0.7126,  0.9255,  1.0824,  0.7686, -0.8000, -0.8000],\n",
      "          [-0.8000, -0.8000, -0.8000, -0.8000, -0.8000, -0.8000, -0.8000,\n",
      "           -0.8000, -0.8000, -0.8000, -0.8000, -0.8000, -0.7776, -0.8000,\n",
      "           -0.6768,  0.7350,  0.6566,  0.6342,  0.9927,  1.1720,  0.9815,\n",
      "            1.0711,  1.1944,  0.8695,  0.8919,  0.8134, -0.8000, -0.8000],\n",
      "          [-0.8000, -0.8000, -0.8000, -0.8000, -0.8000, -0.8000, -0.7888,\n",
      "           -0.8000, -0.7776, -0.7888, -0.8000, -0.7664, -0.8000, -0.8000,\n",
      "            0.4885,  0.4773,  0.3877,  0.7350,  1.0824,  0.9143,  0.9479,\n",
      "            1.0487,  1.0711,  0.8022,  0.9591,  0.9703, -0.6768, -0.8000],\n",
      "          [-0.8000, -0.8000, -0.8000, -0.8000, -0.7888, -0.8000, -0.8000,\n",
      "           -0.8000, -0.8000, -0.8000, -0.7664, -0.8000, -0.8000,  0.1972,\n",
      "            0.7574,  0.2084,  0.2532,  0.9143,  0.8695,  0.6678,  0.8919,\n",
      "            1.0936,  1.1272,  0.8022,  0.9815,  1.0936, -0.2622, -0.8000],\n",
      "          [-0.8000, -0.8000, -0.8000, -0.8000, -0.8000, -0.8000, -0.7776,\n",
      "           -0.7552, -0.7888, -0.8000, -0.8000, -0.8000,  0.2980,  0.7238,\n",
      "            0.4325,  0.4213,  0.4325,  1.0151,  0.7126,  0.8134,  0.8695,\n",
      "            0.9815,  1.0711,  0.8134,  0.9703,  1.0936,  0.5333, -0.8000],\n",
      "          [-0.8000, -0.8000, -0.7776, -0.7776, -0.7888, -0.7776, -0.8000,\n",
      "           -0.8000, -0.8000, -0.8000, -0.5087,  0.4101,  0.5109,  0.3092,\n",
      "            0.4437,  0.5109,  0.7238,  0.9479,  0.7014,  0.9255,  0.9255,\n",
      "            0.9479,  0.9927,  0.7798,  0.8471,  0.9479,  1.1944, -0.8000],\n",
      "          [-0.7664, -0.8000, -0.8000, -0.8000, -0.8000, -0.8000, -0.8000,\n",
      "           -0.5647, -0.2062,  0.2308,  0.5109,  0.4437,  0.3541,  0.4885,\n",
      "            0.6454,  0.7014,  0.8022,  0.9255,  1.0487,  1.1048,  0.9255,\n",
      "            0.8919,  0.9255,  0.8022,  0.7462,  0.8807,  1.0487, -0.3182],\n",
      "          [-0.8000, -0.8000, -0.5423, -0.1950, -0.0717,  0.0515,  0.1524,\n",
      "            0.5221,  0.6342,  0.5782,  0.4437,  0.4661,  0.5221,  0.6230,\n",
      "            0.6006,  0.7574,  0.6902,  0.7238,  0.9927,  0.7686,  0.9367,\n",
      "            1.0039,  0.8134,  0.9367,  1.1272,  1.0039,  1.3176, -0.1053],\n",
      "          [-0.8000, -0.0381,  0.2532,  0.2084,  0.4437,  0.4773,  0.4437,\n",
      "            0.4773,  0.4885,  0.6230,  0.7126,  0.7238,  0.8022,  0.6118,\n",
      "            0.6230,  0.8919,  0.9255,  0.8022,  0.8583,  0.6006,  1.0151,\n",
      "            1.0151,  0.8134,  0.7462,  0.9143,  1.0151,  1.3961, -0.1501],\n",
      "          [-0.0157,  1.0936,  0.6454,  0.3653,  0.2980,  0.3204,  0.2532,\n",
      "            0.2868,  0.2980,  0.3429,  0.4101,  0.3877,  0.5333,  0.5445,\n",
      "            0.6454,  0.8695,  0.9479,  1.0711,  1.3289,  1.3289,  1.3961,\n",
      "            1.4185,  1.4185,  1.2952,  1.4073,  1.3176,  1.2616, -0.3966],\n",
      "          [-0.6207,  0.6118,  1.1160,  1.3064,  1.3064,  1.2616,  1.1160,\n",
      "            0.9143,  0.7126,  0.5445,  0.6118,  0.6230,  0.8359,  1.2728,\n",
      "            1.3849,  1.5417,  1.5305,  2.0571,  1.5417,  1.1832,  1.9451,\n",
      "            2.0235,  2.0123,  2.0123,  1.9675,  1.6650,  1.5081, -0.2510],\n",
      "          [-0.8000, -0.8000, -0.8000, -0.6655, -0.0493,  0.3877,  1.0375,\n",
      "            1.2728,  1.4297,  1.5529,  1.5641,  1.5529,  1.5305,  1.3289,\n",
      "            0.8807,  0.1188, -0.7104, -0.8000, -0.8000, -0.8000,  1.1944,\n",
      "            1.5305,  1.3064,  1.1608,  1.0151,  0.9703,  0.8919, -0.6768],\n",
      "          [-0.8000, -0.8000, -0.8000, -0.8000, -0.8000, -0.8000, -0.8000,\n",
      "           -0.8000, -0.8000, -0.8000, -0.8000, -0.8000, -0.8000, -0.8000,\n",
      "           -0.8000, -0.8000, -0.8000, -0.8000, -0.8000, -0.8000, -0.8000,\n",
      "           -0.8000, -0.8000, -0.8000, -0.8000, -0.8000, -0.8000, -0.8000],\n",
      "          [-0.8000, -0.8000, -0.8000, -0.8000, -0.8000, -0.8000, -0.8000,\n",
      "           -0.8000, -0.8000, -0.8000, -0.8000, -0.8000, -0.8000, -0.8000,\n",
      "           -0.8000, -0.8000, -0.8000, -0.8000, -0.8000, -0.8000, -0.8000,\n",
      "           -0.8000, -0.8000, -0.8000, -0.8000, -0.8000, -0.8000, -0.8000],\n",
      "          [-0.8000, -0.8000, -0.8000, -0.8000, -0.8000, -0.8000, -0.8000,\n",
      "           -0.8000, -0.8000, -0.8000, -0.8000, -0.8000, -0.8000, -0.8000,\n",
      "           -0.8000, -0.8000, -0.8000, -0.8000, -0.8000, -0.8000, -0.8000,\n",
      "           -0.8000, -0.8000, -0.8000, -0.8000, -0.8000, -0.8000, -0.8000],\n",
      "          [-0.8000, -0.8000, -0.8000, -0.8000, -0.8000, -0.8000, -0.8000,\n",
      "           -0.8000, -0.8000, -0.8000, -0.8000, -0.8000, -0.8000, -0.8000,\n",
      "           -0.8000, -0.8000, -0.8000, -0.8000, -0.8000, -0.8000, -0.8000,\n",
      "           -0.8000, -0.8000, -0.8000, -0.8000, -0.8000, -0.8000, -0.8000],\n",
      "          [-0.8000, -0.8000, -0.8000, -0.8000, -0.8000, -0.8000, -0.8000,\n",
      "           -0.8000, -0.8000, -0.8000, -0.8000, -0.8000, -0.8000, -0.8000,\n",
      "           -0.8000, -0.8000, -0.8000, -0.8000, -0.8000, -0.8000, -0.8000,\n",
      "           -0.8000, -0.8000, -0.8000, -0.8000, -0.8000, -0.8000, -0.8000],\n",
      "          [-0.8000, -0.8000, -0.8000, -0.8000, -0.8000, -0.8000, -0.8000,\n",
      "           -0.8000, -0.8000, -0.8000, -0.8000, -0.8000, -0.8000, -0.8000,\n",
      "           -0.8000, -0.8000, -0.8000, -0.8000, -0.8000, -0.8000, -0.8000,\n",
      "           -0.8000, -0.8000, -0.8000, -0.8000, -0.8000, -0.8000, -0.8000]]]]) [9]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9]\n",
      "[False]\n"
     ]
    }
   ],
   "source": [
    "m = 0\n",
    "for X, y in test_iter:\n",
    "    if m < 1:\n",
    "        print(X,y.numpy())\n",
    "        pred1 = net(X.to(device))\n",
    "        m+=1\n",
    "print(pred1.argmax(dim=1).cpu().numpy())        \n",
    "        \n",
    "print(y.numpy() == pred1.argmax(dim=1).cpu().numpy())\n",
    "# print(y == pred1.argmax(dim=1).cpu())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'numpy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-8f897d2540ff>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# print(X.numpy())\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# 显示图片\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'off'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# 不显示坐标轴\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'numpy'"
     ]
    }
   ],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "# print(X.numpy())\n",
    "\n",
    "plt.imshow(X.numpy()[0][0]) # 显示图片\n",
    "plt.axis('off') # 不显示坐标轴\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, inputs):\n",
    "    import numpy as np\n",
    "    import torch\n",
    "    import json\n",
    "    \n",
    "    inputs0 = json.loads(inputs[0])[0]\n",
    "    inputs1 = np.array(inputs0)\n",
    "\n",
    "    \n",
    "    inputs2 = torch.Tensor(inputs1)\n",
    "    print(inputs2,inputs2.dtype)\n",
    "    print(torch.__version__)\n",
    "    pred = model(inputs2)\n",
    "    pred = pred.data.numpy()\n",
    "    return [str(x) for x in pred]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20-07-02:02:02:43 INFO     [docker_container_manager.py:184] [default-cluster] Starting managed Redis instance in Docker\n",
      "20-07-02:02:02:47 INFO     [docker_container_manager.py:276] [default-cluster] Metric Configuration Saved at /tmp/tmp_7f5ah0y.yml\n",
      "20-07-02:02:02:48 INFO     [clipper_admin.py:162] [default-cluster] Clipper is running\n",
      "20-07-02:02:02:48 INFO     [clipper_admin.py:172] [default-cluster] Successfully connected to Clipper cluster at localhost:1337\n"
     ]
    }
   ],
   "source": [
    "# from clipper_admin import ClipperConnection, DockerContainerManager\n",
    "# from clipper_admin.deployers.pytorch import deploy_pytorch_model\n",
    "# clipper_conn = ClipperConnection(DockerContainerManager())\n",
    "# clipper_conn.connect()\n",
    "\n",
    "\n",
    "from clipper_admin import ClipperConnection, DockerContainerManager\n",
    "# from clipper_admin.deployers.tensorflow import deploy_tensorflow_model\n",
    "from clipper_admin.deployers.pytorch import deploy_pytorch_model\n",
    "clipper_conn = ClipperConnection(DockerContainerManager())\n",
    "clipper_conn.start_clipper()\n",
    "clipper_conn.connect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20-07-02:03:38:30 INFO     [clipper_admin.py:236] [default-cluster] Application pytorch-app6 was successfully registered\n",
      "20-07-02:03:38:31 INFO     [deployer_utils.py:41] Saving function to /tmp/tmp9gpwxqmnclipper\n",
      "20-07-02:03:38:31 INFO     [deployer_utils.py:51] Serialized and supplied predict function\n",
      "20-07-02:03:38:31 INFO     [pytorch.py:204] Torch model saved\n",
      "20-07-02:03:38:31 INFO     [pytorch.py:218] Using Python 3.6 base image\n",
      "20-07-02:03:38:31 INFO     [clipper_admin.py:534] [default-cluster] Building model Docker image with model data from /tmp/tmp9gpwxqmnclipper\n",
      "20-07-02:03:38:32 INFO     [clipper_admin.py:539] [default-cluster] Step 1/3 : FROM clipper/pytorch36-container:0.4.1\n",
      "20-07-02:03:38:32 INFO     [clipper_admin.py:539] [default-cluster]  ---> e3c73c7ad6b9\n",
      "20-07-02:03:38:32 INFO     [clipper_admin.py:539] [default-cluster] Step 2/3 : RUN apt-get -y install build-essential && pip install numpy\n",
      "20-07-02:03:38:32 INFO     [clipper_admin.py:539] [default-cluster]  ---> Using cache\n",
      "20-07-02:03:38:32 INFO     [clipper_admin.py:539] [default-cluster]  ---> ffe2c31b9d01\n",
      "20-07-02:03:38:32 INFO     [clipper_admin.py:539] [default-cluster] Step 3/3 : COPY /tmp/tmp9gpwxqmnclipper /model/\n",
      "20-07-02:03:38:32 INFO     [clipper_admin.py:539] [default-cluster]  ---> 61947c16d575\n",
      "20-07-02:03:38:32 INFO     [clipper_admin.py:539] [default-cluster] Successfully built 61947c16d575\n",
      "20-07-02:03:38:32 INFO     [clipper_admin.py:539] [default-cluster] Successfully tagged default-cluster-pytorch-mod6:1\n",
      "20-07-02:03:38:32 INFO     [clipper_admin.py:541] [default-cluster] Pushing model Docker image to default-cluster-pytorch-mod6:1\n",
      "20-07-02:03:38:38 INFO     [docker_container_manager.py:409] [default-cluster] Found 0 replicas for pytorch-mod6:1. Adding 1\n",
      "20-07-02:03:38:39 INFO     [clipper_admin.py:724] [default-cluster] Successfully registered model pytorch-mod6:1\n",
      "20-07-02:03:38:39 INFO     [clipper_admin.py:642] [default-cluster] Done deploying model pytorch-mod6:1.\n",
      "20-07-02:03:38:39 INFO     [clipper_admin.py:303] [default-cluster] Model pytorch-mod6 is now linked to application pytorch-app6\n"
     ]
    }
   ],
   "source": [
    "clipper_conn.register_application(\n",
    "    name=\"pytorch-app6\", input_type=\"strings\", default_output=\"-1.0\", slo_micros=100000)\n",
    "# deploy_tensorflow_model(clipper_conn,name=\"faster-mod4\",version=1,input_type=\"strings\",func=predict4,\n",
    "# tf_sess_or_saved_model_path=sess,pkgs_to_install=['numpy'])\n",
    "\n",
    "deploy_pytorch_model(clipper_conn,name=\"pytorch-mod6\",version=1,input_type=\"strings\",func=predict,\n",
    "pytorch_model=net,pkgs_to_install=['numpy'])\n",
    "\n",
    "clipper_conn.link_model_to_app(app_name=\"pytorch-app6\",model_name=\"pytorch-mod6\")\n",
    "\n",
    "query_address = clipper_conn.get_query_addr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['pytorch-app6']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X[0][0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[[-0.8        -0.8        -0.8        -0.8        -0.8\n",
      "    -0.8        -0.8        -0.8        -0.8        -0.8\n",
      "    -0.8        -0.8        -0.8        -0.8        -0.8\n",
      "    -0.8        -0.8        -0.8        -0.8        -0.8\n",
      "    -0.8        -0.8        -0.8        -0.8        -0.8\n",
      "    -0.8        -0.8        -0.8       ]\n",
      "   [-0.8        -0.8        -0.8        -0.8        -0.8\n",
      "    -0.8        -0.8        -0.8        -0.8        -0.8\n",
      "    -0.8        -0.8        -0.8        -0.8        -0.8\n",
      "    -0.8        -0.8        -0.8        -0.8        -0.8\n",
      "    -0.8        -0.8        -0.8        -0.8        -0.8\n",
      "    -0.8        -0.8        -0.8       ]\n",
      "   [-0.8        -0.8        -0.8        -0.8        -0.8\n",
      "    -0.8        -0.8        -0.8        -0.8        -0.8\n",
      "    -0.8        -0.8        -0.8        -0.8        -0.8\n",
      "    -0.8        -0.8        -0.8        -0.8        -0.8\n",
      "    -0.8        -0.8        -0.8        -0.8        -0.8\n",
      "    -0.8        -0.8        -0.8       ]\n",
      "   [-0.8        -0.8        -0.8        -0.8        -0.8\n",
      "    -0.8        -0.8        -0.8        -0.8        -0.8\n",
      "    -0.8        -0.8        -0.8        -0.8        -0.8\n",
      "    -0.8        -0.8        -0.8        -0.8        -0.8\n",
      "    -0.8        -0.8        -0.8        -0.8        -0.8\n",
      "    -0.8        -0.8        -0.8       ]\n",
      "   [-0.8        -0.8        -0.8        -0.8        -0.8\n",
      "    -0.8        -0.8        -0.8        -0.8        -0.8\n",
      "    -0.8        -0.8        -0.8        -0.8        -0.8\n",
      "    -0.8        -0.8        -0.8        -0.8        -0.8\n",
      "    -0.8        -0.8        -0.8        -0.8        -0.8\n",
      "    -0.8        -0.8        -0.8       ]\n",
      "   [-0.8        -0.8        -0.8        -0.8        -0.8\n",
      "    -0.8        -0.8        -0.8        -0.8        -0.8\n",
      "    -0.8        -0.8        -0.8        -0.8        -0.8\n",
      "    -0.8        -0.8        -0.8        -0.8        -0.8\n",
      "    -0.8        -0.8        -0.8        -0.8        -0.8\n",
      "    -0.8        -0.8        -0.8       ]\n",
      "   [-0.8        -0.8        -0.8        -0.8        -0.8\n",
      "    -0.8        -0.8        -0.8        -0.78879553 -0.78879553\n",
      "    -0.78879553 -0.77759105 -0.8        -0.78879553 -0.46386558\n",
      "    -0.8        -0.8        -0.77759105 -0.8        -0.8\n",
      "    -0.8        -0.8        -0.78879553 -0.78879553 -0.8\n",
      "    -0.8        -0.78879553 -0.8       ]\n",
      "   [-0.8        -0.8        -0.8        -0.8        -0.8\n",
      "    -0.8        -0.8        -0.8        -0.78879553 -0.8\n",
      "    -0.8        -0.8        -0.8        -0.3630252   0.5669468\n",
      "    -0.16134454 -0.8        -0.8        -0.77759105 -0.78879553\n",
      "    -0.78879553 -0.78879553 -0.8        -0.78879553 -0.8\n",
      "    -0.8        -0.8        -0.78879553]\n",
      "   [-0.8        -0.8        -0.8        -0.8        -0.8\n",
      "    -0.78879553 -0.8        -0.8        -0.77759105 -0.78879553\n",
      "    -0.8        -0.78879553 -0.46386558 -0.20616247  0.07394961\n",
      "     1.0375351   0.2084034  -0.8        -0.8        -0.8\n",
      "    -0.8        -0.8        -0.8        -0.77759105 -0.7439776\n",
      "    -0.6991597  -0.7551821  -0.8       ]\n",
      "   [-0.8        -0.8        -0.8        -0.8        -0.8\n",
      "    -0.8        -0.8        -0.78879553 -0.8        -0.8\n",
      "    -0.8        -0.46386558 -0.0380952  -0.15014006 -0.2957983\n",
      "    -0.07170865  0.5669468   0.24201684 -0.38543418 -0.66554624\n",
      "    -0.8        -0.8        -0.7327731  -0.4526611  -0.2957983\n",
      "    -0.00448176 -0.31820726 -0.8       ]\n",
      "   [-0.8        -0.8        -0.8        -0.8        -0.78879553\n",
      "    -0.7439776  -0.5871149  -0.16134454 -0.60952383 -0.8\n",
      "    -0.8        -0.17254902  0.09635857 -0.2957983  -0.19495799\n",
      "    -0.20616247 -0.17254902 -0.02689072  0.2084034   0.09635857\n",
      "    -0.00448176 -0.07170865 -0.1277311  -0.25098038 -0.20616247\n",
      "     0.16358545 -0.23977591 -0.8       ]\n",
      "   [-0.8        -0.8        -0.78879553 -0.78879553 -0.6991597\n",
      "    -0.16134454 -0.25098038 -0.31820726  0.63417375 -0.71036416\n",
      "    -0.8        -0.77759105 -0.08291313 -0.04929968  0.09635857\n",
      "    -0.11652661 -0.07170865 -0.1277311  -0.16134454 -0.2957983\n",
      "    -0.38543418 -0.4414566  -0.41904762 -0.0380952   0.00672272\n",
      "     0.2532213  -0.25098038 -0.8       ]\n",
      "   [-0.8        -0.8        -0.8        -0.8        -0.6207283\n",
      "    -0.16134454 -0.2957983  -0.5086835   0.08515409  0.6565827\n",
      "    -0.27338934 -0.8        -0.40784314 -0.0380952   0.16358545\n",
      "     0.26442578 -0.00448176 -0.31820726  0.54453784  1.9002802\n",
      "     0.75742304  0.33165267  1.407283    0.5109244   0.24201684\n",
      "     0.3652661  -0.04929968 -0.8       ]\n",
      "   [-0.8        -0.8        -0.8        -0.8        -0.77759105\n",
      "    -0.17254902 -0.3630252  -0.38543418 -0.2957983   0.28683475\n",
      "     0.779832    0.4997199   0.53333336  0.26442578 -0.34061623\n",
      "    -0.41904762 -0.31820726 -0.15014006  0.7126051   1.7434175\n",
      "     1.3960785   1.2952381   1.8778713   0.08515409 -0.25098038\n",
      "     0.12997201  0.02913169 -0.8       ]\n",
      "   [-0.8        -0.8        -0.78879553 -0.8        -0.7551821\n",
      "    -0.00448176 -0.4414566  -0.38543418 -0.2957983  -0.2957983\n",
      "    -0.02689072  0.63417375  0.3204482   0.54453784  0.6789917\n",
      "     0.5781513   0.7126051   1.1159664   1.2056023   1.0039216\n",
      "     0.6229692   0.5669468   1.2504202   0.3204482  -0.3630252\n",
      "    -0.0380952   0.05154065 -0.8       ]\n",
      "   [-0.8        -0.8        -0.78879553 -0.8        -0.78879553\n",
      "     0.05154065 -0.27338934 -0.48627454 -0.27338934  0.02913169\n",
      "    -0.37422967 -0.21736695 -0.15014006 -0.31820726  0.29803923\n",
      "     0.5669468   0.8358544   1.7546219   1.0487396   0.98151267\n",
      "     1.1943978   1.0375351   1.2056023   1.9563025   0.16358545\n",
      "    -0.17254902  0.11876754 -0.78879553]\n",
      "   [-0.8        -0.8        -0.8        -0.8        -0.78879553\n",
      "     0.19719891  0.9591037   1.0487396   1.1159664   0.24201684\n",
      "    -0.21736695 -0.17254902 -0.1277311   0.12997201  0.11876754\n",
      "    -0.15014006  0.19719891  0.9591037   1.1495799   1.452101\n",
      "     1.4184874   1.1943978   1.4408963   0.6565827  -0.04929968\n",
      "     0.07394961  0.04033617 -0.78879553]\n",
      "   [-0.8        -0.77759105 -0.78879553 -0.8        -0.7551821\n",
      "    -0.1277311  -0.25098038 -0.00448176 -0.08291313 -0.08291313\n",
      "    -0.02689072  0.08515409  0.21960787 -0.19495799 -0.4526611\n",
      "    -0.15014006  0.04033617 -0.19495799 -0.16134454 -0.21736695\n",
      "     0.4885154   2.0459383   0.6789917  -0.41904762 -0.09411765\n",
      "     0.02913169  0.00672272 -0.8       ]\n",
      "   [-0.78879553 -0.8        -0.8        -0.8        -0.7551821\n",
      "     0.15238097  0.02913169 -0.04929968 -0.0380952  -0.02689072\n",
      "     0.02913169  0.09635857  0.2532213  -0.17254902 -0.21736695\n",
      "     0.15238097  0.3652661   0.3764706   0.17478994 -0.02689072\n",
      "    -0.09411765  0.779832    0.24201684  0.17478994  0.19719891\n",
      "     0.33165267  0.15238097 -0.77759105]\n",
      "   [-0.5086835  -0.6207283  -0.8        -0.77759105 -0.8\n",
      "     0.08515409  0.4885154   0.19719891  0.3204482   0.29803923\n",
      "     0.3204482   0.3204482   0.41008404  0.16358545  0.05154065\n",
      "     0.12997201  0.24201684  0.53333336  0.45490196  0.45490196\n",
      "     0.45490196  0.2532213   0.34285715  0.21960787  0.04033617\n",
      "    -0.34061623 -0.6207283  -0.5759104 ]\n",
      "   [-0.66554624 -0.17254902 -0.32941175 -0.40784314 -0.6207283\n",
      "    -0.4526611  -0.15014006 -0.23977591 -0.20616247 -0.19495799\n",
      "    -0.16134454 -0.1277311  -0.08291313 -0.16134454 -0.37422967\n",
      "    -0.5086835  -0.6207283  -0.60952383 -0.71036416 -0.53109246\n",
      "    -0.54229695 -0.40784314 -0.4526611  -0.65434176 -0.53109246\n",
      "    -0.2957983  -0.15014006 -0.48627454]\n",
      "   [-0.8        -0.6207283  -0.31820726 -0.25098038  0.09635857\n",
      "     0.02913169 -0.07170865 -0.1277311  -0.19495799 -0.17254902\n",
      "    -0.19495799 -0.21736695 -0.23977591 -0.17254902 -0.17254902\n",
      "    -0.0380952   0.02913169  0.11876754  0.11876754  0.07394961\n",
      "     0.05154065  0.04033617  0.12997201  0.21960787  0.2532213\n",
      "     0.21960787 -0.15014006 -0.8       ]\n",
      "   [-0.8        -0.8        -0.8        -0.78879553 -0.7551821\n",
      "    -0.5647059  -0.34061623 -0.27338934 -0.27338934 -0.27338934\n",
      "    -0.23977591 -0.17254902 -0.16134454 -0.1277311  -0.11652661\n",
      "    -0.17254902 -0.27338934 -0.28459382 -0.31820726 -0.32941175\n",
      "    -0.32941175 -0.3630252  -0.3630252  -0.4414566  -0.5647059\n",
      "    -0.7551821  -0.8        -0.8       ]\n",
      "   [-0.8        -0.8        -0.8        -0.8        -0.8\n",
      "    -0.8        -0.8        -0.8        -0.8        -0.8\n",
      "    -0.8        -0.8        -0.8        -0.8        -0.8\n",
      "    -0.8        -0.8        -0.8        -0.8        -0.8\n",
      "    -0.8        -0.8        -0.8        -0.8        -0.8\n",
      "    -0.8        -0.8        -0.8       ]\n",
      "   [-0.8        -0.8        -0.8        -0.8        -0.8\n",
      "    -0.8        -0.8        -0.8        -0.8        -0.8\n",
      "    -0.8        -0.8        -0.8        -0.8        -0.8\n",
      "    -0.8        -0.8        -0.8        -0.8        -0.8\n",
      "    -0.8        -0.8        -0.8        -0.8        -0.8\n",
      "    -0.8        -0.8        -0.8       ]\n",
      "   [-0.8        -0.8        -0.8        -0.8        -0.8\n",
      "    -0.8        -0.8        -0.8        -0.8        -0.8\n",
      "    -0.8        -0.8        -0.8        -0.8        -0.8\n",
      "    -0.8        -0.8        -0.8        -0.8        -0.8\n",
      "    -0.8        -0.8        -0.8        -0.8        -0.8\n",
      "    -0.8        -0.8        -0.8       ]\n",
      "   [-0.8        -0.8        -0.8        -0.8        -0.8\n",
      "    -0.8        -0.8        -0.8        -0.8        -0.8\n",
      "    -0.8        -0.8        -0.8        -0.8        -0.8\n",
      "    -0.8        -0.8        -0.8        -0.8        -0.8\n",
      "    -0.8        -0.8        -0.8        -0.8        -0.8\n",
      "    -0.8        -0.8        -0.8       ]\n",
      "   [-0.8        -0.8        -0.8        -0.8        -0.8\n",
      "    -0.8        -0.8        -0.8        -0.8        -0.8\n",
      "    -0.8        -0.8        -0.8        -0.8        -0.8\n",
      "    -0.8        -0.8        -0.8        -0.8        -0.8\n",
      "    -0.8        -0.8        -0.8        -0.8        -0.8\n",
      "    -0.8        -0.8        -0.8       ]]]] float32\n",
      "{\"query_id\":7,\"output\":-1.0,\"default\":true,\"default_explanation\":\"Failed to retrieve a prediction response within the specified latency SLO\"}\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import base64\n",
    "import json\n",
    "import requests\n",
    "from PIL import Image\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "class MyEncoder(json.JSONEncoder):\n",
    "    def default(self, obj):\n",
    "        if isinstance(obj, np.integer):\n",
    "            return int(obj)\n",
    "        elif isinstance(obj, np.floating):\n",
    "            return float(obj)\n",
    "        elif isinstance(obj, np.ndarray):\n",
    "            return obj.tolist()\n",
    "        if isinstance(obj, time):\n",
    "            return obj.__str__()\n",
    "        else:\n",
    "            return super(NpEncoder, self).default(obj)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "url = \"http://%s/pytorch-app6/predict\" %  query_address\n",
    "\n",
    "X0 = X.numpy()\n",
    "print(X0,X0.dtype)\n",
    "X1 = [X0]\n",
    "\n",
    "\n",
    "#clipper要求输入必须为 字符串 故必须要序列化下\n",
    "# list1 = {'image':[[1,2,3]]}\n",
    "tva = json.dumps(X1,cls=MyEncoder)\n",
    "# tva = json.dumps([list1],cls=MyEncoder)\n",
    "# tva = [train_data]\n",
    "\n",
    "# print(tva)\n",
    "tva_j = json.dumps({\"input\": tva})\n",
    "# print(tva_j)\n",
    "#此处可看出 输入的最终数据为  [{\"image\": [[1, 2, 3]]}] \n",
    "#clipper 接收到的数据为 [b'[{\"image\": [[1, 2, 3]]}]' b'[{\"image\": [[1, 2, 3]]}]']\n",
    "headers = {'Content-type': 'application/json'}\n",
    "start = datetime.now()\n",
    "r = requests.post(url, headers=headers, data=tva_j)\n",
    "end = datetime.now()\n",
    "latency = (end - start).total_seconds() * 1000.0\n",
    "re = r.text\n",
    "\n",
    "print(re)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['pytorch-app6']"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "clipper_conn.get_all_apps()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['pytorch-mod6:1']"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clipper_conn.get_all_models()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20-07-02:03:38:02 INFO     [clipper_admin.py:344] Model pytorch-mod6 is now removed to application pytorch-app6\n"
     ]
    }
   ],
   "source": [
    "clipper_conn.unlink_model_from_app(model_name=\"pytorch-mod6\", app_name=\"pytorch-app6\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20-07-02:03:38:05 WARNING  [clipper_admin.py:240] [default-cluster] [DEPRECATED] Use 'unregister_application' API instead of this.\n",
      "20-07-02:03:38:05 INFO     [clipper_admin.py:260] [default-cluster] Application pytorch-app6 was successfully unregistered\n"
     ]
    }
   ],
   "source": [
    "clipper_conn.delete_application('pytorch-app6')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20-07-02:03:38:07 INFO     [clipper_admin.py:1285] Model pytorch-mod6:1 was successfully deleted\n",
      "20-07-02:03:38:07 INFO     [clipper_admin.py:1319] [default-cluster] Stopped all containers for these models and versions:\n",
      "{'pytorch-mod6': ['1']}\n"
     ]
    }
   ],
   "source": [
    "clipper_conn.stop_models('pytorch-mod6')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20-07-02:03:58:00 INFO     [clipper_admin.py:1424] [default-cluster] Stopped all Clipper cluster and all model containers\n"
     ]
    }
   ],
   "source": [
    "clipper_conn.stop_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[-0.8000, -0.8000, -0.8000, -0.8000, -0.8000, -0.8000, -0.8000,\n",
       "           -0.8000, -0.8000, -0.8000, -0.8000, -0.8000, -0.8000, -0.8000,\n",
       "           -0.8000, -0.8000, -0.8000, -0.8000, -0.8000, -0.8000, -0.8000,\n",
       "           -0.8000, -0.8000, -0.8000, -0.8000, -0.8000, -0.8000, -0.8000],\n",
       "          [-0.8000, -0.8000, -0.8000, -0.8000, -0.8000, -0.8000, -0.8000,\n",
       "           -0.8000, -0.8000, -0.8000, -0.8000, -0.8000, -0.8000, -0.8000,\n",
       "           -0.8000, -0.8000, -0.8000, -0.8000, -0.8000, -0.8000, -0.8000,\n",
       "           -0.8000, -0.8000, -0.8000, -0.8000, -0.8000, -0.8000, -0.8000],\n",
       "          [-0.8000, -0.8000, -0.8000, -0.8000, -0.8000, -0.8000, -0.8000,\n",
       "           -0.8000, -0.8000, -0.8000, -0.8000, -0.8000, -0.8000, -0.8000,\n",
       "           -0.8000, -0.8000, -0.8000, -0.8000, -0.8000, -0.8000, -0.8000,\n",
       "           -0.8000, -0.8000, -0.8000, -0.8000, -0.8000, -0.8000, -0.8000],\n",
       "          [-0.8000, -0.8000, -0.8000, -0.8000, -0.8000, -0.8000, -0.8000,\n",
       "           -0.8000, -0.8000, -0.8000, -0.8000, -0.8000, -0.8000, -0.8000,\n",
       "           -0.8000, -0.8000, -0.8000, -0.8000, -0.8000, -0.8000, -0.8000,\n",
       "           -0.8000, -0.8000, -0.8000, -0.8000, -0.8000, -0.8000, -0.8000],\n",
       "          [-0.8000, -0.8000, -0.8000, -0.8000, -0.8000, -0.8000, -0.8000,\n",
       "           -0.8000, -0.8000, -0.8000, -0.8000, -0.8000, -0.8000, -0.8000,\n",
       "           -0.8000, -0.8000, -0.8000, -0.8000, -0.8000, -0.8000, -0.8000,\n",
       "           -0.8000, -0.8000, -0.8000, -0.8000, -0.8000, -0.8000, -0.8000],\n",
       "          [-0.8000, -0.8000, -0.8000, -0.8000, -0.8000, -0.8000, -0.8000,\n",
       "           -0.8000, -0.8000, -0.8000, -0.8000, -0.8000, -0.8000, -0.8000,\n",
       "           -0.8000, -0.8000, -0.8000, -0.8000, -0.8000, -0.8000, -0.8000,\n",
       "           -0.8000, -0.8000, -0.8000, -0.8000, -0.8000, -0.8000, -0.8000],\n",
       "          [-0.8000, -0.8000, -0.8000, -0.8000, -0.8000, -0.8000, -0.8000,\n",
       "           -0.8000, -0.7888, -0.7888, -0.7888, -0.7776, -0.8000, -0.7888,\n",
       "           -0.4639, -0.8000, -0.8000, -0.7776, -0.8000, -0.8000, -0.8000,\n",
       "           -0.8000, -0.7888, -0.7888, -0.8000, -0.8000, -0.7888, -0.8000],\n",
       "          [-0.8000, -0.8000, -0.8000, -0.8000, -0.8000, -0.8000, -0.8000,\n",
       "           -0.8000, -0.7888, -0.8000, -0.8000, -0.8000, -0.8000, -0.3630,\n",
       "            0.5669, -0.1613, -0.8000, -0.8000, -0.7776, -0.7888, -0.7888,\n",
       "           -0.7888, -0.8000, -0.7888, -0.8000, -0.8000, -0.8000, -0.7888],\n",
       "          [-0.8000, -0.8000, -0.8000, -0.8000, -0.8000, -0.7888, -0.8000,\n",
       "           -0.8000, -0.7776, -0.7888, -0.8000, -0.7888, -0.4639, -0.2062,\n",
       "            0.0739,  1.0375,  0.2084, -0.8000, -0.8000, -0.8000, -0.8000,\n",
       "           -0.8000, -0.8000, -0.7776, -0.7440, -0.6992, -0.7552, -0.8000],\n",
       "          [-0.8000, -0.8000, -0.8000, -0.8000, -0.8000, -0.8000, -0.8000,\n",
       "           -0.7888, -0.8000, -0.8000, -0.8000, -0.4639, -0.0381, -0.1501,\n",
       "           -0.2958, -0.0717,  0.5669,  0.2420, -0.3854, -0.6655, -0.8000,\n",
       "           -0.8000, -0.7328, -0.4527, -0.2958, -0.0045, -0.3182, -0.8000],\n",
       "          [-0.8000, -0.8000, -0.8000, -0.8000, -0.7888, -0.7440, -0.5871,\n",
       "           -0.1613, -0.6095, -0.8000, -0.8000, -0.1725,  0.0964, -0.2958,\n",
       "           -0.1950, -0.2062, -0.1725, -0.0269,  0.2084,  0.0964, -0.0045,\n",
       "           -0.0717, -0.1277, -0.2510, -0.2062,  0.1636, -0.2398, -0.8000],\n",
       "          [-0.8000, -0.8000, -0.7888, -0.7888, -0.6992, -0.1613, -0.2510,\n",
       "           -0.3182,  0.6342, -0.7104, -0.8000, -0.7776, -0.0829, -0.0493,\n",
       "            0.0964, -0.1165, -0.0717, -0.1277, -0.1613, -0.2958, -0.3854,\n",
       "           -0.4415, -0.4190, -0.0381,  0.0067,  0.2532, -0.2510, -0.8000],\n",
       "          [-0.8000, -0.8000, -0.8000, -0.8000, -0.6207, -0.1613, -0.2958,\n",
       "           -0.5087,  0.0852,  0.6566, -0.2734, -0.8000, -0.4078, -0.0381,\n",
       "            0.1636,  0.2644, -0.0045, -0.3182,  0.5445,  1.9003,  0.7574,\n",
       "            0.3317,  1.4073,  0.5109,  0.2420,  0.3653, -0.0493, -0.8000],\n",
       "          [-0.8000, -0.8000, -0.8000, -0.8000, -0.7776, -0.1725, -0.3630,\n",
       "           -0.3854, -0.2958,  0.2868,  0.7798,  0.4997,  0.5333,  0.2644,\n",
       "           -0.3406, -0.4190, -0.3182, -0.1501,  0.7126,  1.7434,  1.3961,\n",
       "            1.2952,  1.8779,  0.0852, -0.2510,  0.1300,  0.0291, -0.8000],\n",
       "          [-0.8000, -0.8000, -0.7888, -0.8000, -0.7552, -0.0045, -0.4415,\n",
       "           -0.3854, -0.2958, -0.2958, -0.0269,  0.6342,  0.3204,  0.5445,\n",
       "            0.6790,  0.5782,  0.7126,  1.1160,  1.2056,  1.0039,  0.6230,\n",
       "            0.5669,  1.2504,  0.3204, -0.3630, -0.0381,  0.0515, -0.8000],\n",
       "          [-0.8000, -0.8000, -0.7888, -0.8000, -0.7888,  0.0515, -0.2734,\n",
       "           -0.4863, -0.2734,  0.0291, -0.3742, -0.2174, -0.1501, -0.3182,\n",
       "            0.2980,  0.5669,  0.8359,  1.7546,  1.0487,  0.9815,  1.1944,\n",
       "            1.0375,  1.2056,  1.9563,  0.1636, -0.1725,  0.1188, -0.7888],\n",
       "          [-0.8000, -0.8000, -0.8000, -0.8000, -0.7888,  0.1972,  0.9591,\n",
       "            1.0487,  1.1160,  0.2420, -0.2174, -0.1725, -0.1277,  0.1300,\n",
       "            0.1188, -0.1501,  0.1972,  0.9591,  1.1496,  1.4521,  1.4185,\n",
       "            1.1944,  1.4409,  0.6566, -0.0493,  0.0739,  0.0403, -0.7888],\n",
       "          [-0.8000, -0.7776, -0.7888, -0.8000, -0.7552, -0.1277, -0.2510,\n",
       "           -0.0045, -0.0829, -0.0829, -0.0269,  0.0852,  0.2196, -0.1950,\n",
       "           -0.4527, -0.1501,  0.0403, -0.1950, -0.1613, -0.2174,  0.4885,\n",
       "            2.0459,  0.6790, -0.4190, -0.0941,  0.0291,  0.0067, -0.8000],\n",
       "          [-0.7888, -0.8000, -0.8000, -0.8000, -0.7552,  0.1524,  0.0291,\n",
       "           -0.0493, -0.0381, -0.0269,  0.0291,  0.0964,  0.2532, -0.1725,\n",
       "           -0.2174,  0.1524,  0.3653,  0.3765,  0.1748, -0.0269, -0.0941,\n",
       "            0.7798,  0.2420,  0.1748,  0.1972,  0.3317,  0.1524, -0.7776],\n",
       "          [-0.5087, -0.6207, -0.8000, -0.7776, -0.8000,  0.0852,  0.4885,\n",
       "            0.1972,  0.3204,  0.2980,  0.3204,  0.3204,  0.4101,  0.1636,\n",
       "            0.0515,  0.1300,  0.2420,  0.5333,  0.4549,  0.4549,  0.4549,\n",
       "            0.2532,  0.3429,  0.2196,  0.0403, -0.3406, -0.6207, -0.5759],\n",
       "          [-0.6655, -0.1725, -0.3294, -0.4078, -0.6207, -0.4527, -0.1501,\n",
       "           -0.2398, -0.2062, -0.1950, -0.1613, -0.1277, -0.0829, -0.1613,\n",
       "           -0.3742, -0.5087, -0.6207, -0.6095, -0.7104, -0.5311, -0.5423,\n",
       "           -0.4078, -0.4527, -0.6543, -0.5311, -0.2958, -0.1501, -0.4863],\n",
       "          [-0.8000, -0.6207, -0.3182, -0.2510,  0.0964,  0.0291, -0.0717,\n",
       "           -0.1277, -0.1950, -0.1725, -0.1950, -0.2174, -0.2398, -0.1725,\n",
       "           -0.1725, -0.0381,  0.0291,  0.1188,  0.1188,  0.0739,  0.0515,\n",
       "            0.0403,  0.1300,  0.2196,  0.2532,  0.2196, -0.1501, -0.8000],\n",
       "          [-0.8000, -0.8000, -0.8000, -0.7888, -0.7552, -0.5647, -0.3406,\n",
       "           -0.2734, -0.2734, -0.2734, -0.2398, -0.1725, -0.1613, -0.1277,\n",
       "           -0.1165, -0.1725, -0.2734, -0.2846, -0.3182, -0.3294, -0.3294,\n",
       "           -0.3630, -0.3630, -0.4415, -0.5647, -0.7552, -0.8000, -0.8000],\n",
       "          [-0.8000, -0.8000, -0.8000, -0.8000, -0.8000, -0.8000, -0.8000,\n",
       "           -0.8000, -0.8000, -0.8000, -0.8000, -0.8000, -0.8000, -0.8000,\n",
       "           -0.8000, -0.8000, -0.8000, -0.8000, -0.8000, -0.8000, -0.8000,\n",
       "           -0.8000, -0.8000, -0.8000, -0.8000, -0.8000, -0.8000, -0.8000],\n",
       "          [-0.8000, -0.8000, -0.8000, -0.8000, -0.8000, -0.8000, -0.8000,\n",
       "           -0.8000, -0.8000, -0.8000, -0.8000, -0.8000, -0.8000, -0.8000,\n",
       "           -0.8000, -0.8000, -0.8000, -0.8000, -0.8000, -0.8000, -0.8000,\n",
       "           -0.8000, -0.8000, -0.8000, -0.8000, -0.8000, -0.8000, -0.8000],\n",
       "          [-0.8000, -0.8000, -0.8000, -0.8000, -0.8000, -0.8000, -0.8000,\n",
       "           -0.8000, -0.8000, -0.8000, -0.8000, -0.8000, -0.8000, -0.8000,\n",
       "           -0.8000, -0.8000, -0.8000, -0.8000, -0.8000, -0.8000, -0.8000,\n",
       "           -0.8000, -0.8000, -0.8000, -0.8000, -0.8000, -0.8000, -0.8000],\n",
       "          [-0.8000, -0.8000, -0.8000, -0.8000, -0.8000, -0.8000, -0.8000,\n",
       "           -0.8000, -0.8000, -0.8000, -0.8000, -0.8000, -0.8000, -0.8000,\n",
       "           -0.8000, -0.8000, -0.8000, -0.8000, -0.8000, -0.8000, -0.8000,\n",
       "           -0.8000, -0.8000, -0.8000, -0.8000, -0.8000, -0.8000, -0.8000],\n",
       "          [-0.8000, -0.8000, -0.8000, -0.8000, -0.8000, -0.8000, -0.8000,\n",
       "           -0.8000, -0.8000, -0.8000, -0.8000, -0.8000, -0.8000, -0.8000,\n",
       "           -0.8000, -0.8000, -0.8000, -0.8000, -0.8000, -0.8000, -0.8000,\n",
       "           -0.8000, -0.8000, -0.8000, -0.8000, -0.8000, -0.8000, -0.8000]]]])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
