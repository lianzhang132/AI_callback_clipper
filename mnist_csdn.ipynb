{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "mnist = input_data.read_data_sets('MNIST_data/', one_hot=True) \n",
    "#MNIST数据集所在路径\n",
    "\n",
    "x = tf.placeholder(tf.float32, [None, 784])\n",
    "\n",
    "y_ = tf.placeholder(tf.float32, [None, 10])\n",
    "\n",
    "\n",
    "def weight_variable(shape):\n",
    "    initial = tf.truncated_normal(shape,stddev = 0.1)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "def bias_variable(shape):\n",
    "    initial = tf.constant(0.1,shape = shape)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "def conv2d(x,W):\n",
    "    return tf.nn.conv2d(x, W, strides = [1,1,1,1], padding = 'SAME')\n",
    "\n",
    "def max_pool_2x2(x):\n",
    "    return tf.nn.max_pool(x, ksize=[1,2,2,1], strides=[1,2,2,1], padding='SAME')\n",
    "\n",
    "W_conv1 = weight_variable([5, 5, 1, 32])\n",
    "b_conv1 = bias_variable([32])\n",
    "\n",
    "x_image = tf.reshape(x,[-1,28,28,1])\n",
    "\n",
    "h_conv1 = tf.nn.relu(conv2d(x_image,W_conv1) + b_conv1)\n",
    "h_pool1 = max_pool_2x2(h_conv1)\n",
    "\n",
    "W_conv2 = weight_variable([5, 5, 32, 64])\n",
    "b_conv2 = bias_variable([64])\n",
    "\n",
    "h_conv2 = tf.nn.relu(conv2d(h_pool1, W_conv2) + b_conv2)\n",
    "h_pool2 = max_pool_2x2(h_conv2)\n",
    "\n",
    "W_fc1 = weight_variable([7 * 7 * 64, 1024])\n",
    "b_fc1 = bias_variable([1024])\n",
    "\n",
    "h_pool2_flat = tf.reshape(h_pool2, [-1, 7*7*64])\n",
    "h_fc1 = tf.nn.relu(tf.matmul(h_pool2_flat, W_fc1) + b_fc1)\n",
    "\n",
    "keep_prob = tf.placeholder(\"float\")\n",
    "h_fc1_drop = tf.nn.dropout(h_fc1, keep_prob)\n",
    "\n",
    "W_fc2 = weight_variable([1024, 10])\n",
    "b_fc2 = bias_variable([10])\n",
    "\n",
    "y_conv=tf.nn.softmax(tf.matmul(h_fc1_drop, W_fc2) + b_fc2)\n",
    "\n",
    "cross_entropy = -tf.reduce_sum(y_*tf.log(y_conv))\n",
    "train_step = tf.train.AdamOptimizer(1e-4).minimize(cross_entropy)\n",
    "correct_prediction = tf.equal(tf.argmax(y_conv,1), tf.argmax(y_,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
    "\n",
    "saver = tf.train.Saver() #定义saver\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for i in range(20000):\n",
    "        batch = mnist.train.next_batch(50)\n",
    "        if i % 100 == 0:\n",
    "            train_accuracy = accuracy.eval(feed_dict={\n",
    "                x: batch[0], y_: batch[1], keep_prob: 1.0})\n",
    "            print('step %d, training accuracy %g' % (i, train_accuracy))\n",
    "#         train_step.run(feed_dict={x: batch[0], y_: batch[1], keep_prob: 0.5})\n",
    "        sess.run(train_step, \n",
    "                 feed_dict={x: batch[0], y_: batch[1],keep_prob: 0.5})\n",
    "    saver.save(sess, '/tmp/tf_csdn1/model.ckpt') #模型储存位置\n",
    "\n",
    "    print('test accuracy %g' % accuracy.eval(feed_dict={\n",
    "        x: mnist.test.images, y_: mnist.test.labels, keep_prob: 1.0}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image, ImageFilter\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def imageprepare(): \n",
    "    im = Image.open('/root/code/4.jpg') #读取的图片所在路径，注意是28*28像素\n",
    "    plt.imshow(im)  #显示需要识别的图片\n",
    "    plt.show()\n",
    "    im = im.convert('L')\n",
    "    tv = list(im.getdata()) \n",
    "    tva = [(255-x)*1.0/255.0 for x in tv] \n",
    "    return tva\n",
    "\n",
    "result=imageprepare()\n",
    "x = tf.placeholder(tf.float32, [None, 784])\n",
    "\n",
    "y_ = tf.placeholder(tf.float32, [None, 10])\n",
    "\n",
    "def weight_variable(shape):\n",
    "    initial = tf.truncated_normal(shape,stddev = 0.1)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "def bias_variable(shape):\n",
    "    initial = tf.constant(0.1,shape = shape)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "def conv2d(x,W):\n",
    "    return tf.nn.conv2d(x, W, strides = [1,1,1,1], padding = 'SAME')\n",
    "\n",
    "def max_pool_2x2(x):\n",
    "    return tf.nn.max_pool(x, ksize=[1,2,2,1], strides=[1,2,2,1], padding='SAME')\n",
    "\n",
    "W_conv1 = weight_variable([5, 5, 1, 32])\n",
    "b_conv1 = bias_variable([32])\n",
    "\n",
    "x_image = tf.reshape(x,[-1,28,28,1])\n",
    "\n",
    "h_conv1 = tf.nn.relu(conv2d(x_image,W_conv1) + b_conv1)\n",
    "h_pool1 = max_pool_2x2(h_conv1)\n",
    "\n",
    "W_conv2 = weight_variable([5, 5, 32, 64])\n",
    "b_conv2 = bias_variable([64])\n",
    "\n",
    "h_conv2 = tf.nn.relu(conv2d(h_pool1, W_conv2) + b_conv2)\n",
    "h_pool2 = max_pool_2x2(h_conv2)\n",
    "\n",
    "W_fc1 = weight_variable([7 * 7 * 64, 1024])\n",
    "b_fc1 = bias_variable([1024])\n",
    "\n",
    "h_pool2_flat = tf.reshape(h_pool2, [-1, 7*7*64])\n",
    "h_fc1 = tf.nn.relu(tf.matmul(h_pool2_flat, W_fc1) + b_fc1)\n",
    "\n",
    "keep_prob = tf.placeholder(\"float\")\n",
    "h_fc1_drop = tf.nn.dropout(h_fc1, keep_prob)\n",
    "\n",
    "W_fc2 = weight_variable([1024, 10])\n",
    "b_fc2 = bias_variable([10])\n",
    "\n",
    "y_conv=tf.nn.softmax(tf.matmul(h_fc1_drop, W_fc2) + b_fc2)\n",
    "\n",
    "cross_entropy = -tf.reduce_sum(y_*tf.log(y_conv))\n",
    "train_step = tf.train.AdamOptimizer(1e-4).minimize(cross_entropy)\n",
    "correct_prediction = tf.equal(tf.argmax(y_conv,1), tf.argmax(y_,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
    "\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    saver.restore(sess, '/tmp/tf_csdn/model.ckpt') #使用模型，参数和之前的代码保持一致\n",
    "\n",
    "    prediction=tf.argmax(y_conv,1)\n",
    "    predint=prediction.eval(feed_dict={x: [result],keep_prob: 1.0}, session=sess)\n",
    "\n",
    "    print('识别结果:')\n",
    "    print(predint[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "from PIL import Image, ImageFilter\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets('MNIST_data/', one_hot=True) \n",
    "\n",
    "def imageprepare(): \n",
    "    im = Image.open('/root/code/pic_png/0.png') #读取的图片所在路径，注意是28*28像素\n",
    "    plt.imshow(im)  #显示需要识别的图片\n",
    "    plt.show()\n",
    "    im = im.convert('L')\n",
    "    tv = list(im.getdata()) \n",
    "    tva = [(255-x)*1.0/255.0 for x in tv] \n",
    "    return tva\n",
    "\n",
    "result=imageprepare()\n",
    "x = tf.placeholder(tf.float32, [None, 784])\n",
    "\n",
    "y_ = tf.placeholder(tf.float32, [None, 10])\n",
    "\n",
    "def weight_variable(shape):\n",
    "    initial = tf.truncated_normal(shape,stddev = 0.1)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "def bias_variable(shape):\n",
    "    initial = tf.constant(0.1,shape = shape)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "def conv2d(x,W):\n",
    "    return tf.nn.conv2d(x, W, strides = [1,1,1,1], padding = 'SAME')\n",
    "\n",
    "def max_pool_2x2(x):\n",
    "    return tf.nn.max_pool(x, ksize=[1,2,2,1], strides=[1,2,2,1], padding='SAME')\n",
    "\n",
    "W_conv1 = weight_variable([5, 5, 1, 32])\n",
    "b_conv1 = bias_variable([32])\n",
    "\n",
    "x_image = tf.reshape(x,[-1,28,28,1])\n",
    "\n",
    "h_conv1 = tf.nn.relu(conv2d(x_image,W_conv1) + b_conv1)\n",
    "h_pool1 = max_pool_2x2(h_conv1)\n",
    "\n",
    "W_conv2 = weight_variable([5, 5, 32, 64])\n",
    "b_conv2 = bias_variable([64])\n",
    "\n",
    "h_conv2 = tf.nn.relu(conv2d(h_pool1, W_conv2) + b_conv2)\n",
    "h_pool2 = max_pool_2x2(h_conv2)\n",
    "\n",
    "W_fc1 = weight_variable([7 * 7 * 64, 1024])\n",
    "b_fc1 = bias_variable([1024])\n",
    "\n",
    "h_pool2_flat = tf.reshape(h_pool2, [-1, 7*7*64])\n",
    "h_fc1 = tf.nn.relu(tf.matmul(h_pool2_flat, W_fc1) + b_fc1)\n",
    "\n",
    "keep_prob = tf.placeholder(\"float\")\n",
    "h_fc1_drop = tf.nn.dropout(h_fc1, keep_prob)\n",
    "\n",
    "W_fc2 = weight_variable([1024, 10])\n",
    "b_fc2 = bias_variable([10])\n",
    "\n",
    "y_conv=tf.nn.softmax(tf.matmul(h_fc1_drop, W_fc2) + b_fc2)\n",
    "\n",
    "cross_entropy = -tf.reduce_sum(y_*tf.log(y_conv))\n",
    "train_step = tf.train.AdamOptimizer(1e-4).minimize(cross_entropy)\n",
    "correct_prediction = tf.equal(tf.argmax(y_conv,1), tf.argmax(y_,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
    "\n",
    "saver = tf.train.Saver()\n",
    "sess = tf.Session()\n",
    "\n",
    "sess.run(tf.global_variables_initializer())\n",
    "saver.restore(sess, '/tmp/tf_csdn1/model.ckpt') #使用模型，参数和之前的代码保持一致\n",
    "batch = mnist.train.next_batch(50)\n",
    "#tf.argmax：返回一个张量维数最大的指标。\n",
    "prediction=tf.argmax(y_conv,1)\n",
    "predint=prediction.eval(feed_dict={x: [result],keep_prob: 1.0}, session=sess)\n",
    "\n",
    "print('识别结果:')\n",
    "print(predint[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-1-c9ea5e33a981>:54: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_csdn/model.ckpt\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "识别结果:\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "from PIL import Image, ImageFilter\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# def imageprepare(): \n",
    "#     im = Image.open('/root/code/3.png') #读取的图片所在路径，注意是28*28像素\n",
    "#     plt.imshow(im)  #显示需要识别的图片\n",
    "#     plt.show()\n",
    "#     im = im.convert('L')\n",
    "#     tv = list(im.getdata()) \n",
    "#     tva = [(255-x)*1.0/255.0 for x in tv] \n",
    "#     return tva\n",
    "\n",
    "# result=imageprepare()\n",
    "x = tf.placeholder(tf.float32, [None, 784])\n",
    "\n",
    "y_ = tf.placeholder(tf.float32, [None, 10])\n",
    "\n",
    "def weight_variable(shape):\n",
    "    initial = tf.truncated_normal(shape,stddev = 0.1)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "def bias_variable(shape):\n",
    "    initial = tf.constant(0.1,shape = shape)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "def conv2d(x,W):\n",
    "    return tf.nn.conv2d(x, W, strides = [1,1,1,1], padding = 'SAME')\n",
    "\n",
    "def max_pool_2x2(x):\n",
    "    return tf.nn.max_pool(x, ksize=[1,2,2,1], strides=[1,2,2,1], padding='SAME')\n",
    "\n",
    "W_conv1 = weight_variable([5, 5, 1, 32])\n",
    "b_conv1 = bias_variable([32])\n",
    "\n",
    "x_image = tf.reshape(x,[-1,28,28,1])\n",
    "\n",
    "h_conv1 = tf.nn.relu(conv2d(x_image,W_conv1) + b_conv1)\n",
    "h_pool1 = max_pool_2x2(h_conv1)\n",
    "\n",
    "W_conv2 = weight_variable([5, 5, 32, 64])\n",
    "b_conv2 = bias_variable([64])\n",
    "\n",
    "h_conv2 = tf.nn.relu(conv2d(h_pool1, W_conv2) + b_conv2)\n",
    "h_pool2 = max_pool_2x2(h_conv2)\n",
    "\n",
    "W_fc1 = weight_variable([7 * 7 * 64, 1024])\n",
    "b_fc1 = bias_variable([1024])\n",
    "\n",
    "h_pool2_flat = tf.reshape(h_pool2, [-1, 7*7*64])\n",
    "h_fc1 = tf.nn.relu(tf.matmul(h_pool2_flat, W_fc1) + b_fc1)\n",
    "\n",
    "keep_prob = tf.placeholder(\"float\")\n",
    "h_fc1_drop = tf.nn.dropout(h_fc1, keep_prob)\n",
    "\n",
    "W_fc2 = weight_variable([1024, 10])\n",
    "b_fc2 = bias_variable([10])\n",
    "\n",
    "y_conv=tf.nn.softmax(tf.matmul(h_fc1_drop, W_fc2) + b_fc2)\n",
    "\n",
    "cross_entropy = -tf.reduce_sum(y_*tf.log(y_conv))\n",
    "train_step = tf.train.AdamOptimizer(1e-4).minimize(cross_entropy)\n",
    "correct_prediction = tf.equal(tf.argmax(y_conv,1), tf.argmax(y_,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
    "\n",
    "saver = tf.train.Saver()\n",
    "sess = tf.Session()\n",
    "\n",
    "sess.run(tf.global_variables_initializer())\n",
    "saver.restore(sess, '/tmp/tf_csdn/model.ckpt') #使用模型，参数和之前的代码保持一致\n",
    "\n",
    "prediction=tf.argmax(y_conv,1)\n",
    "im = Image.open('/root/code/pic_png/3.png') #读取的图片所在路径，注意是28*28像素\n",
    "plt.imshow(im)  #显示需要识别的图片\n",
    "plt.show()\n",
    "im = im.convert('L')\n",
    "tv = list(im.getdata()) \n",
    "tva = [(255-x)*1.0/255.0 for x in tv] \n",
    "predint=prediction.eval(feed_dict={x: [tva],keep_prob: 1.0}, session=sess)\n",
    "\n",
    "print('识别结果:')\n",
    "print(predint[0])\n",
    "#用了函数处理 图像数据 所以用x:【result】"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "from PIL import Image, ImageFilter\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# def imageprepare(): \n",
    "#     im = Image.open('/root/code/3.jpg') #读取的图片所在路径，注意是28*28像素\n",
    "#     plt.imshow(im)  #显示需要识别的图片\n",
    "#     plt.show()\n",
    "#     im = im.convert('L')\n",
    "#     tv = list(im.getdata()) \n",
    "#     tva = [(255-x)*1.0/255.0 for x in tv] \n",
    "#     return tva\n",
    "\n",
    "# result=imageprepare()\n",
    "x = tf.placeholder(tf.float32, [None, 784])\n",
    "\n",
    "y_ = tf.placeholder(tf.float32, [None, 10])\n",
    "\n",
    "def weight_variable(shape):\n",
    "    initial = tf.truncated_normal(shape,stddev = 0.1)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "def bias_variable(shape):\n",
    "    initial = tf.constant(0.1,shape = shape)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "def conv2d(x,W):\n",
    "    return tf.nn.conv2d(x, W, strides = [1,1,1,1], padding = 'SAME')\n",
    "\n",
    "def max_pool_2x2(x):\n",
    "    return tf.nn.max_pool(x, ksize=[1,2,2,1], strides=[1,2,2,1], padding='SAME')\n",
    "\n",
    "W_conv1 = weight_variable([5, 5, 1, 32])\n",
    "b_conv1 = bias_variable([32])\n",
    "\n",
    "x_image = tf.reshape(x,[-1,28,28,1])\n",
    "\n",
    "h_conv1 = tf.nn.relu(conv2d(x_image,W_conv1) + b_conv1)\n",
    "h_pool1 = max_pool_2x2(h_conv1)\n",
    "\n",
    "W_conv2 = weight_variable([5, 5, 32, 64])\n",
    "b_conv2 = bias_variable([64])\n",
    "\n",
    "h_conv2 = tf.nn.relu(conv2d(h_pool1, W_conv2) + b_conv2)\n",
    "h_pool2 = max_pool_2x2(h_conv2)\n",
    "\n",
    "W_fc1 = weight_variable([7 * 7 * 64, 1024])\n",
    "b_fc1 = bias_variable([1024])\n",
    "\n",
    "h_pool2_flat = tf.reshape(h_pool2, [-1, 7*7*64])\n",
    "h_fc1 = tf.nn.relu(tf.matmul(h_pool2_flat, W_fc1) + b_fc1)\n",
    "\n",
    "keep_prob = tf.placeholder(\"float\")\n",
    "h_fc1_drop = tf.nn.dropout(h_fc1, keep_prob)\n",
    "\n",
    "W_fc2 = weight_variable([1024, 10])\n",
    "b_fc2 = bias_variable([10])\n",
    "\n",
    "y_conv=tf.nn.softmax(tf.matmul(h_fc1_drop, W_fc2) + b_fc2)\n",
    "\n",
    "cross_entropy = -tf.reduce_sum(y_*tf.log(y_conv))\n",
    "train_step = tf.train.AdamOptimizer(1e-4).minimize(cross_entropy)\n",
    "correct_prediction = tf.equal(tf.argmax(y_conv,1), tf.argmax(y_,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
    "\n",
    "saver = tf.train.Saver()\n",
    "sess = tf.Session()\n",
    "\n",
    "sess.run(tf.global_variables_initializer())\n",
    "saver.restore(sess, '/tmp/tf_csdn/model.ckpt') #使用模型，参数和之前的代码保持一致\n",
    "\n",
    "im = Image.open('/root/code/3.png') #读取的图片所在路径，注意是28*28像素\n",
    "\n",
    "plt.imshow(im)  #显示需要识别的图片\n",
    "plt.show()\n",
    "im = im.convert('L')\n",
    "tv = list(im.getdata()) \n",
    "tva = [(255-x)*1.0/255.0 for x in tv] \n",
    "\n",
    "prediction=tf.argmax(y_conv,1)\n",
    "predint=prediction.eval(feed_dict={x: [tva],keep_prob: 1.0}, session=sess)\n",
    "\n",
    "print('识别结果:')\n",
    "print(predint[0])\n",
    "#正常处理 用tva变量赋值形式 图像数据 所以用x:【tva】"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 2, 8]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def prediction(sess,adds):\n",
    "    from PIL import Image, ImageFilter\n",
    "#     import tensorflow as tf\n",
    "#     import matplotlib.pyplot as plt\n",
    "    numbers = []\n",
    "    for add in adds:\n",
    "        im = Image.open(add) #读取的图片所在路径，注意是28*28像素\n",
    "#         plt.imshow(im)  #显示需要识别的图片\n",
    "#         plt.show()\n",
    "        im = im.convert('L')\n",
    "        tv = list(im.getdata()) \n",
    "        tva = [(255-x)*1.0/255.0 for x in tv] \n",
    "#         sess.run(tf.global_variables_initializer())\n",
    "#         saver.restore(sess, '/tmp/tf_csdn/model.ckpt') #使用模型，参数和之前的代码保持一致\n",
    "        prediction=tf.argmax(y_conv,1)\n",
    "        predint=prediction.eval(feed_dict={x:[tva],keep_prob: 1.0},\n",
    "                                session=sess)\n",
    "\n",
    "        \n",
    "        numbers.append(predint[0])\n",
    "#     print(numbers)\n",
    "    return numbers\n",
    "  \n",
    "adds = [\"/root/code/pic_png/0.png\",\"/root/code/pic_png/2.png\",\"/root/code/pic_png/8.png\"]\n",
    "prediction(sess,adds)\n",
    "#部署不进去 加引号的话  说 不在 说 x 不在 graph中"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Cannot interpret feed_dict key as Tensor: The name 'x' looks like an (invalid) Operation name, not a Tensor. Tensor names must be of the form \"<op_name>:<output_index>\".",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1119\u001b[0m             subfeed_t = self.graph.as_graph_element(\n\u001b[0;32m-> 1120\u001b[0;31m                 subfeed, allow_tensor=True, allow_operation=False)\n\u001b[0m\u001b[1;32m   1121\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow_core/python/framework/ops.py\u001b[0m in \u001b[0;36mas_graph_element\u001b[0;34m(self, obj, allow_tensor, allow_operation)\u001b[0m\n\u001b[1;32m   3606\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3607\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_as_graph_element_locked\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_operation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3608\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow_core/python/framework/ops.py\u001b[0m in \u001b[0;36m_as_graph_element_locked\u001b[0;34m(self, obj, allow_tensor, allow_operation)\u001b[0m\n\u001b[1;32m   3680\u001b[0m                     \"\\\"<op_name>:<output_index>\\\".\")\n\u001b[0;32m-> 3681\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr_msg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3682\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: The name 'x' looks like an (invalid) Operation name, not a Tensor. Tensor names must be of the form \"<op_name>:<output_index>\".",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-5ee5335b741a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;31m# adds = [\"/root/code/pic_png/0.png\",\"/root/code/pic_png/2.png\",\"/root/code/pic_png/8.png\"]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0madds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"/root/code/pic_png/0.png\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m \u001b[0mprediction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0madds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0;31m#部署不进去 加引号的话  说 不在 说 x 不在 graph中\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-26-5ee5335b741a>\u001b[0m in \u001b[0;36mprediction\u001b[0;34m(sess, adds)\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;31m#         predint=prediction.eval(feed_dict={x:[tva],keep_prob: 1.0},\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;31m#                                 session=sess)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0mpredints\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"prediction\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"x\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtva\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mkeep_prob\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m         \"\"\"\n\u001b[1;32m     20\u001b[0m         \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0m的区别\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    954\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    955\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 956\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    957\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    958\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1121\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1122\u001b[0m             raise TypeError('Cannot interpret feed_dict key as Tensor: ' +\n\u001b[0;32m-> 1123\u001b[0;31m                             e.args[0])\n\u001b[0m\u001b[1;32m   1124\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1125\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubfeed_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Cannot interpret feed_dict key as Tensor: The name 'x' looks like an (invalid) Operation name, not a Tensor. Tensor names must be of the form \"<op_name>:<output_index>\"."
     ]
    }
   ],
   "source": [
    "def prediction(sess,adds):\n",
    "    from PIL import Image, ImageFilter\n",
    "#     import tensorflow as tf\n",
    "#     import matplotlib.pyplot as plt\n",
    "    numbers = []\n",
    "    for add in adds:\n",
    "        im = Image.open(add) #读取的图片所在路径，注意是28*28像素\n",
    "#         plt.imshow(im)  #显示需要识别的图片\n",
    "#         plt.show()\n",
    "        im = im.convert('L')\n",
    "        tv = list(im.getdata()) \n",
    "        tva = [(255-x)*1.0/255.0 for x in tv] \n",
    "#         sess.run(tf.global_variables_initializer())\n",
    "#         saver.restore(sess, '/tmp/tf_csdn/model.ckpt') #使用模型，参数和之前的代码保持一致\n",
    "        prediction=tf.argmax(y_conv,1)\n",
    "#         predint=prediction.eval(feed_dict={x:[tva],keep_prob: 1.0},\n",
    "#                                 session=sess)\n",
    "        predints=sess.run(prediction,feed_dict={x:[tva],keep_prob: 1.0})\n",
    "        \"\"\"\n",
    "        tf.run()  tf.eval() 的区别\n",
    "        在使用t.eval()等价于：tf.get_default_session().run(t)\n",
    "        tf.run(t,feed_dict{}) ==> tf.eval(feed_dict{})\n",
    "\n",
    "        \"\"\"\n",
    "        \n",
    "        numbers.append(predint[0])\n",
    "#     print(numbers)\n",
    "    return numbers\n",
    "  \n",
    "# adds = [\"/root/code/pic_png/0.png\",\"/root/code/pic_png/2.png\",\"/root/code/pic_png/8.png\"]\n",
    "adds = [\"/root/code/pic_png/0.png\"]\n",
    "prediction(sess,adds)\n",
    "#部署不进去 加引号的话  说 不在 说 x 不在 graph中\n",
    "#不加 部署不进去"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.client.session.Session at 0x7fb4ef78b128>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction1(sess, inputs):\n",
    "    from PIL import Image, ImageFilter\n",
    "    import tensorflow as tf\n",
    "    import matplotlib.pyplot as plt\n",
    "    numbers = []\n",
    "#     global y_l\n",
    "#     y_l = y_conv\n",
    "    for add in adds:\n",
    "        im = Image.open(add) #读取的图片所在路径，注意是28*28像素\n",
    "        plt.imshow(im)  #显示需要识别的图片\n",
    "        plt.show()\n",
    "        im = im.convert('L')\n",
    "        tv = list(im.getdata()) \n",
    "        tva = [(255-x)*1.0/255.0 for x in tv] \n",
    "\n",
    "#         prediction=tf.argmax(y_l,1)\n",
    "        predint=prediction.eval(feed_dict={\"x: [tva]\",\"keep_prob: 1.0\"},\n",
    "                                session=sess)\n",
    "        numbers.append(predint[0])\n",
    "    print(numbers)\n",
    "  \n",
    "adds = [\"/root/code/3.jpg\",\"/root/code/0.jpg\",\"/root/code/8.jpg\"]\n",
    "prediction(sess,adds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict3(sess, inputs):\n",
    "    predint=prediction.eval(feed_dict={\"x\":inputs,keep_prob: 1.0},\n",
    "                                session=sess)\n",
    "    # `X` is used, it must be defined in the model with that name explicitly!\n",
    "    return [str(p) for p in predint]\n",
    "#部署 函数 一定要用sess.run 因为clipper只取到 sess ？？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adds = [\"/root/code/3.jpg\",\"/root/code/0.jpg\",\"/root/code/8.jpg\"]\n",
    "predict3(sess,adds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/root/code/0.png'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-e7b799dc146c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m#x的操作不在局部图中\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0madds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"/root/code/0.png\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"/root/code/2.png\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"/root/code/8.png\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mpredict3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0madds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-2-e7b799dc146c>\u001b[0m in \u001b[0;36mpredict3\u001b[0;34m(sess, adds)\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mresults\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0madd\u001b[0m \u001b[0;32min\u001b[0m \u001b[0madds\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m         \u001b[0mim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#读取的图片所在路径，注意是28*28像素\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;31m#         plt.imshow(im)  #显示需要识别的图片\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m#         plt.show()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/PIL/Image.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(fp, mode)\u001b[0m\n\u001b[1;32m   2807\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2808\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2809\u001b[0;31m         \u001b[0mfp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuiltins\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2810\u001b[0m         \u001b[0mexclusive_fp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2811\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/root/code/0.png'"
     ]
    }
   ],
   "source": [
    "def predict3(sess, adds):\n",
    "    results=[]\n",
    "    for add in adds:\n",
    "        im = Image.open(add) #读取的图片所在路径，注意是28*28像素\n",
    "#         plt.imshow(im)  #显示需要识别的图片\n",
    "#         plt.show()\n",
    "        im = im.convert('L')\n",
    "        tv = list(im.getdata()) \n",
    "        tva = [(255-x)*1.0/255.0 for x in tv]\n",
    "        predint=sess.run('predint:0',feed_dict={\"x:[tva]\":add})\n",
    "        results.append(str(predint[0]))\n",
    "    return results\n",
    "#x的操作不在局部图中 \n",
    "adds = [\"/root/code/0.png\",\"/root/code/2.png\",\"/root/code/8.png\"]\n",
    "predict3(sess,adds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict3(sess, inputs):\n",
    "    predint=sess.run('train_step',\n",
    "                     feed_dict={\"x\":inputs, keep_prob: 0.5})\n",
    "    # `X` is used, it must be defined in the model with that name explicitly!\n",
    "    return [str(p) for p in predint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs= [\"/root/code/pic_png/8.png\"]\n",
    "predict3(sess,inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict2(sess, inputs):\n",
    "    plc = inputs[0]\n",
    "    preds = prediction.eval('prediction', \n",
    "                            feed_dict={'x:plc','keep_prob:1.0'},\n",
    "                            session=sess) \n",
    "    # `X` is used, it must be defined in the model with that name explicitly!\n",
    "    return [str(p) for p in preds]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict2(sess,[\"/root/code/8.jpg\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from clipper_admin import ClipperConnection, DockerContainerManager\n",
    "from clipper_admin.deployers.tensorflow import deploy_tensorflow_model\n",
    "clipper_conn = ClipperConnection(DockerContainerManager())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clipper_conn.start_clipper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clipper_conn.connect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clipper_conn.register_application(\n",
    "    name=\"mnist-app\", input_type=\"strings\", default_output=\"-1.0\", slo_micros=100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "deploy_tensorflow_model(\n",
    "    clipper_conn,\n",
    "    name=\"mnist-mod\",\n",
    "    version=1, # version 2 of the same model, `predict` endpoint will be updated \n",
    "    # automatically to the newest model version\n",
    "    input_type=\"strings\",\n",
    "    tf_sess_or_saved_model_path=sess,\n",
    "    func=prediction,\n",
    "    pkgs_to_install=['pillow'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clipper_conn.get_all_apps()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Link the model and the app\n",
    "clipper_conn.link_model_to_app(\n",
    "    app_name=\"mnist-app\",\n",
    "    model_name=\"mnist-mod\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get query address\n",
    "query_address = clipper_conn.get_query_addr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run a query\n",
    "import requests, json, numpy as np\n",
    "headers = {\"Content-type\": \"application/json\"}\n",
    "requests.post(\"http://\"+query_address+\"/mnist-app/predict\", headers=headers, data=json.dumps({\n",
    "    \"input\": [\"/root/code/3.jpg\",\"/root/code/0.jpg\",\"/root/code/8.jpg\"]})).json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "import json\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from PIL import Image, ImageFilter\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import requests\n",
    "\n",
    "def query_json(addr, filename, image_format):\n",
    "    url = \"http://%s/mnist-app/predict\" % addr\n",
    "    req_json = json.dumps({\n",
    "        \"input\":\n",
    "        json.dumps({\n",
    "            'data':[(255-x)*1.0/255.0 for x in list(Image.open(filename).convert('L').getdata())], \n",
    "            'format': image_format\n",
    "        })\n",
    "    })\n",
    "    headers = {'Content-type': 'application/json'}\n",
    "    r = requests.post(url, headers=headers, data=req_json)\n",
    "    print(r.json())\n",
    "    \n",
    "#数据处理还是不能成功预测 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "import json\n",
    "import requests\n",
    "def query_json(addr, filename, image_format):\n",
    "    url = \"http://%s/mnist-app/predict\" % addr\n",
    "    req_json = json.dumps({\n",
    "        \"input\":\n",
    "        json.dumps({\n",
    "            'data': base64.b64encode(open(filename, \"rb\").read()).decode(),\n",
    "            'format': image_format\n",
    "        })\n",
    "    })\n",
    "    headers = {'Content-type': 'application/json'}\n",
    "    r = requests.post(url, headers=headers, data=req_json)\n",
    "    print(r.json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_json(query_address, \"/root/code/3.png\", 'png')\n",
    "# 数据处理在请求之前 依然收不到正常预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clipper_conn.stop_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
