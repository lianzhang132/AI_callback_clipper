{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys,os\n",
    "sys.path.append(os.pardir)\n",
    "import numpy as np\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "from PIL import Image\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-2-5cd6f78f5484>:2: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/site-packages/tensorflow_core/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/site-packages/tensorflow_core/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/site-packages/tensorflow_core/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/site-packages/tensorflow_core/contrib/learn/python/learn/datasets/mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.one_hot on tensors.\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/site-packages/tensorflow_core/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "step 0, training accuracy 0.48\n",
      "step 1, training accuracy 0.61\n",
      "step 2, training accuracy 0.58\n",
      "step 3, training accuracy 0.52\n",
      "step 4, training accuracy 0.54\n",
      "step 5, training accuracy 0.51\n",
      "step 6, training accuracy 0.68\n",
      "step 7, training accuracy 0.69\n",
      "step 8, training accuracy 0.88\n",
      "step 9, training accuracy 0.71\n",
      "step 10, training accuracy 0.83\n",
      "step 11, training accuracy 0.73\n",
      "step 12, training accuracy 0.75\n",
      "step 13, training accuracy 0.82\n",
      "step 14, training accuracy 0.81\n",
      "step 15, training accuracy 0.89\n",
      "step 16, training accuracy 0.81\n",
      "step 17, training accuracy 0.82\n",
      "step 18, training accuracy 0.75\n",
      "step 19, training accuracy 0.79\n",
      "step 20, training accuracy 0.83\n",
      "step 21, training accuracy 0.89\n",
      "step 22, training accuracy 0.95\n",
      "step 23, training accuracy 0.9\n",
      "step 24, training accuracy 0.93\n",
      "step 25, training accuracy 0.83\n",
      "step 26, training accuracy 0.84\n",
      "step 27, training accuracy 0.81\n",
      "step 28, training accuracy 0.91\n",
      "step 29, training accuracy 0.9\n",
      "step 30, training accuracy 0.95\n",
      "step 31, training accuracy 0.91\n",
      "step 32, training accuracy 0.84\n",
      "step 33, training accuracy 0.94\n",
      "step 34, training accuracy 0.9\n",
      "step 35, training accuracy 0.85\n",
      "step 36, training accuracy 0.84\n",
      "step 37, training accuracy 0.91\n",
      "step 38, training accuracy 0.93\n",
      "step 39, training accuracy 0.83\n",
      "step 40, training accuracy 0.97\n",
      "step 41, training accuracy 0.81\n",
      "step 42, training accuracy 0.84\n",
      "step 43, training accuracy 0.94\n",
      "step 44, training accuracy 0.95\n",
      "step 45, training accuracy 0.93\n",
      "step 46, training accuracy 0.93\n",
      "step 47, training accuracy 0.87\n",
      "step 48, training accuracy 0.94\n",
      "step 49, training accuracy 0.91\n"
     ]
    }
   ],
   "source": [
    "def trainNet():\n",
    "    mnist = input_data.read_data_sets (\"MNIST_data/\", one_hot=True)\n",
    "    x = tf.placeholder (tf.float32, [None, 784], name='X')\n",
    "    W = tf.Variable (tf.zeros ([784, 10]),name=\"w\")\n",
    "    b = tf.Variable (tf.zeros ([10]),name=\"b\")\n",
    "    # Construct a linear model\n",
    "    y = tf.nn.softmax (tf.matmul (x, W) + b, name=\"pred\")\n",
    "    y_ = tf.placeholder (tf.float32, [None, 10])\n",
    "    keep_prob = tf.placeholder (tf.float32)\n",
    "    # 定义测试的准确率\n",
    "    correct_prediction = tf.equal (tf.argmax (y, 1), tf.argmax (y_, 1))\n",
    "    accuracy = tf.reduce_mean (tf.cast (correct_prediction, tf.float32))\n",
    "    #\n",
    "    saver = tf.train.Saver (max_to_keep=1)\n",
    "    max_acc = 0\n",
    "    train_accuracy = 0\n",
    "    #交叉熵\n",
    "    cross_entropy = tf.reduce_mean (-tf.reduce_sum (y_ * tf.log (y)))\n",
    "    # cross_error=cross_entropy_error_batch(y,y_)\n",
    "    train_step = tf.train.GradientDescentOptimizer (0.01).minimize (cross_entropy)\n",
    "    sess = tf.InteractiveSession ()\n",
    "    tf.global_variables_initializer ().run ()\n",
    "    for i in range (50):\n",
    "        batch_xs, batch_ys = mnist.train.next_batch (100)\n",
    "        sess.run (train_step, feed_dict={x: batch_xs, y_: batch_ys, keep_prob: 1.0})\n",
    "        train_accuracy = accuracy.eval (feed_dict={x: batch_xs, y_: batch_ys, keep_prob: 1.0})\n",
    "        print (\"step %d, training accuracy %g\" % (i, train_accuracy))\n",
    "        saver.save (sess, './mnist_model/mnist_100.ckpt')\n",
    "trainNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor_name:  b\n",
      "[-0.08864587  0.19907866 -0.03322526 -0.10384166  0.05253445  0.27046007\n",
      " -0.03096306  0.22740693 -0.4423793  -0.05042442]\n",
      "tensor_name:  w\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "# Total number of params: 7850\n"
     ]
    }
   ],
   "source": [
    "# import the inspect_checkpoint library\n",
    "from tensorflow.python.tools import inspect_checkpoint as chkp\n",
    "# print all tensors in checkpoint file\n",
    "chkp.print_tensors_in_checkpoint_file(\n",
    "    \"./mnist_model/mnist_100.ckpt\", tensor_name='', all_tensors=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X \n",
      "\n",
      "zeros/shape_as_tensor \n",
      "\n",
      "zeros/Const \n",
      "\n",
      "zeros \n",
      "\n",
      "w \n",
      "\n",
      "w/Assign \n",
      "\n",
      "w/read \n",
      "\n",
      "zeros_1 \n",
      "\n",
      "b \n",
      "\n",
      "b/Assign \n",
      "\n",
      "b/read \n",
      "\n",
      "MatMul \n",
      "\n",
      "add \n",
      "\n",
      "pred \n",
      "\n",
      "Placeholder \n",
      "\n",
      "Placeholder_1 \n",
      "\n",
      "ArgMax/dimension \n",
      "\n",
      "ArgMax \n",
      "\n",
      "ArgMax_1/dimension \n",
      "\n",
      "ArgMax_1 \n",
      "\n",
      "Equal \n",
      "\n",
      "Cast \n",
      "\n",
      "Const \n",
      "\n",
      "Mean \n",
      "\n",
      "save/filename/input \n",
      "\n",
      "save/filename \n",
      "\n",
      "save/Const \n",
      "\n",
      "save/SaveV2/tensor_names \n",
      "\n",
      "save/SaveV2/shape_and_slices \n",
      "\n",
      "save/SaveV2 \n",
      "\n",
      "save/control_dependency \n",
      "\n",
      "save/RestoreV2/tensor_names \n",
      "\n",
      "save/RestoreV2/shape_and_slices \n",
      "\n",
      "save/RestoreV2 \n",
      "\n",
      "save/Assign \n",
      "\n",
      "save/Assign_1 \n",
      "\n",
      "save/restore_all \n",
      "\n",
      "Log \n",
      "\n",
      "mul \n",
      "\n",
      "Const_1 \n",
      "\n",
      "Sum \n",
      "\n",
      "Neg \n",
      "\n",
      "Const_2 \n",
      "\n",
      "Mean_1 \n",
      "\n",
      "gradients/Shape \n",
      "\n",
      "gradients/grad_ys_0 \n",
      "\n",
      "gradients/Fill \n",
      "\n",
      "gradients/Mean_1_grad/Reshape/shape \n",
      "\n",
      "gradients/Mean_1_grad/Reshape \n",
      "\n",
      "gradients/Mean_1_grad/Const \n",
      "\n",
      "gradients/Mean_1_grad/Tile \n",
      "\n",
      "gradients/Mean_1_grad/Const_1 \n",
      "\n",
      "gradients/Mean_1_grad/truediv \n",
      "\n",
      "gradients/Neg_grad/Neg \n",
      "\n",
      "gradients/Sum_grad/Reshape/shape \n",
      "\n",
      "gradients/Sum_grad/Reshape \n",
      "\n",
      "gradients/Sum_grad/Shape \n",
      "\n",
      "gradients/Sum_grad/Tile \n",
      "\n",
      "gradients/mul_grad/Shape \n",
      "\n",
      "gradients/mul_grad/Shape_1 \n",
      "\n",
      "gradients/mul_grad/BroadcastGradientArgs \n",
      "\n",
      "gradients/mul_grad/Mul \n",
      "\n",
      "gradients/mul_grad/Sum \n",
      "\n",
      "gradients/mul_grad/Reshape \n",
      "\n",
      "gradients/mul_grad/Mul_1 \n",
      "\n",
      "gradients/mul_grad/Sum_1 \n",
      "\n",
      "gradients/mul_grad/Reshape_1 \n",
      "\n",
      "gradients/mul_grad/tuple/group_deps \n",
      "\n",
      "gradients/mul_grad/tuple/control_dependency \n",
      "\n",
      "gradients/mul_grad/tuple/control_dependency_1 \n",
      "\n",
      "gradients/Log_grad/Reciprocal \n",
      "\n",
      "gradients/Log_grad/mul \n",
      "\n",
      "gradients/pred_grad/mul \n",
      "\n",
      "gradients/pred_grad/Sum/reduction_indices \n",
      "\n",
      "gradients/pred_grad/Sum \n",
      "\n",
      "gradients/pred_grad/sub \n",
      "\n",
      "gradients/pred_grad/mul_1 \n",
      "\n",
      "gradients/add_grad/Shape \n",
      "\n",
      "gradients/add_grad/Shape_1 \n",
      "\n",
      "gradients/add_grad/BroadcastGradientArgs \n",
      "\n",
      "gradients/add_grad/Sum \n",
      "\n",
      "gradients/add_grad/Reshape \n",
      "\n",
      "gradients/add_grad/Sum_1 \n",
      "\n",
      "gradients/add_grad/Reshape_1 \n",
      "\n",
      "gradients/add_grad/tuple/group_deps \n",
      "\n",
      "gradients/add_grad/tuple/control_dependency \n",
      "\n",
      "gradients/add_grad/tuple/control_dependency_1 \n",
      "\n",
      "gradients/MatMul_grad/MatMul \n",
      "\n",
      "gradients/MatMul_grad/MatMul_1 \n",
      "\n",
      "gradients/MatMul_grad/tuple/group_deps \n",
      "\n",
      "gradients/MatMul_grad/tuple/control_dependency \n",
      "\n",
      "gradients/MatMul_grad/tuple/control_dependency_1 \n",
      "\n",
      "GradientDescent/learning_rate \n",
      "\n",
      "GradientDescent/update_w/ApplyGradientDescent \n",
      "\n",
      "GradientDescent/update_b/ApplyGradientDescent \n",
      "\n",
      "GradientDescent \n",
      "\n",
      "init \n",
      "\n"
     ]
    }
   ],
   "source": [
    "tensor_name_list = [tensor.name for tensor in tf.get_default_graph().as_graph_def().node]\n",
    "#print(tensor_name_list)\n",
    "for tensor_name in tensor_name_list:\n",
    "    print(tensor_name,'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ！！！不用这个！！！！\n",
    "def predict(sess, inputs):\n",
    "    #mnist = input_data.read_data_sets (\"MNIST_data/\", one_hot=True)\n",
    "    #meta_path = './mnist_model/mnist_100.ckpt.meta'\n",
    "    #model_path = './mnist_model/mnist_100.ckpt'    \n",
    "    #saver = tf.train.import_meta_graph (meta_path)\n",
    "    #saver.restore (sess, model_path)\n",
    "    #graph = tf.get_default_graph ()\n",
    "    #W = graph.get_tensor_by_name (\"w:0\")\n",
    "    #b = graph.get_tensor_by_name (\"b:0\")\n",
    "    #x = tf.placeholder (tf.float32, [None, 784])\n",
    "    #y = tf.nn.softmax (tf.matmul (x, W) + b)\n",
    "    #keep_prob = tf.placeholder (tf.float32)\n",
    "    batch_xs, batch_ys=mnist.train.next_batch (100)\n",
    "    one_img = batch_xs[0].reshape ((1, 784))\n",
    "    one_num = batch_ys[0].reshape ((1, 10))\n",
    "    temp = sess.run (y, feed_dict={x: one_img, keep_prob: 1.0})\n",
    "    b = sess.run (tf.argmax (temp, 1))\n",
    "    return str(b[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(sess, inputs):\n",
    "    # n = len(inputs)\n",
    "    file= open('/root/code/ZhouYY/inputs.txt', 'w')  \n",
    "    for fp in inputs:\n",
    "        file.write(str(fp))\n",
    "        file.write('\\n')\n",
    "    file.close()\n",
    "    preds = sess.run('pred:0', feed_dict={'X:0': np.array(inputs).reshape(1,-1)})\n",
    "    \n",
    "    # `X` is used, it must be defined in the model with that name explicitly!\n",
    "    return [float(0) for p in preds]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "1\n",
      "(1, 784)\n"
     ]
    }
   ],
   "source": [
    "sess = tf.Session ()\n",
    "\n",
    "inputs = list()\n",
    "mnist = input_data.read_data_sets (\"MNIST_data/\", one_hot=True)\n",
    "batch_xs, batch_ys=mnist.train.next_batch (100)\n",
    "one_img = batch_xs[0].reshape ((-1)) # (,784)\n",
    "inputs.append(list(one_img))\n",
    "print(len(inputs))\n",
    "inp = one_img.tolist()\n",
    "inp2 = np.array(inp).reshape(1,-1)\n",
    "print(inp2.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20-03-26:20:00:28 INFO     [docker_container_manager.py:184] [default-cluster] Starting managed Redis instance in Docker\n",
      "20-03-26:20:00:33 INFO     [docker_container_manager.py:276] [default-cluster] Metric Configuration Saved at /tmp/tmpau19roqu.yml\n",
      "20-03-26:20:00:34 INFO     [clipper_admin.py:162] [default-cluster] Clipper is running\n",
      "20-03-26:20:00:34 INFO     [clipper_admin.py:172] [default-cluster] Successfully connected to Clipper cluster at localhost:1337\n"
     ]
    }
   ],
   "source": [
    "from clipper_admin import ClipperConnection, DockerContainerManager\n",
    "from clipper_admin.deployers.tensorflow import deploy_tensorflow_model\n",
    "clipper_conn = ClipperConnection(DockerContainerManager())\n",
    "clipper_conn.start_clipper()\n",
    "clipper_conn.connect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20-03-26:20:00:36 INFO     [clipper_admin.py:236] [default-cluster] Application mnist-zyy was successfully registered\n"
     ]
    }
   ],
   "source": [
    "# Add an application with a name and an input type\n",
    "clipper_conn.register_application(\n",
    "    name=\"mnist-zyy\", input_type=\"floats\", \n",
    "    default_output=\"-1.0\", slo_micros=10000000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clipper_conn.get_all_apps()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clipper_conn.get_all_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20-03-26:20:00:40 INFO     [deployer_utils.py:41] Saving function to /tmp/tmpl7v5gmpaclipper\n",
      "20-03-26:20:00:40 INFO     [deployer_utils.py:51] Serialized and supplied predict function\n",
      "20-03-26:20:00:40 INFO     [tensorflow.py:264] TensorFlow model copied to: tfmodel \n",
      "20-03-26:20:00:40 INFO     [tensorflow.py:277] Using Python 3.6 base image\n",
      "20-03-26:20:00:40 INFO     [clipper_admin.py:534] [default-cluster] Building model Docker image with model data from /tmp/tmpl7v5gmpaclipper\n",
      "20-03-26:20:00:41 INFO     [clipper_admin.py:539] [default-cluster] Step 1/2 : FROM clipper/tf36-container:0.4.1\n",
      "20-03-26:20:00:41 INFO     [clipper_admin.py:539] [default-cluster]  ---> 3db42af800ff\n",
      "20-03-26:20:00:41 INFO     [clipper_admin.py:539] [default-cluster] Step 2/2 : COPY /tmp/tmpl7v5gmpaclipper /model/\n",
      "20-03-26:20:00:41 INFO     [clipper_admin.py:539] [default-cluster]  ---> 56a9b24941ae\n",
      "20-03-26:20:00:41 INFO     [clipper_admin.py:539] [default-cluster] Successfully built 56a9b24941ae\n",
      "20-03-26:20:00:41 INFO     [clipper_admin.py:539] [default-cluster] Successfully tagged default-cluster-mnist-zyy:1\n",
      "20-03-26:20:00:41 INFO     [clipper_admin.py:541] [default-cluster] Pushing model Docker image to default-cluster-mnist-zyy:1\n",
      "20-03-26:20:00:44 INFO     [docker_container_manager.py:409] [default-cluster] Found 0 replicas for mnist-zyy:1. Adding 1\n",
      "20-03-26:20:00:45 INFO     [clipper_admin.py:724] [default-cluster] Successfully registered model mnist-zyy:1\n",
      "20-03-26:20:00:45 INFO     [clipper_admin.py:642] [default-cluster] Done deploying model mnist-zyy:1.\n"
     ]
    }
   ],
   "source": [
    "deploy_tensorflow_model(\n",
    "    clipper_conn,\n",
    "    name=\"mnist-zyy\",\n",
    "    version=1,\n",
    "    input_type=\"floats\",\n",
    "    func=predict,\n",
    "    tf_sess_or_saved_model_path=\"/root/code/ZhouYY/mnist_model/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20-03-26:20:00:50 INFO     [clipper_admin.py:303] [default-cluster] Model mnist-zyy is now linked to application mnist-zyy\n"
     ]
    }
   ],
   "source": [
    "clipper_conn.link_model_to_app(\n",
    "    app_name=\"mnist-zyy\",\n",
    "    model_name=\"mnist-zyy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "localhost:1337\n"
     ]
    }
   ],
   "source": [
    "query_address = clipper_conn.get_query_addr()\n",
    "print(query_address)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'query_id': 0,\n",
       " 'output': -1.0,\n",
       " 'default': True,\n",
       " 'default_explanation': 'Failed to retrieve a prediction response within the specified latency SLO'}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests, json, numpy as np\n",
    "class NpEncoder(json.JSONEncoder):\n",
    "    def default(self, obj):\n",
    "        if isinstance(obj, np.integer):\n",
    "            return int(obj)\n",
    "        elif isinstance(obj, np.floating):\n",
    "            return float(obj)\n",
    "        elif isinstance(obj, np.ndarray):\n",
    "            return obj.tolist()\n",
    "        else:\n",
    "            return super(NpEncoder, self).default(obj)\n",
    "\n",
    "headers = {\"Content-type\": \"application/json\"}\n",
    "requests.post(\"http://\"+query_address+\"/mnist-zyy/predict\", \n",
    "              headers=headers, data=json.dumps({\"input\":one_img.tolist()})).json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clipper_conn.unlink_model_from_app('mnist-zyy','mnist-zyy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clipper_conn.get_all_apps()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clipper_conn.stop_inactive_model_versions('mnist-zyy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clipper_conn.get_all_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clipper_conn.delete_application('mnist-zyy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20-03-26:22:37:20 INFO     [clipper_admin.py:1424] [default-cluster] Stopped all Clipper cluster and all model containers\n"
     ]
    }
   ],
   "source": [
    "clipper_conn.stop_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
