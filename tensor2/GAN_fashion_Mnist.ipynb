{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.2\n",
      "gpu is  not AVAILABLE\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "print(\"gpu is \",\"available\"if tf.test.is_gpu_available() else  \"not AVAILABLE\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import PIL\n",
    "from tensorflow.keras  import layers\n",
    "import time \n",
    "import glob\n",
    "\n",
    "from IPython import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#使用fashion mnist 进行Gan 的训练 生成器类似于 fashion_mnist 的数据集\n",
    "fashion_mnist = tf.keras.datasets.fashion_mnist\n",
    "(train_images,train_labels),(test_images,test_labels)=fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = train_images.reshape(train_images.shape[0],28,28,1).astype('float32')\n",
    "train_images = (train_images -127.5)/127.5 #将图片标准化到【-1 ， 1】"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "buffer_size = 60000\n",
    "batch_size = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#批量化 和打乱数据\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices(train_images).shuffle(buffer_size).batch(batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_generator_model():\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(layers.Dense(7*7*256,use_bias=False,input_shape=(100,)))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.LeakyReLU())\n",
    "    \n",
    "    model.add(layers.Reshape((7,7,256)))\n",
    "    assert model.output_shape == (None,7,7,256)\n",
    "    \n",
    "    model.add(layers.Conv2DTranspose(128,(5,5),strides=(1,1),padding='same',use_bias=False))\n",
    "    assert model.output_shape == (None,7,7,128)\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.LeakyReLU())\n",
    "    \n",
    "    model.add(layers.Convolution2DTranspose(64,(5,5),strides=(2,2),padding='same',use_bias=False))\n",
    "    assert model.output_shape == (None,14,14,64)\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.LeakyReLU())\n",
    "    \n",
    "    model.add(layers.Convolution2DTranspose(1,(5,5),strides=(2,2),padding='same',use_bias=False,activation='tanh'))\n",
    "    assert model.output_shape == (None,28,28,1)\n",
    "    \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 12544)             1254400   \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 12544)             50176     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu (LeakyReLU)      (None, 12544)             0         \n",
      "_________________________________________________________________\n",
      "reshape (Reshape)            (None, 7, 7, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose (Conv2DTran (None, 7, 7, 128)         819200    \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 7, 7, 128)         512       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)    (None, 7, 7, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_1 (Conv2DTr (None, 14, 14, 64)        204800    \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 14, 14, 64)        256       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)    (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_2 (Conv2DTr (None, 28, 28, 1)         1600      \n",
      "=================================================================\n",
      "Total params: 2,330,944\n",
      "Trainable params: 2,305,472\n",
      "Non-trainable params: 25,472\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "generator = make_generator_model()\n",
    "generator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x16f5a780848>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "noise = tf.random.normal([1,100])\n",
    "generated_image = generator(noise,training=False)\n",
    "plt.imshow(generated_image[0,:,:,0],cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#构建判别器\n",
    "def make_discriminator_model():\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(layers.Conv2D(64,(5,5),strides=(2,2),padding='same',input_shape=[28,28,1]))\n",
    "    \n",
    "    model.add(layers.LeakyReLU())\n",
    "    model.add(layers.Dropout(0.3))\n",
    "    \n",
    "    \n",
    "    model.add(layers.Conv2D(128,(5,5),strides=(2,2),padding='same'))\n",
    "    model.add(layers.LeakyReLU())\n",
    "    model.add(layers.Dropout(0.3))\n",
    "    \n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(1))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 14, 14, 64)        1664      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)    (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 7, 7, 128)         204928    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_4 (LeakyReLU)    (None, 7, 7, 128)         0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 7, 7, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 6272)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 6273      \n",
      "=================================================================\n",
      "Total params: 212,865\n",
      "Trainable params: 212,865\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "discriminator = make_discriminator_model()\n",
    "discriminator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([[0.00119668]], shape=(1, 1), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "decision = discriminator(generated_image)\n",
    "print(decision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#判别器损失函数\n",
    "def discriminator_loss(real_output,fake_output):\n",
    "    #计算为真【【1】】和实际输出real_output的损失\n",
    "    real_loss = cross_entropy(tf.ones_like(real_output),real_output)\n",
    "    fake_loss = cross_entropy(tf.zeros_like(fake_output),fake_output)\n",
    "    total_loss = real_loss+fake_loss\n",
    "    return total_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#生成器损失函数\n",
    "def generator_loss(fake_output):\n",
    "    return cross_entropy(tf.ones_like(fake_output),fake_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator_optimizer = tf.keras.optimizers.Adam(1e-4)\n",
    "discriminator_optimizer = tf.keras.optimizers.Adam(1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#定义检查点文件\n",
    "checkpoint_dir = './training_checkpoints'\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir,'ckpt')\n",
    "\n",
    "checkpoint = tf.train.Checkpoint(generator_optimizer = generator_optimizer,\n",
    "                                discriminator_optimizer = discriminator_optimizer,\n",
    "                                 generator = generator,\n",
    "                                 discriminator = discriminator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#训练模型\n",
    "epochs = 5\n",
    "noise_dim = 100\n",
    "num_examples_to_generate = 16\n",
    "\n",
    "#产生随机种子\n",
    "#后面将重复使用该种子 （因此在动画gif中更容易可视化进度）\n",
    "seed = tf.random.normal([num_examples_to_generate,noise_dim])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#注意 tf.funtion 的使用 该注解函数  被编译为计算图模式\n",
    "@tf.function()\n",
    "def train_step(images):\n",
    "    noise  =  tf.random.normal([batch_size,noise_dim])\n",
    "    #tf.GradientTape()自动计算梯度的空间\n",
    "    with tf.GradientTape() as gen_tape , tf.GradientTape() as disc_tape:\n",
    "        generated_image = generator(noise,training=True)\n",
    "        \n",
    "        real_output = discriminator(images,training=True)\n",
    "        fake_output = discriminator(generated_image,training=True)\n",
    "        \n",
    "        gen_loss = generator_loss(fake_output)\n",
    "        disc_loss = discriminator_loss(real_output,fake_output)\n",
    "        \n",
    "    gradients_of_generator = gen_tape.gradient(gen_loss,generator.trainable_variables)\n",
    "    gradients_of_discriminator = disc_tape.gradient(disc_loss,discriminator.trainable_variables)\n",
    "    \n",
    "    \n",
    "    generator_optimizer.apply_gradients(zip(gradients_of_generator,generator.trainable_variables))\n",
    "    discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator,discriminator.trainable_variables))\n",
    "    \n",
    "    '''\n",
    "    训练在生成器接收到一个随机种子作为输入时开始，用于生产一张图片 判断器随后被用于区\n",
    "    分真实图片（选自训练集）和伪造图片（生成器生成）。针对这里的每一个模型都计算损失函数\n",
    "    并且计算梯度用于更新生成器与判别器\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_and_save_images(model,epoch,test_input):\n",
    "    #注意 training 设定为false\n",
    "    #因此 所有层都在推理模式下运行（batchnorm）\n",
    "    predictions = model(test_input,training = False)\n",
    "    \n",
    "    fig = plt.figure(figsize=(4,4))\n",
    "    \n",
    "    for i in range(predictions.shape[0]):\n",
    "        plt.subplot(4,4,i+1)\n",
    "        plt.imshow(predictions[i,:,:,0]*127.5+127.5,cmap='gray')\n",
    "        plt.axis('off')\n",
    "        \n",
    "        \n",
    "    plt.savefig('image_at_epoch_[:04d].png'.format(epoch))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataset,epochs):\n",
    "    for epoch in range(epochs):\n",
    "        start = time.time()\n",
    "        \n",
    "        for image_batch in dataset:\n",
    "            train_step(image_batch)\n",
    "        \n",
    "        #生成图片\n",
    "        display.clear_output(wait=True)\n",
    "        generate_and_save_images(generator,epoch+1,seed)\n",
    "        \n",
    "        #每 5 epochs 进行一次存储\n",
    "        if (epoch+1) % 5 ==0:\n",
    "            checkpoint.save(file_prefix=checkpoint_prefix)\n",
    "            \n",
    "        print('Time for epoch {} is {} sec'.format(epoch+1,time.time -start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UsageError: Can't use statement directly after '%%time'!\n"
     ]
    }
   ],
   "source": [
    "%%time #将会给出cellde 代码运行一次所花费的时间\n",
    "\n",
    "train(train_dataset,epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#恢复最新的检查点\n",
    "\n",
    "checkpoint.restore(tf.train.latest_checkpoint(checkpoint_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_image(epoch_no):\n",
    "    return PIL.Image.open('image_at_epoch_{:04d}.png'.format(epoch_no))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_image(epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#合成训练 过程产生图像的gif图\n",
    "import imageio\n",
    "anim_file = 'dcgan.gif'\n",
    "\n",
    "with imageio.get_writer(anim_file,model='I') as writer:\n",
    "    filenames = glob.glob('image*.png')\n",
    "    filenames = sorted(filenames)\n",
    "    last = -1\n",
    "    for i,filename in enumerate(filenames):\n",
    "        frame = 2*(i**0.5)\n",
    "        if round(frame) > round(last):\n",
    "            last = frame\n",
    "        else:\n",
    "            continue \n",
    "        image = imageio.imread(filename)\n",
    "        writer.append_data(image)\n",
    "        \n",
    "    image = imageio.imread(filename)\n",
    "    writer.append_data(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
