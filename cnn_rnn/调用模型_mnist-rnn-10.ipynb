{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-1-0fcde3bb405a>:8: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/site-packages/tensorflow_core/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/site-packages/tensorflow_core/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting /root/code/MNIST_data/train-images-idx3-ubyte.gz\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/site-packages/tensorflow_core/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting /root/code/MNIST_data/train-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/site-packages/tensorflow_core/contrib/learn/python/learn/datasets/mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.one_hot on tensors.\n",
      "Extracting /root/code/MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting /root/code/MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/site-packages/tensorflow_core/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From <ipython-input-1-0fcde3bb405a>:34: LSTMCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This class is equivalent as tf.keras.layers.LSTMCell, and will be replaced by that in Tensorflow 2.0.\n",
      "WARNING:tensorflow:From <ipython-input-1-0fcde3bb405a>:35: MultiRNNCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This class is equivalent as tf.keras.layers.StackedRNNCells, and will be replaced by that in Tensorflow 2.0.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/site-packages/tensorflow_core/python/ops/rnn_cell_impl.py:958: Layer.add_variable (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `layer.add_weight` method instead.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/site-packages/tensorflow_core/python/ops/rnn_cell_impl.py:962: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tf_rnn_10/model.ckpt\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "识别结果:\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "from datetime import datetime\n",
    "from PIL import Image, ImageFilter\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "#载入数据\n",
    "mnist = input_data.read_data_sets(\"/root/code/MNIST_data/\",one_hot=True)\n",
    "lr = 1e-3\n",
    "# 在训练和测试的时候，我们想用不同的 batch_size.所以采用占位符的方式\n",
    "keep_prob = tf.placeholder(tf.float32, [],name='keep_prob')\n",
    "batch_size = tf.placeholder(tf.int32, [],name='batch_size')\n",
    " \n",
    "# 每个时刻的输入特征是28维的，就是每个时刻输入一行，一行有 28 个像素\n",
    "input_size = 28\n",
    "# 时序持续长度为28，即每做一次预测，需要先输入28行\n",
    "timestep_size = 28\n",
    "# 每个隐含层的节点数\n",
    "hidden_size = 256\n",
    "# LSTM layer 的层数\n",
    "layer_num = 10\n",
    "# 最后输出分类类别数量，如果是回归预测的话应该是 1\n",
    "class_num = 10\n",
    "\n",
    "\n",
    "\n",
    "_X = tf.placeholder(tf.float32, [None, 784],name='x')\n",
    "y = tf.placeholder(tf.float32, [None, class_num],name='y')\n",
    "\n",
    "X = tf.reshape(_X, [-1, 28, 28])\n",
    "\n",
    "stacked_rnn = []\n",
    "for iiLyr in range(layer_num):\n",
    "    stacked_rnn.append(tf.nn.rnn_cell.LSTMCell(num_units=hidden_size, state_is_tuple=True))\n",
    "mlstm_cell = tf.nn.rnn_cell.MultiRNNCell(cells=stacked_rnn, state_is_tuple=True)\n",
    "init_state = mlstm_cell.zero_state(batch_size, dtype=tf.float32)\n",
    "\n",
    "outputs = list()\n",
    "state = init_state\n",
    "with tf.variable_scope('RNN'):\n",
    "    for timestep in range(timestep_size):\n",
    "        if timestep > 0:\n",
    "            tf.get_variable_scope().reuse_variables()\n",
    "        # 这里的state保存了每一层 LSTM 的状态\n",
    "        (cell_output, state) = mlstm_cell(X[:, timestep, :], state)\n",
    "        outputs.append(cell_output)\n",
    "h_state = outputs[-1]\n",
    "\n",
    "W = tf.Variable(tf.truncated_normal([hidden_size, class_num], stddev=0.1), dtype=tf.float32)\n",
    "bias = tf.Variable(tf.constant(0.1,shape=[class_num]), dtype=tf.float32)\n",
    "y_pre = tf.nn.softmax(tf.matmul(h_state, W) + bias,name=\"result\")\n",
    "\n",
    "# 损失和评估函数\n",
    "cross_entropy = -tf.reduce_mean(y * tf.log(y_pre))\n",
    "train_op = tf.train.AdamOptimizer(lr).minimize(cross_entropy)\n",
    " \n",
    "correct_prediction = tf.equal(tf.argmax(y_pre,1), tf.argmax(y,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
    "\n",
    "\n",
    "saver = tf.train.Saver()\n",
    "sess = tf.Session()\n",
    "\n",
    "sess.run(tf.global_variables_initializer())\n",
    "saver.restore(sess, '/tmp/tf_rnn_10/model.ckpt') #使用模型，参数和之前的代码保持一致\n",
    "\n",
    "prediction=tf.argmax(y_pre,1)\n",
    "im = Image.open('/root/code/pic_png/3.png') #读取的图片所在路径，注意是28*28像素\n",
    "plt.imshow(im)  #显示需要识别的图片\n",
    "plt.show()\n",
    "im = im.convert('L')\n",
    "tv = list(im.getdata()) \n",
    "tva = [(255-x)*1.0/255.0 for x in tv]\n",
    "predint=prediction.eval(feed_dict={_X: [tva],keep_prob: 1.0,batch_size: 1}, session=sess)\n",
    "#TypeError: eval() got an unexpected keyword argument 'name' 这是不是代表 sess.run的函数方式行不通了\n",
    "print('识别结果:')\n",
    "print(predint[0])\n",
    "#用了函数处理 图像数据 所以用x:【result】"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict10(sess, adds):\n",
    "    import json\n",
    "    num_imgs = len(adds)\n",
    "    result = []\n",
    "    for i in range(num_imgs):\n",
    "        data = json.loads(adds[i])\n",
    "        predints=sess.run('result:0',feed_dict={\"x:0\":data,\"keep_prob:0\": 1.0,'batch_size:0':1})\n",
    "        result.append(str(predints[0]))\n",
    "    \n",
    "    return result\n",
    "# predict9(sess,tva_c) 成功预测 并部署通过 数据处理可得到 预测结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from clipper_admin import ClipperConnection, DockerContainerManager\n",
    "from clipper_admin.deployers.tensorflow import deploy_tensorflow_model\n",
    "clipper_conn = ClipperConnection(DockerContainerManager())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20-05-11:05:52:14 INFO     [docker_container_manager.py:184] [default-cluster] Starting managed Redis instance in Docker\n",
      "20-05-11:05:52:19 INFO     [docker_container_manager.py:276] [default-cluster] Metric Configuration Saved at /tmp/tmpt73ijjeu.yml\n",
      "20-05-11:05:52:20 INFO     [clipper_admin.py:162] [default-cluster] Clipper is running\n"
     ]
    }
   ],
   "source": [
    "clipper_conn.start_clipper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20-05-11:05:52:21 INFO     [clipper_admin.py:172] [default-cluster] Successfully connected to Clipper cluster at localhost:1337\n"
     ]
    }
   ],
   "source": [
    "clipper_conn.connect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20-05-11:05:52:26 INFO     [clipper_admin.py:236] [default-cluster] Application mnist_rnn-app was successfully registered\n"
     ]
    }
   ],
   "source": [
    "clipper_conn.register_application(\n",
    "    name=\"mnist_rnn-app\", input_type=\"strings\", default_output=\"-1.0\", slo_micros=100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20-05-11:05:52:27 INFO     [deployer_utils.py:41] Saving function to /tmp/tmpfp0f_a91clipper\n",
      "20-05-11:05:52:27 INFO     [deployer_utils.py:51] Serialized and supplied predict function\n",
      "20-05-11:05:52:31 INFO     [tensorflow.py:196] TensorFlow model saved at: /tmp/tmpfp0f_a91clipper/tfmodel/model.ckpt \n",
      "20-05-11:05:52:31 INFO     [tensorflow.py:277] Using Python 3.6 base image\n",
      "20-05-11:05:52:32 INFO     [clipper_admin.py:534] [default-cluster] Building model Docker image with model data from /tmp/tmpfp0f_a91clipper\n",
      "20-05-11:05:52:34 INFO     [clipper_admin.py:539] [default-cluster] Step 1/2 : FROM clipper/tf36-container:0.4.1\n",
      "20-05-11:05:52:34 INFO     [clipper_admin.py:539] [default-cluster]  ---> 3db42af800ff\n",
      "20-05-11:05:52:34 INFO     [clipper_admin.py:539] [default-cluster] Step 2/2 : COPY /tmp/tmpfp0f_a91clipper /model/\n",
      "20-05-11:05:52:34 INFO     [clipper_admin.py:539] [default-cluster]  ---> 05bd89eefd95\n",
      "20-05-11:05:52:34 INFO     [clipper_admin.py:539] [default-cluster] Successfully built 05bd89eefd95\n",
      "20-05-11:05:52:34 INFO     [clipper_admin.py:539] [default-cluster] Successfully tagged default-cluster-mnist-rnn-mod:1\n",
      "20-05-11:05:52:34 INFO     [clipper_admin.py:541] [default-cluster] Pushing model Docker image to default-cluster-mnist-rnn-mod:1\n",
      "20-05-11:05:52:40 INFO     [docker_container_manager.py:409] [default-cluster] Found 0 replicas for mnist-rnn-mod:1. Adding 1\n",
      "20-05-11:05:52:41 INFO     [clipper_admin.py:724] [default-cluster] Successfully registered model mnist-rnn-mod:1\n",
      "20-05-11:05:52:41 INFO     [clipper_admin.py:642] [default-cluster] Done deploying model mnist-rnn-mod:1.\n"
     ]
    }
   ],
   "source": [
    "deploy_tensorflow_model(\n",
    "    clipper_conn,\n",
    "    name=\"mnist-rnn-mod\",\n",
    "    version=1, # version 2 of the same model, `predict` endpoint will be updated \n",
    "    # automatically to the newest model version\n",
    "    input_type=\"strings\",\n",
    "     func=predict10,\n",
    "    tf_sess_or_saved_model_path=sess,\n",
    "   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.client.session.Session at 0x7f8f24077c88>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20-05-11:05:52:47 INFO     [clipper_admin.py:303] [default-cluster] Model mnist-rnn-mod is now linked to application mnist_rnn-app\n"
     ]
    }
   ],
   "source": [
    "# Link the model and the app\n",
    "clipper_conn.link_model_to_app(\n",
    "    app_name=\"mnist_rnn-app\",\n",
    "    model_name=\"mnist-rnn-mod\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "localhost:1337\n"
     ]
    }
   ],
   "source": [
    "# Get query address\n",
    "query_address = clipper_conn.get_query_addr()\n",
    "print(query_address)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import base64\n",
    "import json\n",
    "import requests\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "\n",
    "def query_json(addr, filename,mnist,sess):\n",
    "    url = \"http://%s/mnist_rnn-app/predict\" % addr\n",
    "\n",
    "    im = Image.open(filename)\n",
    "    plt.imshow(im)  #显示需要识别的图片\n",
    "    plt.show()\n",
    "    im = im.convert('L')\n",
    "    tv = list(im.getdata())\n",
    "    tva = [[(255-x)*1.0/255.0 for x in tv]]\n",
    "    tva = json.dumps(tva)\n",
    "    tva_j = json.dumps({\"input\": tva})\n",
    "    headers = {'Content-type': 'application/json'}\n",
    "    start = datetime.now()\n",
    "    r = requests.post(url, headers=headers, data=tva_j)\n",
    "    end = datetime.now()\n",
    "    latency = (end - start).total_seconds() * 1000.0\n",
    "    re = r.text\n",
    "    global false, null, true\n",
    "\n",
    "    false = null = true = ''\n",
    "    ls = eval(re)\n",
    "    numbers = ls['output']\n",
    "    numbers_str = numbers[1:-1]\n",
    "    numbers_str=numbers_str.replace(\"\\n\", \"\")\n",
    "    list1 = numbers_str.split(' ')\n",
    "    print(\"this number is \"+ str(list1.index(max(list1)))+\" , \"+\"The latency is   \"+str(latency))\n",
    "    train_accuracy = sess.run(accuracy, feed_dict={\n",
    "            _X:mnist.test.images, y: mnist.test.labels, keep_prob: 1.0, batch_size: 10000})\n",
    "    print(\" test accuracy %g\" % ( train_accuracy))\n",
    "    return (list1.index(max(list1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /root/code/MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting /root/code/MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting /root/code/MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting /root/code/MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this number is 8 , The latency is   6.87\n",
      " test accuracy 0.9841\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets('/root/code/MNIST_data/', one_hot=True) \n",
    "query_json(query_address, \"/root/code/pic_png/8.png\",mnist,sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20-05-11:05:54:36 INFO     [clipper_admin.py:1424] [default-cluster] Stopped all Clipper cluster and all model containers\n"
     ]
    }
   ],
   "source": [
    "clipper_conn.stop_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
