{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-1-272e1a94ed5d>:5: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/site-packages/tensorflow_core/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/site-packages/tensorflow_core/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/site-packages/tensorflow_core/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/site-packages/tensorflow_core/contrib/learn/python/learn/datasets/mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.one_hot on tensors.\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/site-packages/tensorflow_core/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From <ipython-input-1-272e1a94ed5d>:29: BasicLSTMCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This class is equivalent as tf.keras.layers.LSTMCell, and will be replaced by that in Tensorflow 2.0.\n",
      "WARNING:tensorflow:From <ipython-input-1-272e1a94ed5d>:32: dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `keras.layers.RNN(cell)`, which is equivalent to this API\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/site-packages/tensorflow_core/python/ops/rnn_cell_impl.py:735: Layer.add_variable (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `layer.add_weight` method instead.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/site-packages/tensorflow_core/python/ops/rnn_cell_impl.py:739: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From <ipython-input-1-272e1a94ed5d>:40: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
      "\n",
      "Iter0,testing accuracy=0.818\n",
      "Iter1,testing accuracy=0.8827\n",
      "Iter2,testing accuracy=0.9077\n",
      "Iter3,testing accuracy=0.9124\n",
      "Iter4,testing accuracy=0.929\n",
      "Iter5,testing accuracy=0.9372\n",
      "Iter6,testing accuracy=0.9432\n",
      "Iter7,testing accuracy=0.9465\n",
      "Iter8,testing accuracy=0.9474\n",
      "Iter9,testing accuracy=0.9501\n",
      "Iter10,testing accuracy=0.9513\n",
      "Iter11,testing accuracy=0.9553\n",
      "Iter12,testing accuracy=0.9582\n",
      "Iter13,testing accuracy=0.9561\n",
      "Iter14,testing accuracy=0.9555\n",
      "Iter15,testing accuracy=0.9638\n",
      "Iter16,testing accuracy=0.9626\n",
      "Iter17,testing accuracy=0.964\n",
      "Iter18,testing accuracy=0.9659\n",
      "Iter19,testing accuracy=0.9653\n",
      "Iter20,testing accuracy=0.9645\n",
      "Iter21,testing accuracy=0.9656\n",
      "Iter22,testing accuracy=0.9645\n",
      "Iter23,testing accuracy=0.9652\n",
      "Iter24,testing accuracy=0.9659\n",
      "Iter25,testing accuracy=0.9682\n",
      "Iter26,testing accuracy=0.969\n",
      "Iter27,testing accuracy=0.9687\n",
      "Iter28,testing accuracy=0.9701\n",
      "Iter29,testing accuracy=0.9706\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf \n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "#载入数据\n",
    "mnist = input_data.read_data_sets(\"/root/code/MNIST_data/\",one_hot=True)\n",
    "#载入图片是 28*28\n",
    "n_inputs = 28 #输入一共28行\n",
    "max_time = 28 #一共28行\n",
    "lstm_size = 100#隐层单元 block\n",
    "n_classes = 10 #10个分类\n",
    "batch_size = 50 #每批次50个样本\n",
    "n_batch = mnist.train.num_examples//batch_size #计算一共有多少批次\n",
    "\n",
    "#这里的none 表示第一维度可以为任意长度\n",
    "x = tf.placeholder(tf.float32,[None,784],name='x')\n",
    "#正确的标签\n",
    "y = tf.placeholder(tf.float32,[None,10],name='y')\n",
    "\n",
    "#初始化权重\n",
    "weights = tf.Variable(tf.truncated_normal([lstm_size,n_classes],stddev=0.1))\n",
    "#初始化偏置\n",
    "biases =tf.Variable(tf.constant(0.1,shape=[n_classes]))\n",
    "\n",
    "#定义run网络\n",
    "def RUN(X,weights,biases,re_name):\n",
    "    # inputs = [batch_size,max_time,n_inputs]\n",
    "    inputs = tf.reshape(X,[-1,max_time,n_inputs])\n",
    "    #定义LSTM基本CELL\n",
    "    \"\"\"\n",
    "    tf.nn.rnn_cell.BasicLSTMCell(n_hidden, forget_bias=1.0, state_is_tuple=True): \n",
    "    n_hidden表示神经元的个数，\n",
    "    forget_bias就是LSTM们的忘记系数，默认为1，如果等于1，就是不会忘记任何信息。如果等于0，就都忘记。\n",
    "    state_is_tuple默认就是True，官方建议用True，就是表示返回的状态用一个元祖表示。\n",
    "    这个里面存在一个状态初始化函数，就是zero_state（batch_size，dtype）两个参数。\n",
    "    batch_size就是输入样本批次的数目，\n",
    "    dtype就是数据类型。\n",
    "    \"\"\"\n",
    "    lstm_cell = tf.nn.rnn_cell.BasicLSTMCell(lstm_size)\n",
    "    #final_state[0]是cell state\n",
    "    #final_state[1]是hidden state\n",
    "    \"\"\"\n",
    "    tf.nn.dynamic_rnn(cell,inputs,sequence_length=None,initial_state=None,dtype=None,parallel_iterations=None,swap_memory=False,\n",
    "    time_major=False,scope=None )\n",
    "    cell: RNNCell的一个实例.\n",
    "\n",
    "inputs: RNN输入.\n",
    "\n",
    "如果time_major == False(默认), 则是一个shape为[batch_size, max_time, input_size]的Tensor,或者这些元素的嵌套元组。\n",
    "\n",
    "如果time_major == True,则是一个shape为[max_time, batch_size, input_size]的Tensor,或这些元素的嵌套元组。\n",
    "\n",
    "sequence_length: (可选）大小为[batch_size],数据的类型是int32/int64向量。如果当前时间步的index超过该序列的实际长度时，\n",
    "则该时间步不进行计算，RNN的state复制上一个时间步的，同时该时间步的输出全部为零。\n",
    "\n",
    "initial_state: (可选)RNN的初始state(状态)。如果cell.state_size(一层的RNNCell)是一个整数，\n",
    "那么它必须是一个具有适当类型和形状的张量[batch_size，cell.state_size]。如果cell.state_size是一个元组(多层的RNNCell,如MultiRNNCell)，\n",
    "那么它应该是一个张量元组，每个元素的形状为[batch_size，s] for s in cell.state_size。\n",
    "\n",
    "time_major: inputs 和outputs 张量的形状格式。如果为True，则这些张量都应该是（都会是）[max_time, batch_size, depth]。\n",
    "如果为false，则这些张量都应该是（都会是）[batch_size，max_time, depth]。time_major=true说明输入和输出tensor的第一维是max_time。\n",
    "否则为batch_size。\n",
    "\n",
    "使用time_major =True更有效,因为它避免了RNN计算开始和结束时的转置.但是,大多数TensorFlow数据都是batch-major,因此默认情况下,\n",
    "此函数接受输入并以batch-major形式发出输出.\n",
    "\n",
    "返回值：\n",
    "\n",
    "一对(outputs, state),其中：\n",
    "\n",
    "outputs： RNN输出Tensor.\n",
    "\n",
    "如果time_major == False(默认),这将是shape为[batch_size, max_time, cell.output_size]的Tensor.\n",
    "\n",
    "如果time_major == True,这将是shape为[max_time, batch_size, cell.output_size]的Tensor.\n",
    "\n",
    "state： 最终的状态.\n",
    "\n",
    "一般情况下state的形状为 [batch_size, cell.output_size ]\n",
    "\n",
    "如果cell是LSTMCells,则state将是包含每个单元格的LSTMStateTuple的元组，state的形状为[2，batch_size, cell.output_size ]\n",
    "\n",
    "    \"\"\"\n",
    "    outputs,final_state = tf.nn.dynamic_rnn(lstm_cell,inputs,dtype=tf.float32)\n",
    "    results = tf.nn.softmax(tf.matmul(final_state[1],weights)+biases,name=re_name)\n",
    "    return results\n",
    "\n",
    "#计算RUN的返回结果\n",
    "result = \"result\"\n",
    "prediction = RUN(x,weights,biases,result)\n",
    "#损失函数\n",
    "cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=prediction,labels =y))\n",
    "#使用Adamoptimizer进行优化\n",
    "train_step = tf.train.AdamOptimizer(1e-4).minimize(cross_entropy)\n",
    "#结果存放在一个布尔型列表中\n",
    "correct_prediction= tf.equal(tf.argmax(y,1),tf.argmax(prediction,1))\n",
    "#求准确率\n",
    "\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction,tf.float32))\n",
    "\n",
    "saver = tf.train.Saver() #定义saver\n",
    "\n",
    "\n",
    "#初始化\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    for epoch in range(30):\n",
    "        for batch in range(n_batch):\n",
    "            batch_xs,batch_ys =mnist.train.next_batch(batch_size)\n",
    "            sess.run(train_step,feed_dict={x:batch_xs,y:batch_ys})\n",
    "            \n",
    "        acc = sess.run(accuracy,feed_dict={x:mnist.test.images,y:mnist.test.labels})\n",
    "        print(\"Iter\"+str(epoch)+\",testing accuracy=\"+ str(acc))\n",
    "    \n",
    "    saver.save(sess, '/tmp/tf_rnn/model.ckpt') #模型储存位置\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
