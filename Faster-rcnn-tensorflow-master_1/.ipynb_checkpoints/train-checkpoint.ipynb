{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/pandas/compat/__init__.py:117: UserWarning: Could not import the lzma module. Your installed Python is incomplete. Attempting to use lzma compression will result in a RuntimeError.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:\n",
      "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "WARNING:tensorflow:From /root/code/Faster-rcnn-tensorflow-master_1/network.py:28: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /root/code/Faster-rcnn-tensorflow-master_1/network.py:104: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/site-packages/tensorflow_core/contrib/layers/python/layers/layers.py:1057: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `layer.__call__` method instead.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/site-packages/tfplot/ops.py:114: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "tf.py_func is deprecated in TF V2. Instead, there are two\n",
      "    options available in V2.\n",
      "    - tf.py_function takes a python function which manipulates tf eager\n",
      "    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to\n",
      "    an ndarray (just call tensor.numpy()) but having access to eager tensors\n",
      "    means `tf.py_function`s can use accelerators such as GPUs as well as\n",
      "    being differentiable using a gradient tape.\n",
      "    - tf.numpy_function maintains the semantics of the deprecated tf.py_func\n",
      "    (it is not differentiable, and manipulates numpy arrays). It drops the\n",
      "    stateful argument making all functions stateful.\n",
      "    \n",
      "WARNING:tensorflow:From /root/code/Faster-rcnn-tensorflow-master_1/network.py:192: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.cast` instead.\n",
      "WARNING:tensorflow:From /root/code/Faster-rcnn-tensorflow-master_1/network.py:64: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.cast` instead.\n",
      "WARNING:tensorflow:From /root/code/Faster-rcnn-tensorflow-master_1/network.py:247: calling crop_and_resize_v1 (from tensorflow.python.ops.image_ops_impl) with box_ind is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "box_ind is deprecated, use box_indices instead\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/site-packages/tensorflow_core/contrib/layers/python/layers/layers.py:1634: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.flatten instead.\n",
      "WARNING:tensorflow:From /root/code/Faster-rcnn-tensorflow-master_1/network.py:266: The name tf.summary.image is deprecated. Please use tf.compat.v1.summary.image instead.\n",
      "\n",
      "WARNING:tensorflow:From /root/code/Faster-rcnn-tensorflow-master_1/losslayer.py:26: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "Loading gt_labels from: annotation_cache/VOC2007_trainval/pascal_train_gt_labels.pkl\n",
      "Appending horizontally-flipped training examples ...\n",
      "Loading gt_labels from: annotation_cache/VOC2007_test/pascal_test_gt_labels.pkl\n",
      "start training\n",
      "WARNING:tensorflow:From /root/code/Faster-rcnn-tensorflow-master_1/losslayer.py:99: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "reg\n",
      "Tensor(\"Sum:0\", shape=(), dtype=float32)\n",
      "WARNING:tensorflow:From /root/code/Faster-rcnn-tensorflow-master_1/losslayer.py:120: The name tf.summary.scalar is deprecated. Please use tf.compat.v1.summary.scalar instead.\n",
      "\n",
      "vgg_16/conv1/conv1_1/weights:0\n",
      "vgg_16/conv1/conv1_1/biases:0\n",
      "vgg_16/conv1/conv1_2/weights:0\n",
      "vgg_16/conv1/conv1_2/biases:0\n",
      "vgg_16/conv2/conv2_1/weights:0\n",
      "vgg_16/conv2/conv2_1/biases:0\n",
      "vgg_16/conv2/conv2_2/weights:0\n",
      "vgg_16/conv2/conv2_2/biases:0\n",
      "vgg_16/conv3/conv3_1/weights:0\n",
      "vgg_16/conv3/conv3_1/biases:0\n",
      "vgg_16/conv3/conv3_2/weights:0\n",
      "vgg_16/conv3/conv3_2/biases:0\n",
      "vgg_16/conv3/conv3_3/weights:0\n",
      "vgg_16/conv3/conv3_3/biases:0\n",
      "vgg_16/conv4/conv4_1/weights:0\n",
      "vgg_16/conv4/conv4_1/biases:0\n",
      "vgg_16/conv4/conv4_2/weights:0\n",
      "vgg_16/conv4/conv4_2/biases:0\n",
      "vgg_16/conv4/conv4_3/weights:0\n",
      "vgg_16/conv4/conv4_3/biases:0\n",
      "vgg_16/conv5/conv5_1/weights:0\n",
      "vgg_16/conv5/conv5_1/biases:0\n",
      "vgg_16/conv5/conv5_2/weights:0\n",
      "vgg_16/conv5/conv5_2/biases:0\n",
      "vgg_16/conv5/conv5_3/weights:0\n",
      "vgg_16/conv5/conv5_3/biases:0\n",
      "rpn/conv6/weights:0\n",
      "rpn/conv6/biases:0\n",
      "rpn/conv7/weights:0\n",
      "rpn/conv7/biases:0\n",
      "rpn/conv8/weights:0\n",
      "rpn/conv8/biases:0\n",
      "vgg_16/fc6/weights:0\n",
      "vgg_16/fc6/biases:0\n",
      "vgg_16/fc7/weights:0\n",
      "vgg_16/fc7/biases:0\n",
      "vgg_16/region_deciton/cls_score/weights:0\n",
      "vgg_16/region_deciton/cls_score/biases:0\n",
      "vgg_16/region_deciton/bbox_pred/weights:0\n",
      "vgg_16/region_deciton/bbox_pred/biases:0\n",
      "Variable:0\n",
      "vgg_16/conv3/conv3_1/weights/Momentum:0\n",
      "vgg_16/conv3/conv3_1/biases/Momentum:0\n",
      "vgg_16/conv3/conv3_2/weights/Momentum:0\n",
      "vgg_16/conv3/conv3_2/biases/Momentum:0\n",
      "vgg_16/conv3/conv3_3/weights/Momentum:0\n",
      "vgg_16/conv3/conv3_3/biases/Momentum:0\n",
      "vgg_16/conv4/conv4_1/weights/Momentum:0\n",
      "vgg_16/conv4/conv4_1/biases/Momentum:0\n",
      "vgg_16/conv4/conv4_2/weights/Momentum:0\n",
      "vgg_16/conv4/conv4_2/biases/Momentum:0\n",
      "vgg_16/conv4/conv4_3/weights/Momentum:0\n",
      "vgg_16/conv4/conv4_3/biases/Momentum:0\n",
      "vgg_16/conv5/conv5_1/weights/Momentum:0\n",
      "vgg_16/conv5/conv5_1/biases/Momentum:0\n",
      "vgg_16/conv5/conv5_2/weights/Momentum:0\n",
      "vgg_16/conv5/conv5_2/biases/Momentum:0\n",
      "vgg_16/conv5/conv5_3/weights/Momentum:0\n",
      "vgg_16/conv5/conv5_3/biases/Momentum:0\n",
      "rpn/conv6/weights/Momentum:0\n",
      "rpn/conv6/biases/Momentum:0\n",
      "rpn/conv7/weights/Momentum:0\n",
      "rpn/conv7/biases/Momentum:0\n",
      "rpn/conv8/weights/Momentum:0\n",
      "rpn/conv8/biases/Momentum:0\n",
      "vgg_16/fc6/weights/Momentum:0\n",
      "vgg_16/fc6/biases/Momentum:0\n",
      "vgg_16/fc7/weights/Momentum:0\n",
      "vgg_16/fc7/biases/Momentum:0\n",
      "vgg_16/region_deciton/cls_score/weights/Momentum:0\n",
      "vgg_16/region_deciton/cls_score/biases/Momentum:0\n",
      "vgg_16/region_deciton/bbox_pred/weights/Momentum:0\n",
      "vgg_16/region_deciton/bbox_pred/biases/Momentum:0\n",
      "INFO:tensorflow:Restoring parameters from model_pretrained/vgg_16.ckpt\n",
      "Fix VGG16 layers..\n",
      "INFO:tensorflow:Restoring parameters from model_pretrained/vgg_16.ckpt\n",
      "这是啥 dataset/VOCdevkit/VOC2007_trainval/JPEGImages/001998.jpg\n",
      "这是啥类型 <class 'str'>\n",
      "这是啥 dataset/VOCdevkit/VOC2007_test/JPEGImages/000001.jpg\n",
      "这是啥类型 <class 'str'>\n",
      "The 0 step train_total_loss is 4.2880526 val_total_loss is 4.3401427\n",
      "learning_rate is  0.001\n",
      "这是啥 dataset/VOCdevkit/VOC2007_trainval/JPEGImages/009304.jpg\n",
      "这是啥类型 <class 'str'>\n",
      "这是啥 dataset/VOCdevkit/VOC2007_trainval/JPEGImages/009280.jpg\n",
      "这是啥类型 <class 'str'>\n",
      "这是啥 dataset/VOCdevkit/VOC2007_trainval/JPEGImages/005581.jpg\n",
      "这是啥类型 <class 'str'>\n",
      "这是啥 dataset/VOCdevkit/VOC2007_trainval/JPEGImages/007818.jpg\n",
      "这是啥类型 <class 'str'>\n",
      "这是啥 dataset/VOCdevkit/VOC2007_trainval/JPEGImages/001869.jpg\n",
      "这是啥类型 <class 'str'>\n",
      "这是啥 dataset/VOCdevkit/VOC2007_trainval/JPEGImages/009906.jpg\n",
      "这是啥类型 <class 'str'>\n",
      "这是啥 dataset/VOCdevkit/VOC2007_trainval/JPEGImages/001317.jpg\n",
      "这是啥类型 <class 'str'>\n",
      "这是啥 dataset/VOCdevkit/VOC2007_trainval/JPEGImages/004101.jpg\n",
      "这是啥类型 <class 'str'>\n",
      "这是啥 dataset/VOCdevkit/VOC2007_trainval/JPEGImages/001694.jpg\n",
      "这是啥类型 <class 'str'>\n",
      "这是啥 dataset/VOCdevkit/VOC2007_trainval/JPEGImages/001656.jpg\n",
      "这是啥类型 <class 'str'>\n",
      "这是啥 dataset/VOCdevkit/VOC2007_trainval/JPEGImages/006168.jpg\n",
      "这是啥类型 <class 'str'>\n",
      "这是啥 dataset/VOCdevkit/VOC2007_trainval/JPEGImages/002930.jpg\n",
      "这是啥类型 <class 'str'>\n",
      "这是啥 dataset/VOCdevkit/VOC2007_trainval/JPEGImages/006388.jpg\n",
      "这是啥类型 <class 'str'>\n",
      "这是啥 dataset/VOCdevkit/VOC2007_trainval/JPEGImages/008321.jpg\n",
      "这是啥类型 <class 'str'>\n",
      "这是啥 dataset/VOCdevkit/VOC2007_trainval/JPEGImages/006087.jpg\n",
      "这是啥类型 <class 'str'>\n",
      "这是啥 dataset/VOCdevkit/VOC2007_trainval/JPEGImages/008039.jpg\n",
      "这是啥类型 <class 'str'>\n",
      "这是啥 dataset/VOCdevkit/VOC2007_trainval/JPEGImages/001850.jpg\n",
      "这是啥类型 <class 'str'>\n",
      "这是啥 dataset/VOCdevkit/VOC2007_trainval/JPEGImages/004608.jpg\n",
      "这是啥类型 <class 'str'>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "这是啥 dataset/VOCdevkit/VOC2007_trainval/JPEGImages/004615.jpg\n",
      "这是啥类型 <class 'str'>\n",
      "这是啥 dataset/VOCdevkit/VOC2007_trainval/JPEGImages/007041.jpg\n",
      "这是啥类型 <class 'str'>\n",
      "这是啥 dataset/VOCdevkit/VOC2007_trainval/JPEGImages/001942.jpg\n",
      "这是啥类型 <class 'str'>\n",
      "这是啥 dataset/VOCdevkit/VOC2007_trainval/JPEGImages/008538.jpg\n",
      "这是啥类型 <class 'str'>\n",
      "这是啥 dataset/VOCdevkit/VOC2007_trainval/JPEGImages/009167.jpg\n",
      "这是啥类型 <class 'str'>\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-048d08fccd7d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0msolver\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSolver\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrpn_loss_obj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredict_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m     \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'start training'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 151\u001b[0;31m     \u001b[0msolver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    152\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-1-048d08fccd7d>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    101\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_iter\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m                     \u001b[0msaver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mckpt_filename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglobal_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m                 \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    954\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    955\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 956\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    957\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    958\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1178\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1179\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1180\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1181\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1182\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1357\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1358\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1359\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1360\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1361\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1363\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1364\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1365\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1366\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1367\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1348\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1349\u001b[0m       return self._call_tf_sessionrun(options, feed_dict, fetch_list,\n\u001b[0;32m-> 1350\u001b[0;31m                                       target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1351\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1352\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1441\u001b[0m     return tf_session.TF_SessionRun_wrapper(self._session, options, feed_dict,\n\u001b[1;32m   1442\u001b[0m                                             \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1443\u001b[0;31m                                             run_metadata)\n\u001b[0m\u001b[1;32m   1444\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1445\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Created on Thu Oct 25 09:54:12 2018\n",
    "\n",
    "@author: LongJun\n",
    "\"\"\"\n",
    "\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import config as cfg\n",
    "import os\n",
    "import pascal_voc as pascl\n",
    "import tensorflow.contrib.slim as slim\n",
    "import anchor_generate\n",
    "from tensorflow.python import pywrap_tensorflow\n",
    "from anchor_label import anchor_labels_process, labels_generate, anchor_labels_process\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import network\n",
    "import datetime\n",
    "from losslayer import RPN_loss\n",
    "from predict_loss import Predict_loss\n",
    "# Solver Class, used for training\n",
    "# net: the name of backbone net, only support VGG16, more backbone net will be supported in the feature\n",
    "# data/val_data： trian_data/vla_data is a list that consist of dict of ground_truth label\n",
    "# rpn_loss class : used for calculating rpn_loss\n",
    "# predict_loss: used for calculating predict_loss\n",
    "class Solver(object):   \n",
    "    def __init__(self, net ,data, val_data, rpn_loss, predict_loss): \n",
    "        self.net = net\n",
    "        self.data = data\n",
    "        self.val_data = val_data\n",
    "        self.max_iter = cfg.MAX_ITER\n",
    "        self.lr = cfg.LEARNING_RATE\n",
    "        self.rpn_loss = rpn_loss\n",
    "        self.predict_loss = predict_loss\n",
    "        self.lr_change_ITER = cfg.lr_change_ITER\n",
    "        self.summary_iter = cfg.SUMMARY_ITER\n",
    "        self.save_iter = cfg.SAVE_ITER\n",
    "        self.overlaps_max = cfg.overlaps_max\n",
    "        self.overlaps_min = cfg.overlaps_min\n",
    "        self._variables_to_fix = {}\n",
    "        self.Summary_output = os.path.join(cfg.Summary_output, datetime.datetime.now().strftime('%Y_%m_%d_%H_%M'))\n",
    "        if not os._exists(self.Summary_output):\n",
    "            os.mkdir(self.Summary_output)\n",
    "        self.train_summary_dir = os.path.join(self.Summary_output, 'train')\n",
    "        self.val_summary_dir = os.path.join(self.Summary_output, 'val')\n",
    "        self.model_output_dir = os.path.join(cfg.OUTPUT_DIR) \n",
    "        if not os.path.exists(self.model_output_dir):\n",
    "            os.mkdir(self.model_output_dir)\n",
    "        if not os.path.exists(self.train_summary_dir):\n",
    "            os.mkdir(self.train_summary_dir)\n",
    "        if not os.path.exists(self.val_summary_dir):\n",
    "            os.mkdir(self.val_summary_dir)\n",
    "        self.ckpt_filename = os.path.join(self.model_output_dir, 'output.model')\n",
    "        \n",
    " # training process       \n",
    "    def train_model(self):\n",
    "        lr = tf.Variable(self.lr[0],trainable=False)\n",
    "        self.optimizer = tf.train.MomentumOptimizer(lr, cfg.momentum)\n",
    "        #self.optimizer = tf.train.GradientDescentOptimizer(lr)\n",
    "        self.loss = self.rpn_loss.add_loss() + self.predict_loss.add_loss()     \n",
    "        train_op = self.optimizer.minimize(self.loss)\n",
    "        variables = tf.global_variables()\n",
    "        reader = pywrap_tensorflow.NewCheckpointReader(self.net.weight_file_path)\n",
    "        var_to_shape_map = reader.get_variable_to_shape_map()\n",
    "        variables_to_restore = self.get_var_list(variables, var_to_shape_map)\n",
    "        init = tf.global_variables_initializer()\n",
    "        saver = tf.train.Saver(var_list=variables_to_restore)\n",
    "        merged = tf.summary.merge_all()\n",
    "        with tf.Session() as sess:\n",
    "            train_writer = tf.summary.FileWriter(self.train_summary_dir, sess.graph)\n",
    "            val_writer = tf.summary.FileWriter(self.val_summary_dir)\n",
    "            sess.run(init)\n",
    "            saver.restore(sess, self.net.weight_file_path)\n",
    "            self.fix_variables(sess, self.net.weight_file_path)\n",
    "            saver = tf.train.Saver(variables,max_to_keep = 10)\n",
    "            for step in range(self.max_iter+1):\n",
    "                if step == self.lr_change_ITER:\n",
    "                    lr = tf.assign(lr, self.lr[1])\n",
    "                train_data = self.data.get()\n",
    "                image_height = np.array(train_data['image'].shape[1])\n",
    "                image_width = np.array(train_data['image'].shape[2])\n",
    "                feed_dict = {self.net.image: train_data['image'], self.net.image_width: image_width,\\\n",
    "                             self.net.image_height: image_height, self.net.gt_boxes: train_data['box'],\\\n",
    "                             self.net.gt_cls: train_data['cls']}\n",
    "                if step % self.summary_iter == 0:\n",
    "                    total_loss, summary, learning_rate= sess.run([self.loss, merged, lr], feed_dict=feed_dict)\n",
    "                    train_writer.add_summary(summary, step)\n",
    "                    val_data = self.val_data.get()\n",
    "                    val_image_height = np.array(val_data['image'].shape[1])\n",
    "                    val_image_width = np.array(val_data['image'].shape[2])\n",
    "                    val_feed_dict = {self.net.image: val_data['image'], self.net.image_width: val_image_width,\\\n",
    "                                     self.net.image_height: val_image_height, self.net.gt_boxes: val_data['box'],\\\n",
    "                                     self.net.gt_cls: val_data['cls']}\n",
    "                    val_loss, val_summary = sess.run([self.loss, merged], feed_dict=val_feed_dict)\n",
    "                    val_writer.add_summary(val_summary, step)\n",
    "                    print ('The', step, 'step train_total_loss is', total_loss, 'val_total_loss is', val_loss)\n",
    "                    print ('learning_rate is ', learning_rate)\n",
    "                if step % self.save_iter == 0:\n",
    "                    saver.save(sess, self.ckpt_filename, global_step = step)\n",
    "                sess.run(train_op, feed_dict=feed_dict)\n",
    "                    \n",
    "               \n",
    "                \n",
    "                \n",
    "#get the variables to restore               \n",
    "    def get_var_list(self, global_variables, ckpt_variables):\n",
    "        variables_to_restore = []\n",
    "        for key in global_variables:\n",
    "            print (key.name)\n",
    "            if key.name == ('vgg_16/fc6/weights:0') or key.name == ('vgg_16/fc7/weights:0'):\n",
    "                self._variables_to_fix[key.name] = key\n",
    "                continue\n",
    "            \n",
    "            if key.name.split(':')[0] in ckpt_variables:\n",
    "                variables_to_restore.append(key) \n",
    "        return variables_to_restore\n",
    "    \n",
    "#because fc6 and fc7 layers of pretrained vgg16 model is convolution format, so we need convert them to fully-connected layers\n",
    "    def fix_variables(self, sess, pretrained_model):\n",
    "        print('Fix VGG16 layers..')\n",
    "        with tf.variable_scope('Fix_VGG16') as scope:\n",
    "            with tf.device(\"/cpu:0\"):\n",
    "                fc6_conv = tf.get_variable(\"fc6_conv\", [7, 7, 512, 4096], trainable=False)\n",
    "                fc7_conv = tf.get_variable(\"fc7_conv\", [1, 1, 4096, 4096], trainable=False)\n",
    "                restorer_fc = tf.train.Saver({'vgg_16' + \"/fc6/weights\": fc6_conv, \n",
    "                                              'vgg_16' + \"/fc7/weights\": fc7_conv})\n",
    "                restorer_fc.restore(sess, pretrained_model)\n",
    "        \n",
    "                sess.run(tf.assign(self._variables_to_fix['vgg_16' + '/fc6/weights:0'], tf.reshape(fc6_conv, \n",
    "                                    self._variables_to_fix['vgg_16' + '/fc6/weights:0'].get_shape())))\n",
    "                sess.run(tf.assign(self._variables_to_fix['vgg_16' + '/fc7/weights:0'], tf.reshape(fc7_conv, \n",
    "                                    self._variables_to_fix['vgg_16' + '/fc7/weights:0'].get_shape())))\n",
    "    \n",
    "\n",
    "if __name__ == '__main__':\n",
    "    os.environ['CUDA_VISIBLE_DEVICES'] = cfg.GPU_ID\n",
    "    net = network.Net()\n",
    "    rpn_loss_obj = RPN_loss(net.rois_output['rois_bbx'], net.all_anchors, net.gt_boxes, \\\n",
    "                        net.rois_output['rois_cls'], net.labels, net.anchor_obj)\n",
    "    predict_loss = Predict_loss(net._predictions[\"cls_score\"], net._proposal_targets['labels'],\\\n",
    "                                net._predictions['bbox_pred'], net._proposal_targets['bbox_targets'],\\\n",
    "                                net._proposal_targets['bbox_inside_weights'], net._proposal_targets['bbox_outside_weights'])\n",
    "    \n",
    "    train_data = pascl.pascal_voc(cfg.train_imdb_name, 'train', fliped=True)\n",
    "    val_data = pascl.pascal_voc(cfg.test_imdb_name, 'test', fliped=False)\n",
    "    solver = Solver(net, train_data, val_data, rpn_loss_obj, predict_loss)\n",
    "    print ('start training')\n",
    "    start = datetime.datetime.now()\n",
    "    solver.train_model()\n",
    "    end = datetime.now()\n",
    "    latency = (end - start).total_seconds()  \n",
    "    print(\"The latency is   \"+str(latency)+\"秒\")  \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
