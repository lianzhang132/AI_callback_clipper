{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/pandas/compat/__init__.py:117: UserWarning: Could not import the lzma module. Your installed Python is incomplete. Attempting to use lzma compression will result in a RuntimeError.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:\n",
      "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "WARNING:tensorflow:From /root/code/Faster-rcnn-tensorflow-master_1/network.py:28: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /root/code/Faster-rcnn-tensorflow-master_1/network.py:104: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/site-packages/tensorflow_core/contrib/layers/python/layers/layers.py:1057: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `layer.__call__` method instead.\n",
      "WARNING:tensorflow:From /root/code/Faster-rcnn-tensorflow-master_1/network.py:75: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "tf.py_func is deprecated in TF V2. Instead, there are two\n",
      "    options available in V2.\n",
      "    - tf.py_function takes a python function which manipulates tf eager\n",
      "    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to\n",
      "    an ndarray (just call tensor.numpy()) but having access to eager tensors\n",
      "    means `tf.py_function`s can use accelerators such as GPUs as well as\n",
      "    being differentiable using a gradient tape.\n",
      "    - tf.numpy_function maintains the semantics of the deprecated tf.py_func\n",
      "    (it is not differentiable, and manipulates numpy arrays). It drops the\n",
      "    stateful argument making all functions stateful.\n",
      "    \n",
      "WARNING:tensorflow:From /root/code/Faster-rcnn-tensorflow-master_1/network.py:192: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.cast` instead.\n",
      "WARNING:tensorflow:From /root/code/Faster-rcnn-tensorflow-master_1/network.py:247: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.cast` instead.\n",
      "WARNING:tensorflow:From /root/code/Faster-rcnn-tensorflow-master_1/network.py:247: calling crop_and_resize_v1 (from tensorflow.python.ops.image_ops_impl) with box_ind is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "box_ind is deprecated, use box_indices instead\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/site-packages/tensorflow_core/contrib/layers/python/layers/layers.py:1634: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.flatten instead.\n",
      "WARNING:tensorflow:From /root/code/Faster-rcnn-tensorflow-master_1/network.py:266: The name tf.summary.image is deprecated. Please use tf.compat.v1.summary.image instead.\n",
      "\n",
      "Loading gt_labels from: annotation_cache/VOC2007_test/pascal_test_gt_labels.pkl\n",
      "start training\n",
      "INFO:tensorflow:Restoring parameters from output/output.model-70000\n",
      "0  image test compeleted\n",
      "1  image test compeleted\n",
      "2  image test compeleted\n",
      "3  image test compeleted\n",
      "4  image test compeleted\n",
      "5  image test compeleted\n",
      "6  image test compeleted\n",
      "7  image test compeleted\n",
      "8  image test compeleted\n",
      "9  image test compeleted\n",
      "10  image test compeleted\n",
      "11  image test compeleted\n",
      "12  image test compeleted\n",
      "13  image test compeleted\n",
      "14  image test compeleted\n",
      "15  image test compeleted\n",
      "16  image test compeleted\n",
      "17  image test compeleted\n",
      "18  image test compeleted\n",
      "19  image test compeleted\n",
      "20  image test compeleted\n",
      "21  image test compeleted\n",
      "22  image test compeleted\n",
      "23  image test compeleted\n",
      "24  image test compeleted\n",
      "25  image test compeleted\n",
      "26  image test compeleted\n",
      "27  image test compeleted\n",
      "28  image test compeleted\n",
      "29  image test compeleted\n",
      "30  image test compeleted\n",
      "31  image test compeleted\n",
      "32  image test compeleted\n",
      "33  image test compeleted\n",
      "34  image test compeleted\n",
      "35  image test compeleted\n",
      "36  image test compeleted\n",
      "37  image test compeleted\n",
      "38  image test compeleted\n",
      "39  image test compeleted\n",
      "40  image test compeleted\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Created on Thu Oct 25 09:54:12 2018\n",
    "\n",
    "@author: LongJun\n",
    "\"\"\"\n",
    "\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import config as cfg\n",
    "import os\n",
    "import pascal_voc as pascl\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import network\n",
    "import datetime\n",
    "import cv2\n",
    "from nms import py_cpu_nms\n",
    "#Val_test class is used to test the output model, the result is mean_ap tested on the pascal_voc 2007 test_imdb\n",
    "#netï¼š VGG16\n",
    "#val_data: val_data name\n",
    "class Val_test(object):   \n",
    "    def __init__(self, net ,val_data):\n",
    "        self.net = net\n",
    "        self.val_data = val_data\n",
    "        self.overlaps_max = cfg.overlaps_max\n",
    "        self.overlaps_min = cfg.overlaps_min\n",
    "        self.ckpt_filename = tf.train.latest_checkpoint(os.path.join(cfg.OUTPUT_DIR))\n",
    "        self.test_output_dir = cfg.test_output_path\n",
    "        self.image_output_dir = cfg.image_output_dir\n",
    "        txtname = os.path.join(self.val_data.devkil_path, self.val_data.name, 'ImageSets', 'Main', self.val_data.phase+'.txt')\n",
    "        with open(txtname) as f:\n",
    "            self.image_index = [x.strip() for x in f.readlines()]\n",
    "\n",
    "    def test_model(self):\n",
    "        saver = tf.train.Saver()\n",
    "        _rois_coord = self.net.rois_coord[:,1:5]\n",
    "        #rois_coord = self.net.rois_coord\n",
    "        _pred_box = self.net.bbox_pred\n",
    "        _pred_score = self.net.cls_prob\n",
    "        #_pred_box_score_arg = tf.argmax(_pred_score, axis=1)\n",
    "        dect_total_result = [[[] for i in range(self.val_data.num_gtlabels)] for j in range(self.net.num_classes)]\n",
    "        with tf.Session() as sess:\n",
    "            saver.restore(sess, self.ckpt_filename)\n",
    "            for i in range (self.val_data.num_gtlabels):\n",
    "                print (i, ' image test compeleted')            \n",
    "                train_data = self.val_data.get()\n",
    "                image_height = np.array(train_data['image'].shape[1])\n",
    "                image_width = np.array(train_data['image'].shape[2])\n",
    "                feed_dict = {self.net.image: train_data['image'], self.net.image_width: image_width,\\\n",
    "                             self.net.image_height: image_height}\n",
    "                                \n",
    "                rois_coord, pred_box, pred_score= sess.run([_rois_coord, _pred_box, _pred_score],\\\n",
    "                                                                        feed_dict=feed_dict) \n",
    "\n",
    "                for k in range(1, self.net.num_classes):    \n",
    "                    #pre_class_arg = np.where(pred_score[:,k]>=0)[0]\n",
    "                    cls_pred_box_target = pred_box[:, k*4:(k+1)*4]\n",
    "                    cls_pred_box_target = cls_pred_box_target * np.array(cfg.bbox_nor_stdv) + np.array(cfg.bbox_nor_mean)\n",
    "                    cls_pred_box_coord = self.coord_transform_inv(rois_coord, cls_pred_box_target.astype(np.float32))\n",
    "                    cls_pred_box_coord = cls_pred_box_coord/train_data['scale'] + 1.0\n",
    "                    cls_pred_score = pred_score[:, k]\n",
    "                    #print(cls_pred_box_coord.shape, cls_pred_score.shape)\n",
    "                    cls_pred_score = cls_pred_score[:, np.newaxis]  \n",
    "                    cls_pred_target = np.concatenate((cls_pred_box_coord, cls_pred_score), axis=1)\n",
    "                    keep = py_cpu_nms(cls_pred_target, cfg.test_nms_thresh)\n",
    "                    cls_pred_target = cls_pred_target[keep, :]\n",
    "                    dect_total_result[k][i] = cls_pred_target\n",
    "                   # print (cls_pred_target)\n",
    "                image_scores = np.hstack([dect_total_result[j][i][:, -1] for j in range(1, self.net.num_classes)]) #\n",
    "                if len(image_scores) > cfg.test_max_per_image:\n",
    "                    image_thresh = np.sort(image_scores)[-cfg.test_max_per_image] #\n",
    "                    for j in range(1, self.net.num_classes):\n",
    "                        keep = np.where(dect_total_result[j][i][:, -1] >= image_thresh)[0]\n",
    "                        dect_total_result[j][i] = dect_total_result[j][i][keep, :] #\n",
    "            mean_ap = self.map_compute(dect_total_result)\n",
    "            print ('the mean_ap of pascal_voc 2007 is', mean_ap)\n",
    "        \n",
    "        \n",
    "    def coord_transform_inv (self, anchors, boxes):\n",
    "        anchors = anchors.astype(np.float32)\n",
    "        anchors = np.reshape(anchors, [-1,4])\n",
    "        anchor_x = (anchors[:,2] + anchors[:,0]) * 0.5\n",
    "        anchor_y = (anchors[:,3] + anchors[:,1]) * 0.5\n",
    "        acnhor_w = (anchors[:,2] - anchors[:,0]) + 1.0\n",
    "        acnhor_h = (anchors[:,3] - anchors[:,1]) + 1.0\n",
    "        boxes = np.reshape(boxes, [-1,4])\n",
    "        boxes_x = boxes[:,0]*acnhor_w + anchor_x\n",
    "        boxes_y = boxes[:,1]*acnhor_h + anchor_y\n",
    "        boxes_w = np.exp(boxes[:,2])*acnhor_w\n",
    "        boxes_h = np.exp(boxes[:,3])*acnhor_h\n",
    "        coord_x1 = boxes_x - boxes_w*0.5\n",
    "        coord_y1 = boxes_y - boxes_h*0.5\n",
    "        coord_x2 = boxes_x + boxes_w*0.5\n",
    "        coord_y2 = boxes_y + boxes_h*0.5\n",
    "        coord_result = np.stack([coord_x1, coord_y1, coord_x2, coord_y2], axis=1)\n",
    "        return coord_result              \n",
    "\n",
    "\n",
    "#computing map using pascal_voc 2010 algorithm\n",
    "    def map_compute(self, dect_boxes):\n",
    "        ap = []\n",
    "        for cls_ind, cls in enumerate(self.val_data.classes):\n",
    "            cls_obj = {}\n",
    "            num_cls_obj = 0\n",
    "            if cls == 'background':\n",
    "                 continue\n",
    "            if not os.path.exists(self.test_output_dir):\n",
    "                os.mkdir(self.test_output_dir)\n",
    "            cls_filename = os.path.join(self.test_output_dir, cls+'.txt')\n",
    "            with open(cls_filename, 'w') as f:\n",
    "                 for img_ind_dex, image_ind in enumerate(self.image_index):\n",
    "                      dect_box = dect_boxes[cls_ind][img_ind_dex]\n",
    "                      if dect_box == []:\n",
    "                           continue\n",
    "                      for i in range(dect_box.shape[0]):\n",
    "                           f.write('{:s} {:2f} {:2f} {:2f} {:2f} {:3f} \\n'.format\\\n",
    "                                   (image_ind, dect_box[i][0], dect_box[i][1], dect_box[i][2],\\\n",
    "                                    dect_box[i][3], dect_box[i][4]))\n",
    "                           \n",
    "            for gt_label in self.val_data.gt_labels:\n",
    "                 gt_label_cls_ind = np.where(gt_label['gt_classs']==cls_ind)[0]\n",
    "                 gt_label_pick_box = gt_label['boxes'][gt_label_cls_ind, :]\n",
    "                 gt_label_pick_cls = gt_label['gt_classs'][gt_label_cls_ind]\n",
    "                 diff_pick = gt_label['diff'][gt_label_cls_ind].astype(np.bool)\n",
    "                 dec_id = [False] * gt_label_cls_ind.size\n",
    "                 num_cls_obj = num_cls_obj + sum(~diff_pick)\n",
    "                 cls_obj[gt_label['image_index']] = {'bbox': gt_label_pick_box,\\\n",
    "                                                      'cls': gt_label_pick_cls,\\\n",
    "                                                      'dec_id': dec_id, 'diff': diff_pick}\n",
    "                 #print (num_cls_obj)\n",
    "            with open(cls_filename, 'r') as f:\n",
    "              lines = f.readlines()\n",
    "            splitlines = [x.strip().split(' ') for x in lines] \n",
    "            image_ids = [x[0] for x in splitlines]  \n",
    "            confidence = np.array([float(x[5]) for x in splitlines])\n",
    "            BB = np.array([[float(z) for z in x[1:5]] for x in splitlines]) #bounding box                 \n",
    "            \n",
    "            nd = len(image_ids)                   \n",
    "            tp = np.zeros(nd)         \n",
    "            fp = np.zeros(nd)\n",
    "            \n",
    "            if BB.shape[0] > 0:\n",
    "                 sorted_ind = np.argsort(-confidence) \n",
    "                 BB = BB[sorted_ind, :]\n",
    "                 image_ids = [image_ids[x] for x in sorted_ind] \n",
    "                 for d in range(nd): \n",
    "                      R = cls_obj[image_ids[d]] \n",
    "                      bb = BB[d, :].astype(float) \n",
    "                      ovmax = -np.inf \n",
    "                      BBGT = R['bbox'].astype(float) \n",
    "                      \n",
    "                      if BBGT.size > 0: \n",
    "                           ixmin = np.maximum(BBGT[:, 0], bb[0])\n",
    "                           iymin = np.maximum(BBGT[:, 1], bb[1])\n",
    "                           ixmax = np.minimum(BBGT[:, 2], bb[2])\n",
    "                           iymax = np.minimum(BBGT[:, 3], bb[3])\n",
    "                           iw = np.maximum(ixmax - ixmin + 1., 0.)\n",
    "                           ih = np.maximum(iymax - iymin + 1., 0.)\n",
    "                           inters = iw * ih\n",
    "                           uni = ((bb[2] - bb[0] + 1.) * (bb[3] - bb[1] + 1.) +\\\n",
    "                                  (BBGT[:, 2] - BBGT[:, 0] + 1.) *\\\n",
    "                                  (BBGT[:, 3] - BBGT[:, 1] + 1.) - inters)\n",
    "                           overlaps = inters / uni\n",
    "                           ovmax = np.max(overlaps) \n",
    "                           jmax = np.argmax(overlaps) \n",
    "                           \n",
    "                      if ovmax > cfg.test_fp_tp_thresh:\n",
    "                           if not R['diff'][jmax]:\n",
    "                               if not R['dec_id'][jmax]: \n",
    "                                    tp[d] = 1.\n",
    "                                    R['dec_id'][jmax] = 1 \n",
    "                               else:\n",
    "                                    fp[d] = 1.\n",
    "                      else:\n",
    "                           fp[d] = 1. \n",
    "            fp = np.cumsum(fp) \n",
    "            tp = np.cumsum(tp) \n",
    "            rec = tp / float(num_cls_obj) \n",
    "            prec = tp / np.maximum(tp + fp, np.finfo(np.float64).eps) \n",
    "            ap.append(self.val_data.voc_ap(rec, prec)) \t\n",
    "            print (np.mean(ap))\n",
    "        return sum(ap)/(self.net.num_classes - 1.0)\n",
    "    \n",
    "                   \n",
    "    def get_var_list(self, global_variables, ckpt_variables):\n",
    "        variables_to_restore = []\n",
    "        for key in global_variables:\n",
    "            if key.name.split(':')[0] in ckpt_variables:\n",
    "                variables_to_restore.append(key) \n",
    "        return variables_to_restore\n",
    "    \n",
    "    \n",
    "\n",
    "if __name__ == '__main__':\n",
    "    os.environ['CUDA_VISIBLE_DEVICES'] = cfg.GPU_ID\n",
    "    net = network.Net(is_training=False)\n",
    "    val_data = pascl.pascal_voc(cfg.test_imdb_name, 'test', fliped=False)\n",
    "    test = Val_test(net, val_data)\n",
    "    print ('start training')\n",
    "    test.test_model()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
