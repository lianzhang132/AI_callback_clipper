{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing gt_labels from: dataset\\VOCdevkit\\VOC2012\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'dataset\\\\VOCdevkit\\\\VOC2012\\\\ImageSets\\\\Main\\\\trainval.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-77f2c263d19f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    167\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    168\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'__main__'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 169\u001b[1;33m     \u001b[0mpascal\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpascal_voc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'train'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    170\u001b[0m     \u001b[0mtf_blob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpascal\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    171\u001b[0m     \u001b[0mprint\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpascal\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgt_labels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-1-77f2c263d19f>\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, phase, rebuild)\u001b[0m\n\u001b[0;32m     25\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mepoch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m     \u001b[1;31m#当前的epoch\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m         \u001b[1;31m#self.gt_labels = None\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 27\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprepare\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     28\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnum_gtlabels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgt_labels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-1-77f2c263d19f>\u001b[0m in \u001b[0;36mprepare\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     62\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mprepare\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 64\u001b[1;33m         \u001b[0mgt_labels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_labels\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     65\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflipped\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Appending horizontally-flipped training examples ...'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#{'boxes':boxes, 'gt_classs':gt_classes, 'imname':imname}组成的list\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-1-77f2c263d19f>\u001b[0m in \u001b[0;36mload_labels\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    100\u001b[0m                 self.data_path, 'ImageSets', 'Main', 'val.txt')\n\u001b[0;32m    101\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflipped\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 102\u001b[1;33m         \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtxtname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'r'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    103\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimage_index\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreadlines\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    104\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'dataset\\\\VOCdevkit\\\\VOC2012\\\\ImageSets\\\\Main\\\\trainval.txt'"
     ]
    }
   ],
   "source": [
    "\n",
    "import os\n",
    "import xml.etree.ElementTree as ET\n",
    "import numpy as np\n",
    "import cv2\n",
    "import pickle\n",
    "import copy\n",
    "import config as cfg\n",
    " \n",
    " \n",
    "class pascal_voc(object):\n",
    "    def __init__(self, phase, rebuild=False):\n",
    "        self.devkil_path = os.path.join(cfg.PASCAL_PATH, 'VOCdevkit')   #pasval_voc路径\n",
    "        self.data_path = os.path.join(self.devkil_path, 'VOC2012')  #pascal_voc 2007路径\n",
    "        self.cache_path = cfg.CACHE_PATH    #缓存路径\n",
    "        self.batch_size = cfg.BATCH_SIZE    #batch_size\n",
    "        self.target_size = cfg.target_size  #图片的最小尺寸\n",
    "        self.max_size = cfg.max_size    #图片的最大尺寸\n",
    "        self.classes = cfg.CLASSES  #类别信息  ['background', 'aeroplane', 'bicycle', 'bird', 'boat', 'bottle', 'bus'....]\n",
    "        self.pixel_means = cfg.PIXEL_MEANS  #背景像素\n",
    "        self.class_to_ind = dict(zip(self.classes, range(len(self.classes))))   #构造class字典\n",
    "        self.flipped = cfg.FLIPPED  #图片是否翻转\n",
    "        self.phase = phase  #ImageSet 的名称\n",
    "        self.rebuild = rebuild   #是否重新简历缓存\n",
    "        self.cursor = 0    #当前游标\n",
    "        self.epoch = 1     #当前的epoch\n",
    "        #self.gt_labels = None\n",
    "        self.prepare()\n",
    "        self.num_gtlabels = len(self.gt_labels)\n",
    "    \n",
    "    def image_read(self, imname, flipped=False):\n",
    "        image = cv2.imread(imname)  #opencv 中默认图片色彩格式为BGR\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB).astype(np.float32) #将图片转成RGB格式\n",
    "        if flipped:\n",
    "            image = image[:, ::-1, :]\n",
    "        return image\n",
    "    \n",
    "    def get(self): #在get中完成 self.epoch+1的操作\n",
    "        #images = np.zeros((self.batch_size, self.image_size, self.image_size, 3))\n",
    "        #gt_box = np.zeros((self.batch_size, 4), dtype=np.uint16)\n",
    "        #gt_cls = np.zeros((num_objs), dtype=np.int32)\n",
    "        count = 0\n",
    "        tf_blob = {}\n",
    "        assert self.batch_size == 1, \"only support single batch\" \n",
    "        while count < self.batch_size:\n",
    "            imname = self.gt_labels[self.cursor]['imname']\n",
    "            flipped = self.gt_labels[self.cursor]['flipped']\n",
    "            image = self.image_read(imname, flipped=flipped)\n",
    "            image, image_scale = self.prep_im_for_blob(image, self.pixel_means, self.target_size, self.max_size)#resize后的image\n",
    "            image = np.reshape(image, (self.batch_size, image.shape[0], image.shape[1], 3)) #将image 转化成tensorflow输入的形式\n",
    "            gt_box = self.gt_labels[self.cursor]['boxes'] * image_scale #将gt_box sclae与scale相乘 boxes.shape=[num_obj,4]\n",
    "            gt_cls = self.gt_labels[self.cursor]['gt_classs']\n",
    "            count += 1\n",
    "            self.cursor += 1\n",
    "            if self.cursor >= len(self.gt_labels):\n",
    "                np.random.shuffle(self.gt_labels)\n",
    "                self.cursor = 0\n",
    "                self.epoch += 1\n",
    "        tf_blob = {'image':image, 'scale':image_scale, 'cls':gt_cls, 'box': gt_box, 'imname': imname}\n",
    "        return tf_blob #返回的image.shape=[batch,size,size,3] image_scale, gt_box.shape=[num_objs,4]\n",
    " \n",
    "    \n",
    " \n",
    "    def prepare(self):\n",
    "        gt_labels = self.load_labels()\n",
    "        if self.flipped:\n",
    "            print('Appending horizontally-flipped training examples ...') #{'boxes':boxes, 'gt_classs':gt_classes, 'imname':imname}组成的list\n",
    "            gt_labels_cp = copy.deepcopy(gt_labels) #很重要\n",
    "            for idx in range(len(gt_labels_cp)):\n",
    "                gt_labels_cp[idx]['flipped'] = True\n",
    "                width_pre = copy.deepcopy(gt_labels_cp[idx]['boxes'][:,0])\n",
    "                gt_labels_cp[idx]['boxes'][:,0] = gt_labels_cp[idx]['image_size'][0] - gt_labels_cp[idx]['boxes'][:,2]\n",
    "                gt_labels_cp[idx]['boxes'][:,2] = gt_labels_cp[idx]['image_size'][0] - width_pre\n",
    "#                gt_labels_cp[idx]['boxes'][:,[0,2]] = gt_labels_cp[idx]['image_size'][0] - gt_labels_cp[idx]['boxes'][:,[0,2]][:,::-1]\n",
    "            gt_labels += gt_labels_cp\n",
    "        if self.phase == 'train':\n",
    "            np.random.shuffle(gt_labels)\n",
    "        self.gt_labels = gt_labels\n",
    "        #return gt_labels\n",
    " \n",
    "    def load_labels(self):\n",
    "        cache_file = os.path.join(\n",
    "            self.cache_path, 'pascal_' + self.phase + '_gt_labels.pkl')\n",
    " \n",
    "        if os.path.isfile(cache_file) and not self.rebuild:\n",
    "            print('Loading gt_labels from: ' + cache_file)\n",
    "            with open(cache_file, 'rb') as f:\n",
    "                gt_labels = pickle.load(f)  #从.pkl文件中反序列对象\n",
    "            return gt_labels\n",
    " \n",
    "        print('Processing gt_labels from: ' + self.data_path)\n",
    " \n",
    "        if not os.path.exists(self.cache_path):\n",
    "            os.makedirs(self.cache_path)\n",
    " \n",
    "        if self.phase == 'train':\n",
    "            txtname = os.path.join(\n",
    "                self.data_path, 'ImageSets', 'Main', 'trainval.txt')\n",
    "        else:\n",
    "            txtname = os.path.join(\n",
    "                self.data_path, 'ImageSets', 'Main', 'val.txt')\n",
    "            self.flipped = False\n",
    "        with open(txtname, 'r') as f:\n",
    "            self.image_index = [x.strip() for x in f.readlines()]\n",
    " \n",
    "        gt_labels = []\n",
    "        for index in self.image_index:\n",
    "            gt_label = self.load_pascal_annotation(index) #groundtruth_roidb 包括objet box坐标信息 以及类别信息(转换成dict后的)\n",
    "            gt_labels.append(gt_label)\n",
    "        print('Saving gt_labels to: ' + cache_file)\n",
    "        with open(cache_file, 'wb') as f:\n",
    "            pickle.dump(gt_labels, f)\n",
    "        return gt_labels\n",
    " \n",
    "    def load_pascal_annotation(self, index):\n",
    "        \"\"\"\n",
    "        Load image and bounding boxes info from XML file in the PASCAL VOC\n",
    "        format.\n",
    "        \"\"\"\n",
    "        filename = os.path.join(self.data_path, 'Annotations', index + '.xml')\n",
    "        tree = ET.parse(filename)\n",
    "        objs = tree.findall('object')\n",
    "        image_size = tree.find('size')\n",
    "        size_info = np.zeros((2,), dtype=np.float32)\n",
    "        size_info[0] = float(image_size.find('width').text)\n",
    "        size_info[1] = float(image_size.find('height').text)\n",
    "        num_objs = len(objs) #object的数量\n",
    "        boxes = np.zeros((num_objs, 4), dtype=np.float32) #boxes 坐标 (num_objs,4)个 dtype=np.uint16\n",
    "        gt_classes = np.zeros((num_objs), dtype=np.int32) #class 的数量num_objs个 dtype=np.int32 应该是groundtruth中读到的class\n",
    "        \n",
    "        for ix, obj in enumerate(objs):\n",
    "            bbox = obj.find('bndbox')\n",
    "            # Make pixel indexes 0-based\n",
    "            x1 = float(bbox.find('xmin').text) - 1\n",
    "            y1 = float(bbox.find('ymin').text) - 1\n",
    "            x2 = float(bbox.find('xmax').text) - 1\n",
    "            y2 = float(bbox.find('ymax').text) - 1\n",
    "            cls = self.class_to_ind[obj.find('name').text.lower().strip()] #找到class对应的类别信息\n",
    "            boxes[ix, :] = [x1, y1, x2, y2] #注意boxes是一个np类的矩阵 大小为[num_objs,4]\n",
    "            gt_classes[ix] = cls #将class信息存入gt_classses中，注意gt_classes也是一个np类的矩阵 大小为[num_objs] 是int值 对应于name\n",
    "            imname = os.path.join(self.data_path, 'JPEGImages', index + '.jpg')\n",
    "        return {'boxes':boxes, 'gt_classs':gt_classes, 'imname':imname, 'flipped':False, 'image_size':size_info, 'image_index': index}\n",
    "    \n",
    "    def prep_im_for_blob(self, im, pixel_means, target_size, max_size): #传入image 背景 600 1000\n",
    "            im = im.astype(np.float32, copy=False)\n",
    "            im -= pixel_means #去掉背景\n",
    "            im_shape = im.shape\n",
    "            im_size_min = np.min(im_shape[0:2])\n",
    "            im_size_max = np.max(im_shape[0:2])\n",
    "            im_scale = float(target_size) / float(im_size_min) #600/最短边\n",
    "            # Prevent the biggest axis from being more than MAX_SIZE\n",
    "            if np.round(im_scale * im_size_max) > max_size:\n",
    "                im_scale = float(max_size) / float(im_size_max)\n",
    "            im = cv2.resize(im, None, None, fx=im_scale, fy=im_scale,interpolation=cv2.INTER_LINEAR)\n",
    "            return im, im_scale #返回im 和 im_scale\n",
    " \n",
    "    def voc_ap(self, rec, prec): #使用10年之后的pascal_voc的map计算方式\n",
    "        mrec = np.concatenate(([0.], rec, [1.]))\n",
    "        mpre = np.concatenate(([0.], prec, [0.]))\n",
    "        for i in range(mpre.size - 1, 0, -1):\n",
    "            mpre[i-1] = np.maximum(mpre[i-1], mpre[i])\n",
    "        \n",
    "        i = np.where(mrec[1:] != mrec[:-1])[0] #取所有与取倒数第一个之间\n",
    "        ap = np.sum((mrec[i + 1] - mrec[i]) * mpre[i + 1]) #计算ap\n",
    "        \n",
    "        return ap\n",
    " \n",
    " \n",
    "if __name__ == '__main__':\n",
    "    pascal = pascal_voc('train')\n",
    "    tf_blob = pascal.get()\n",
    "    print (len(pascal.gt_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
