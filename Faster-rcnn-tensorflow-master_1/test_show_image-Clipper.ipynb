{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/pandas/compat/__init__.py:117: UserWarning: Could not import the lzma module. Your installed Python is incomplete. Attempting to use lzma compression will result in a RuntimeError.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:\n",
      "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20-06-28:05:07:04 INFO     [docker_container_manager.py:184] [default-cluster] Starting managed Redis instance in Docker\n",
      "20-06-28:05:07:08 INFO     [docker_container_manager.py:276] [default-cluster] Metric Configuration Saved at /tmp/tmp7d9mf28a.yml\n",
      "20-06-28:05:07:10 INFO     [clipper_admin.py:162] [default-cluster] Clipper is running\n",
      "20-06-28:05:07:10 INFO     [clipper_admin.py:172] [default-cluster] Successfully connected to Clipper cluster at localhost:1337\n",
      "20-06-28:05:07:10 INFO     [clipper_admin.py:236] [default-cluster] Application faster-app was successfully registered\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import config as cfg\n",
    "import os\n",
    "import pascal_voc as pascl\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import network\n",
    "import datetime\n",
    "import cv2\n",
    "from nms import py_cpu_nms\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "from clipper_admin import ClipperConnection, DockerContainerManager\n",
    "from clipper_admin.deployers.tensorflow import deploy_tensorflow_model\n",
    "clipper_conn = ClipperConnection(DockerContainerManager())\n",
    "clipper_conn.start_clipper()\n",
    "clipper_conn.connect()\n",
    "\n",
    "\n",
    "\n",
    "clipper_conn.register_application(\n",
    "    name=\"faster-app\", input_type=\"strings\", default_output=\"-1.0\", slo_micros=100000)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(sess,train_data):\n",
    "    import numpy as np\n",
    "    num_imgs = len(train_data)\n",
    "#     print('这是啥',train_data,num_imgs)\n",
    "    result = []\n",
    "    for i in range(num_imgs):\n",
    "        data = json.loads(train_data[i][0])\n",
    "        print(data,type(data),type(i),type(train_data))\n",
    "#         test_data[i] = data\n",
    "        image_height = np.array(np.array(data['image']).shape[1])\n",
    "        image_width = np.array(np.array(data['image']).shape[2])\n",
    "        feed_dict = {\"Placeholder:0\": data['image'], \"Placeholder_1:0\": image_width,\\\n",
    "                     \"Placeholder_2:0\": image_height}\n",
    "        rois_coord, pred_box, pred_box_score_arg, pred_score= sess.run([\"strided_slice_13:0\", \"vgg_16_2/region_deciton/bbox_pred/BiasAdd:0\",\n",
    "                                                                        \"ArgMax:0\", \"vgg_16_2/region_deciton/cls_prob:0\"],\\\n",
    "                                                                feed_dict=feed_dict)\n",
    "        result.extend([str(rois_coord), str(pred_box), str(pred_box_score_arg), str(pred_score)])\n",
    "    return result\n",
    "\n",
    "#\"log\":\"TypeError: list indices must be integers or slices, not str\\n\",\"stream\":\"stderr\",\"time\":\"2020-06-28T02:46:45.704169109Z\"}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#此处可看出 输入的最终数据为  [{\"image\": [[1, 2, 3]]}] \n",
    "#clipper 接收到的数据为 [b'[{\"image\": [[1, 2, 3]]}]' b'[{\"image\": [[1, 2, 3]]}]']\n",
    "\n",
    "def predict2(sess,train_data):\n",
    "    import numpy as np\n",
    "#     num_imgs = len(train_data)\n",
    "#     print('这是啥',train_data,num_imgs)\n",
    "    result = []\n",
    "#     for i in range(num_imgs):\n",
    "    data = json.loads(train_data[0])[0]\n",
    "    print(data,type(data))\n",
    "#         test_data[i] = data\n",
    "    image_height = np.array(np.array(data['image']).shape[1])\n",
    "    image_width = np.array(np.array(data['image']).shape[2])\n",
    "    feed_dict = {\"Placeholder:0\": data['image'], \"Placeholder_1:0\": image_width,\\\n",
    "                 \"Placeholder_2:0\": image_height}\n",
    "    rois_coord, pred_box, pred_box_score_arg, pred_score= sess.run([\"strided_slice_13:0\", \"vgg_16_2/region_deciton/bbox_pred/BiasAdd:0\",\n",
    "                                                                    \"ArgMax:0\", \"vgg_16_2/region_deciton/cls_prob:0\"],\\\n",
    "                                                            feed_dict=feed_dict)\n",
    "    result.extend([str(rois_coord), str(pred_box), str(pred_box_score_arg), str(pred_score)])\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list1 = []\n",
    "list2 = [str([1]),str([2])]\n",
    "list1.extend(list2)\n",
    "print(type(list1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /root/code/Faster-rcnn-tensorflow-master_1/network.py:28: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20-06-28:05:07:34 WARNING  [module_wrapper.py:139] From /root/code/Faster-rcnn-tensorflow-master_1/network.py:28: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /root/code/Faster-rcnn-tensorflow-master_1/network.py:104: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20-06-28:05:07:34 WARNING  [module_wrapper.py:139] From /root/code/Faster-rcnn-tensorflow-master_1/network.py:104: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/site-packages/tensorflow_core/contrib/layers/python/layers/layers.py:1057: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `layer.__call__` method instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20-06-28:05:07:34 WARNING  [deprecation.py:323] From /usr/local/lib/python3.6/site-packages/tensorflow_core/contrib/layers/python/layers/layers.py:1057: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `layer.__call__` method instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /root/code/Faster-rcnn-tensorflow-master_1/network.py:75: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "tf.py_func is deprecated in TF V2. Instead, there are two\n",
      "    options available in V2.\n",
      "    - tf.py_function takes a python function which manipulates tf eager\n",
      "    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to\n",
      "    an ndarray (just call tensor.numpy()) but having access to eager tensors\n",
      "    means `tf.py_function`s can use accelerators such as GPUs as well as\n",
      "    being differentiable using a gradient tape.\n",
      "    - tf.numpy_function maintains the semantics of the deprecated tf.py_func\n",
      "    (it is not differentiable, and manipulates numpy arrays). It drops the\n",
      "    stateful argument making all functions stateful.\n",
      "    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20-06-28:05:07:35 WARNING  [deprecation.py:323] From /root/code/Faster-rcnn-tensorflow-master_1/network.py:75: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "tf.py_func is deprecated in TF V2. Instead, there are two\n",
      "    options available in V2.\n",
      "    - tf.py_function takes a python function which manipulates tf eager\n",
      "    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to\n",
      "    an ndarray (just call tensor.numpy()) but having access to eager tensors\n",
      "    means `tf.py_function`s can use accelerators such as GPUs as well as\n",
      "    being differentiable using a gradient tape.\n",
      "    - tf.numpy_function maintains the semantics of the deprecated tf.py_func\n",
      "    (it is not differentiable, and manipulates numpy arrays). It drops the\n",
      "    stateful argument making all functions stateful.\n",
      "    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /root/code/Faster-rcnn-tensorflow-master_1/network.py:192: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.cast` instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20-06-28:05:07:35 WARNING  [deprecation.py:323] From /root/code/Faster-rcnn-tensorflow-master_1/network.py:192: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.cast` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /root/code/Faster-rcnn-tensorflow-master_1/network.py:248: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.cast` instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20-06-28:05:07:35 WARNING  [deprecation.py:323] From /root/code/Faster-rcnn-tensorflow-master_1/network.py:248: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.cast` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /root/code/Faster-rcnn-tensorflow-master_1/network.py:248: calling crop_and_resize_v1 (from tensorflow.python.ops.image_ops_impl) with box_ind is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "box_ind is deprecated, use box_indices instead\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20-06-28:05:07:35 WARNING  [deprecation.py:506] From /root/code/Faster-rcnn-tensorflow-master_1/network.py:248: calling crop_and_resize_v1 (from tensorflow.python.ops.image_ops_impl) with box_ind is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "box_ind is deprecated, use box_indices instead\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/site-packages/tensorflow_core/contrib/layers/python/layers/layers.py:1634: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.flatten instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20-06-28:05:07:35 WARNING  [deprecation.py:323] From /usr/local/lib/python3.6/site-packages/tensorflow_core/contrib/layers/python/layers/layers.py:1634: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.flatten instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /root/code/Faster-rcnn-tensorflow-master_1/network.py:267: The name tf.summary.image is deprecated. Please use tf.compat.v1.summary.image instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20-06-28:05:07:36 WARNING  [module_wrapper.py:139] From /root/code/Faster-rcnn-tensorflow-master_1/network.py:267: The name tf.summary.image is deprecated. Please use tf.compat.v1.summary.image instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading gt_labels from: annotation_cache/VOC2007_test/pascal_test_gt_labels.pkl\n",
      "start training\n",
      "INFO:tensorflow:Restoring parameters from output/output.model-70000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20-06-28:05:07:36 INFO     [saver.py:1284] Restoring parameters from output/output.model-70000\n",
      "20-06-28:05:07:37 INFO     [deployer_utils.py:41] Saving function to /tmp/tmpx2baqe9xclipper\n",
      "20-06-28:05:07:37 INFO     [deployer_utils.py:51] Serialized and supplied predict function\n",
      "20-06-28:05:07:38 INFO     [tensorflow.py:196] TensorFlow model saved at: /tmp/tmpx2baqe9xclipper/tfmodel/model.ckpt \n",
      "20-06-28:05:07:38 INFO     [tensorflow.py:277] Using Python 3.6 base image\n",
      "20-06-28:05:07:39 INFO     [clipper_admin.py:534] [default-cluster] Building model Docker image with model data from /tmp/tmpx2baqe9xclipper\n",
      "20-06-28:05:07:52 INFO     [clipper_admin.py:539] [default-cluster] Step 1/3 : FROM clipper/tf36-container:0.4.1\n",
      "20-06-28:05:07:52 INFO     [clipper_admin.py:539] [default-cluster]  ---> 3db42af800ff\n",
      "20-06-28:05:07:52 INFO     [clipper_admin.py:539] [default-cluster] Step 2/3 : RUN apt-get -y install build-essential && pip install numpy\n",
      "20-06-28:05:07:52 INFO     [clipper_admin.py:539] [default-cluster]  ---> Using cache\n",
      "20-06-28:05:07:52 INFO     [clipper_admin.py:539] [default-cluster]  ---> 471953624095\n",
      "20-06-28:05:07:52 INFO     [clipper_admin.py:539] [default-cluster] Step 3/3 : COPY /tmp/tmpx2baqe9xclipper /model/\n",
      "20-06-28:05:07:52 INFO     [clipper_admin.py:539] [default-cluster]  ---> 701a98522397\n",
      "20-06-28:05:07:52 INFO     [clipper_admin.py:539] [default-cluster] Successfully built 701a98522397\n",
      "20-06-28:05:07:52 INFO     [clipper_admin.py:539] [default-cluster] Successfully tagged default-cluster-faster-mod:1\n",
      "20-06-28:05:07:52 INFO     [clipper_admin.py:541] [default-cluster] Pushing model Docker image to default-cluster-faster-mod:1\n",
      "20-06-28:05:07:57 INFO     [docker_container_manager.py:409] [default-cluster] Found 0 replicas for faster-mod:1. Adding 1\n",
      "20-06-28:05:07:58 INFO     [clipper_admin.py:724] [default-cluster] Successfully registered model faster-mod:1\n",
      "20-06-28:05:07:58 INFO     [clipper_admin.py:642] [default-cluster] Done deploying model faster-mod:1.\n",
      "20-06-28:05:07:59 INFO     [clipper_admin.py:303] [default-cluster] Model faster-mod is now linked to application faster-app\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "这是测试数据哦 {'image': array([[[[-121.7717  , -114.9465  , -102.9801  ],\n",
      "         [-121.7717  , -114.9465  , -102.9801  ],\n",
      "         [-121.7717  , -114.9465  , -102.9801  ],\n",
      "         ...,\n",
      "         [-120.80087 , -111.97568 , -100.00928 ],\n",
      "         [-121.38919 , -112.563995, -100.597595],\n",
      "         [-121.7717  , -112.9465  , -100.9801  ]],\n",
      "\n",
      "        [[-121.7717  , -114.9465  , -102.9801  ],\n",
      "         [-121.7717  , -114.9465  , -102.9801  ],\n",
      "         [-121.7717  , -114.9465  , -102.9801  ],\n",
      "         ...,\n",
      "         [-120.80087 , -111.97568 , -100.00928 ],\n",
      "         [-121.38919 , -112.563995, -100.597595],\n",
      "         [-121.7717  , -112.9465  , -100.9801  ]],\n",
      "\n",
      "        [[-121.7717  , -114.9465  , -102.9801  ],\n",
      "         [-121.7717  , -114.9465  , -102.9801  ],\n",
      "         [-121.7717  , -114.9465  , -102.9801  ],\n",
      "         ...,\n",
      "         [-120.80087 , -111.97568 , -100.00928 ],\n",
      "         [-121.38919 , -112.563995, -100.597595],\n",
      "         [-121.7717  , -112.9465  , -100.9801  ]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-108.23404 ,  -92.408844,  -40.44244 ],\n",
      "         [-107.416534,  -90.06134 ,  -39.624935],\n",
      "         [-106.15911 ,  -86.450584,  -38.367508],\n",
      "         ...,\n",
      "         [ -91.03569 ,  -55.327194,   17.843428],\n",
      "         [ -91.82255 ,  -58.467323,   18.821527],\n",
      "         [ -92.33414 ,  -60.50894 ,   19.45746 ]],\n",
      "\n",
      "        [[-115.88257 , -100.05737 ,  -48.09097 ],\n",
      "         [-110.78924 ,  -93.434044,  -42.997643],\n",
      "         [-102.95506 ,  -83.24653 ,  -35.163464],\n",
      "         ...,\n",
      "         [ -92.263885,  -56.55539 ,   16.615236],\n",
      "         [ -94.08915 ,  -60.733925,   16.55493 ],\n",
      "         [ -95.27588 ,  -63.45068 ,   16.515718]],\n",
      "\n",
      "        [[-119.7717  , -103.9465  ,  -51.980103],\n",
      "         [-112.504196,  -95.149   ,  -44.712597],\n",
      "         [-101.32587 ,  -81.61733 ,  -33.534267],\n",
      "         ...,\n",
      "         [ -92.8884  ,  -57.179897,   15.990725],\n",
      "         [ -95.24167 ,  -61.886444,   15.402407],\n",
      "         [ -96.7717  ,  -64.9465  ,   15.0199  ]]]], dtype=float32), 'scale': 1.6997167138810199, 'cls': array([12, 15], dtype=int32), 'box': array([[ 79.88668 , 406.2323  , 329.74503 , 628.8952  ],\n",
      "       [ 11.898017,  18.696884, 596.6006  , 844.7592  ]], dtype=float32), 'imname': '/root/VOCdevkit/VOC2007_test/JPEGImages/000001.jpg'}\n",
      "睡10秒再请求\n",
      "{\"query_id\":0,\"output\":-1.0,\"default\":true,\"default_explanation\":\"Failed to retrieve a prediction response within the specified latency SLO\"}\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import base64\n",
    "import json\n",
    "import requests\n",
    "from PIL import Image\n",
    "from datetime import datetime\n",
    "\n",
    "import time\n",
    "\n",
    "class MyEncoder(json.JSONEncoder):\n",
    "    def default(self, obj):\n",
    "        if isinstance(obj, np.integer):\n",
    "            return int(obj)\n",
    "        elif isinstance(obj, np.floating):\n",
    "            return float(obj)\n",
    "        elif isinstance(obj, np.ndarray):\n",
    "            return obj.tolist()\n",
    "        if isinstance(obj, time):\n",
    "            return obj.__str__()\n",
    "        else:\n",
    "            return super(NpEncoder, self).default(obj)\n",
    "\n",
    "\n",
    "class Val_test(object):   \n",
    "    def __init__(self, net ,val_data):\n",
    "        self.net = net\n",
    "        self.val_data = val_data\n",
    "        self.overlaps_max = cfg.overlaps_max\n",
    "#         self.graph = tf.get_default_graph()\n",
    "        self.overlaps_min = cfg.overlaps_min\n",
    "        self.ckpt_filename = tf.train.latest_checkpoint(cfg.OUTPUT_DIR)\n",
    "        self.test_output_dir = cfg.test_output_path\n",
    "        self.image_output_dir = cfg.image_output_dir\n",
    "        \n",
    "        \n",
    "    def test_model(self):\n",
    "        saver = tf.train.Saver()\n",
    "#         saver = tf.train.import_meta_graph('/root/code/Faster-rcnn-tensorflow-master_1/output/output.model-70000.meta')\n",
    "\n",
    "        _rois_coord = self.net.rois_coord[:,1:5]\n",
    "        #rois_coord = self.net.rois_coord\n",
    "        _pred_box = self.net.bbox_pred\n",
    "        _pred_score = self.net.cls_prob\n",
    "        _pred_box_score_arg = tf.argmax(_pred_score, axis=1)\n",
    "        dect_total_result = [[[] for i in range(cfg.img_save_num)] for j in range(self.net.num_classes)]\n",
    "        test_data = [[] for i in range (cfg.img_save_num)]\n",
    "        with tf.Session() as sess:\n",
    "            saver.restore(sess, self.ckpt_filename)\n",
    "            \n",
    "            print('所有的变量名字 在这里 ')\n",
    "#             print([n.name for n in graph.as_graph_def().node])\n",
    "\n",
    "#             for node in sess.graph_def.node:\n",
    "#                 print(node)\n",
    "            print('结束了')\n",
    "            #部署clipper预测容器 \n",
    "            \n",
    "            deploy_tensorflow_model(clipper_conn,name=\"faster-mod\",version=1,input_type=\"strings\",func=predict2,\n",
    "            tf_sess_or_saved_model_path=sess,pkgs_to_install=['numpy'])\n",
    "            \n",
    "            clipper_conn.link_model_to_app(app_name=\"faster-app\",model_name=\"faster-mod\")\n",
    "            \n",
    "            query_address = clipper_conn.get_query_addr()\n",
    "            \n",
    "            url = \"http://%s/faster-app/predict\" %  query_address\n",
    "            \n",
    "#             for i in range (cfg.img_save_num):\n",
    "#                 print (i, ' image test compeleted')            \n",
    "            train_data = self.val_data.get()  #if you want to change the test imgae, you can using cv2.imread() here to read your own image data\n",
    "\n",
    "\n",
    "            print('这是测试数据哦',train_data)\n",
    "            tva = json.dumps([train_data],cls=MyEncoder)\n",
    "\n",
    "            tva_j = json.dumps({\"input\": tva})\n",
    "            headers = {'Content-type': 'application/json'}\n",
    "            start = datetime.now()\n",
    "            print('睡10秒再请求')\n",
    "            \n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "#             return None\n",
    "\n",
    "        \n",
    "            time.sleep(10)\n",
    "            r = requests.post(url, headers=headers, data=tva_j)\n",
    "            end = datetime.now()\n",
    "            latency = (end - start).total_seconds() * 1000.0\n",
    "            re = r.text\n",
    "\n",
    "            print(re)\n",
    "            return re\n",
    "\n",
    "\n",
    "# #             os.exit()\n",
    "\n",
    "#             pred_box_score_arg = pred_box_score_arg.astype(np.int32)\n",
    "#             num_pred = pred_box_score_arg.shape[0]\n",
    "#             pred_box_gather = np.empty([num_pred, 4], dtype = np.float32)\n",
    "#             pred_score_gather = np.empty(num_pred)\n",
    "\n",
    "#             for j in range(num_pred):\n",
    "#                 pred_box_gather[j, :] = pred_box[j, 4*pred_box_score_arg[j]:4*(pred_box_score_arg[j]+1)]\n",
    "#                 pred_score_gather[j] = pred_score[j, pred_box_score_arg[j]]\n",
    "\n",
    "#             pred_box_gather = pred_box_gather * np.array(cfg.bbox_nor_stdv) + np.array(cfg.bbox_nor_mean)\n",
    "#             pre_box_coord = self.coord_transform_inv(rois_coord, pred_box_gather.astype(np.float32))\n",
    "#             pre_box_coord = pre_box_coord\n",
    "#             for k in range(1, self.net.num_classes):\n",
    "#                 pre_class_arg = np.where(pred_box_score_arg==k)[0]\n",
    "#                 cls_pred_box_coord = pre_box_coord[pre_class_arg, :]\n",
    "#                 cls_pred_score = pred_score_gather[pre_class_arg]\n",
    "#                 #print(cls_pred_box_coord.shape, cls_pred_score.shape)\n",
    "#                 cls_pred_score = cls_pred_score[:, np.newaxis]  \n",
    "#                 cls_pred_target = np.concatenate((cls_pred_box_coord, cls_pred_score), axis=1)\n",
    "#                 keep = py_cpu_nms(cls_pred_target, cfg.test_nms_thresh)\n",
    "#                 cls_pred_target = cls_pred_target[keep, :]\n",
    "#                 dect_total_result[k][i] = cls_pred_target\n",
    "\n",
    "#             for k in range(cfg.img_save_num):\n",
    "#                 imname = test_data[k]['imname']\n",
    "#                 im_scale = test_data[k]['scale']\n",
    "#                 image = cv2.imread(imname)\n",
    "#                 im = cv2.resize(image, None, None, fx=im_scale, fy=im_scale, interpolation=cv2.INTER_LINEAR)\n",
    "#                 im = self.draw_result(im, dect_total_result, k)\n",
    "#                 if not os.path.exists(self.image_output_dir):\n",
    "#                     os.mkdir(self.image_output_dir)\n",
    "#                 im_save_path = os.path.join(self.image_output_dir, '{:d}'.format(k)+'.jpg')\n",
    "#                 cv2.imwrite(im_save_path, im)\n",
    "                \n",
    "                \n",
    "# #                 cv2.imshow('Image',im)#这里有环境问题\n",
    "# #                 cv2.destroyAllWindows()\n",
    "#                 plt.figure(figsize=(10,10))\n",
    "        \n",
    "#                 im = Image.open(im_save_path)\n",
    "#                 plt.imshow(im)  #显示需要识别的图片\n",
    "#                 plt.show()\n",
    "                \n",
    "                \n",
    "                \n",
    "                \n",
    "#                 cv2.waitKey(0)\n",
    "\n",
    "\n",
    "    def draw_result(self, img, result, ind):\n",
    "        for i in range(1, self.net.num_classes):\n",
    "            for j in range(result[i][ind].shape[0]):\n",
    "                if result[i][ind][j][4]>0.5:\n",
    "                    x1 = int(result[i][ind][j][0])\n",
    "                    y1 = int(result[i][ind][j][1])\n",
    "                    x2 = int(result[i][ind][j][2])\n",
    "                    y2 = int(result[i][ind][j][3])                    \n",
    "                    cv2.rectangle(img, (x1, y1), (x2, y2), ((i%19)*15, (i%3)*100+40, (i%6)*50+35), 2) \n",
    "                    cv2.rectangle(img, (x1, y1-20),(x2, y1), (125, 125, 125), -1)\n",
    "                    lineType = cv2.LINE_AA if cv2.__version__ > '3' else cv2.CV_AA\n",
    "                    cv2.putText(img, cfg.CLASSES[i] + ' : %.2f' % result[i][ind][j][4],\\\n",
    "                    (x1 + 5, y1 - 7), cv2.FONT_HERSHEY_SIMPLEX, 0.5,\\\n",
    "                    (0, 0, 0), 1, lineType)                \n",
    "        return img\n",
    "        \n",
    "        \n",
    "    def coord_transform_inv (self, anchors, boxes):\n",
    "        anchors = anchors.astype(np.float32)\n",
    "        anchors = np.reshape(anchors, [-1,4])\n",
    "        anchor_x = (anchors[:,2] + anchors[:,0]) * 0.5\n",
    "        anchor_y = (anchors[:,3] + anchors[:,1]) * 0.5\n",
    "        acnhor_w = (anchors[:,2] - anchors[:,0]) + 1.0\n",
    "        acnhor_h = (anchors[:,3] - anchors[:,1]) + 1.0\n",
    "        boxes = np.reshape(boxes, [-1,4])\n",
    "        boxes_x = boxes[:,0]*acnhor_w + anchor_x\n",
    "        boxes_y = boxes[:,1]*acnhor_h + anchor_y\n",
    "        boxes_w = np.exp(boxes[:,2])*acnhor_w\n",
    "        boxes_h = np.exp(boxes[:,3])*acnhor_h\n",
    "        coord_x1 = boxes_x - boxes_w*0.5\n",
    "        coord_y1 = boxes_y - boxes_h*0.5\n",
    "        coord_x2 = boxes_x + boxes_w*0.5\n",
    "        coord_y2 = boxes_y + boxes_h*0.5\n",
    "        coord_result = np.stack([coord_x1, coord_y1, coord_x2, coord_y2], axis=1)\n",
    "        return coord_result                  \n",
    "    \n",
    "    \n",
    "#get variables_to_restore               \n",
    "    def get_var_list(self, global_variables, ckpt_variables):\n",
    "        variables_to_restore = []\n",
    "        for key in global_variables:\n",
    "            if key.name.split(':')[0] in ckpt_variables:\n",
    "                variables_to_restore.append(key) \n",
    "        return variables_to_restore\n",
    "    \n",
    "    \n",
    "\n",
    "if __name__ == '__main__':\n",
    "    os.environ['CUDA_VISIBLE_DEVICES'] = cfg.GPU_ID\n",
    "#     import os\n",
    "#     os.environ['TF_CPP_MIN_LOG_LEVEL'] = '0'\n",
    "    net = network.Net(is_training=False)\n",
    "    val_data = pascl.pascal_voc(cfg.test_imdb_name, 'test', fliped=False)\n",
    "    test = Val_test(net, val_data)\n",
    "    print ('start training')\n",
    "    test.test_model()\n",
    "#     sess = test.test_model()#把sess传出来"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_data = pascl.pascal_voc(cfg.test_imdb_name, 'test', fliped=False)\n",
    "query_address = clipper_conn.get_query_addr()\n",
    "\n",
    "url = \"http://%s/faster-app/predict\" %  query_address\n",
    "\n",
    "#             for i in range (cfg.img_save_num):\n",
    "#                 print (i, ' image test compeleted')            \n",
    "train_data = val_data.get()  #if you want to change the test imgae, you can using cv2.imread() here to read your own image data\n",
    "\n",
    "print(len(train_data))\n",
    "\n",
    "#clipper要求输入必须为 字符串 故必须要序列化下\n",
    "# list1 = {'image':[[1,2,3]]}\n",
    "tva = json.dumps([train_data],cls=MyEncoder)\n",
    "# tva = json.dumps([list1],cls=MyEncoder)\n",
    "# tva = [train_data]\n",
    "\n",
    "print(tva)\n",
    "tva_j = json.dumps({\"input\": tva})\n",
    "print(tva_j)\n",
    "#此处可看出 输入的最终数据为  [{\"image\": [[1, 2, 3]]}] \n",
    "#clipper 接收到的数据为 [b'[{\"image\": [[1, 2, 3]]}]' b'[{\"image\": [[1, 2, 3]]}]']\n",
    "headers = {'Content-type': 'application/json'}\n",
    "start = datetime.now()\n",
    "r = requests.post(url, headers=headers, data=tva_j)\n",
    "end = datetime.now()\n",
    "latency = (end - start).total_seconds() * 1000.0\n",
    "re = r.text\n",
    "\n",
    "print(re)\n",
    "\n",
    "#docker 日志显示 ValueError: callback pyfunc_0 is not found 报错 疑似 线 程 问 题  \n",
    "#原文件在预测时 是在同一个线程 但是 我们把sess部署到clipper上 时线程改变了 故找不到相关参数 \n",
    "# 正在找解决办法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len([train_data]))\n",
    "print([train_data][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict1(sess,train_data):\n",
    "    import numpy as np\n",
    "    num_imgs = len(train_data)\n",
    "#     print('这是啥',train_data,num_imgs)\n",
    "    result = []\n",
    "    for i in range(num_imgs):\n",
    "        data =train_data\n",
    "#         data = json.loads(train_data[i])\n",
    "#         print(data,type(data),type(i),type(train_data))\n",
    "#         test_data[i] = data\n",
    "        image_height = np.array(data['image'].shape[1])\n",
    "        image_width = np.array(data['image'].shape[2])\n",
    "        feed_dict = {\"Placeholder:0\": data['image'], \"Placeholder_1:0\": image_width,\\\n",
    "                     \"Placeholder_2:0\": image_height}\n",
    "        rois_coord, pred_box, pred_box_score_arg, pred_score= sess.run([\"strided_slice_13:0\", \"vgg_16_2/region_deciton/bbox_pred/BiasAdd:0\",\n",
    "                                                                        \"ArgMax:0\", \"vgg_16_2/region_deciton/cls_prob:0\"],\\\n",
    "                                                                feed_dict=feed_dict)\n",
    "        result.extend([str(rois_coord), str(pred_box), str(pred_box_score_arg), str(pred_score)])\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_data = pascl.pascal_voc(cfg.test_imdb_name, 'test', fliped=False)\n",
    "train_data = val_data.get() \n",
    "predict1(sess,train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20-06-28:23:13:21 INFO     [clipper_admin.py:1424] [default-cluster] Stopped all Clipper cluster and all model containers\n"
     ]
    }
   ],
   "source": [
    "clipper_conn.stop_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
