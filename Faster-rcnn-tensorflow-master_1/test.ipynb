{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:\n",
      "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "WARNING:tensorflow:From E:\\jupyter_deep\\Faster-rcnn-tensorflow-master\\network.py:28: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From E:\\jupyter_deep\\Faster-rcnn-tensorflow-master\\network.py:104: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
      "\n",
      "WARNING:tensorflow:From D:\\ProgramData\\Anaconda3\\envs\\tensor1\\lib\\site-packages\\tensorflow_core\\contrib\\layers\\python\\layers\\layers.py:1057: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `layer.__call__` method instead.\n",
      "WARNING:tensorflow:From E:\\jupyter_deep\\Faster-rcnn-tensorflow-master\\network.py:75: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "tf.py_func is deprecated in TF V2. Instead, there are two\n",
      "    options available in V2.\n",
      "    - tf.py_function takes a python function which manipulates tf eager\n",
      "    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to\n",
      "    an ndarray (just call tensor.numpy()) but having access to eager tensors\n",
      "    means `tf.py_function`s can use accelerators such as GPUs as well as\n",
      "    being differentiable using a gradient tape.\n",
      "    - tf.numpy_function maintains the semantics of the deprecated tf.py_func\n",
      "    (it is not differentiable, and manipulates numpy arrays). It drops the\n",
      "    stateful argument making all functions stateful.\n",
      "    \n",
      "WARNING:tensorflow:From E:\\jupyter_deep\\Faster-rcnn-tensorflow-master\\network.py:192: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.cast` instead.\n",
      "WARNING:tensorflow:From E:\\jupyter_deep\\Faster-rcnn-tensorflow-master\\network.py:247: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.cast` instead.\n",
      "WARNING:tensorflow:From E:\\jupyter_deep\\Faster-rcnn-tensorflow-master\\network.py:247: calling crop_and_resize_v1 (from tensorflow.python.ops.image_ops_impl) with box_ind is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "box_ind is deprecated, use box_indices instead\n",
      "WARNING:tensorflow:From D:\\ProgramData\\Anaconda3\\envs\\tensor1\\lib\\site-packages\\tensorflow_core\\contrib\\layers\\python\\layers\\layers.py:1634: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.flatten instead.\n",
      "WARNING:tensorflow:From E:\\jupyter_deep\\Faster-rcnn-tensorflow-master\\network.py:266: The name tf.summary.image is deprecated. Please use tf.compat.v1.summary.image instead.\n",
      "\n",
      "Processing gt_labels from: dataset\\VOCdevkit\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'dataset\\\\VOCdevkit\\\\VOC2012_test\\\\ImageSets\\\\Main\\\\test.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-56fccb2992ed>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    197\u001b[0m     \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'CUDA_VISIBLE_DEVICES'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcfg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mGPU_ID\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m     \u001b[0mnet\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnetwork\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mNet\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mis_training\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 199\u001b[1;33m     \u001b[0mval_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpascl\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpascal_voc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcfg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtest_imdb_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'test'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfliped\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    200\u001b[0m     \u001b[0mtest\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mVal_test\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    201\u001b[0m     \u001b[0mprint\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m'start training'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\jupyter_deep\\Faster-rcnn-tensorflow-master\\pascal_voc.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, name, phase, fliped, rebuild)\u001b[0m\n\u001b[0;32m     25\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mepoch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m         \u001b[1;31m#self.gt_labels = None\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 27\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgt_labels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcombine_imdb\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     28\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnum_gtlabels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgt_labels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\jupyter_deep\\Faster-rcnn-tensorflow-master\\pascal_voc.py\u001b[0m in \u001b[0;36mcombine_imdb\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m     30\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mcombine_imdb\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m         \u001b[1;34m\"\"\" combine VOC2007 imdb and VOC2012 imdb\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 32\u001b[1;33m         \u001b[0mgt_labels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprepare\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimdb_name\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mimdb_name\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'+'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     33\u001b[0m         \u001b[0mgt_label\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgt_labels\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgt_labels\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\jupyter_deep\\Faster-rcnn-tensorflow-master\\pascal_voc.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     30\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mcombine_imdb\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m         \u001b[1;34m\"\"\" combine VOC2007 imdb and VOC2012 imdb\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 32\u001b[1;33m         \u001b[0mgt_labels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprepare\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimdb_name\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mimdb_name\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'+'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     33\u001b[0m         \u001b[0mgt_label\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgt_labels\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgt_labels\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\jupyter_deep\\Faster-rcnn-tensorflow-master\\pascal_voc.py\u001b[0m in \u001b[0;36mprepare\u001b[1;34m(self, imdb_name)\u001b[0m\n\u001b[0;32m     70\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mprepare\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimdb_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     71\u001b[0m         \u001b[1;34m\"\"\"prepare the imdb, if pkl exists, you can load the pkl file\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 72\u001b[1;33m         \u001b[0mgt_labels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_labels\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimdb_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     73\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflipped\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Appending horizontally-flipped training examples ...'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#{'boxes':boxes, 'gt_classs':gt_classes, 'imname':imname}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\jupyter_deep\\Faster-rcnn-tensorflow-master\\pascal_voc.py\u001b[0m in \u001b[0;36mload_labels\u001b[1;34m(self, imdb_name)\u001b[0m\n\u001b[0;32m    110\u001b[0m                 self.devkil_path, imdb_name, 'ImageSets', 'Main', self.phase + '.txt')\n\u001b[0;32m    111\u001b[0m             \u001b[1;31m#self.flipped = False\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 112\u001b[1;33m         \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtxtname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'r'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    113\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimage_index\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreadlines\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    114\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'dataset\\\\VOCdevkit\\\\VOC2012_test\\\\ImageSets\\\\Main\\\\test.txt'"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Created on Thu Oct 25 09:54:12 2018\n",
    "\n",
    "@author: LongJun\n",
    "\"\"\"\n",
    "\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import config as cfg\n",
    "import os\n",
    "import pascal_voc as pascl\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import network\n",
    "import datetime\n",
    "import cv2\n",
    "from nms import py_cpu_nms\n",
    "#Val_test class is used to test the output model, the result is mean_ap tested on the pascal_voc 2007 test_imdb\n",
    "#net： VGG16\n",
    "#val_data: val_data name\n",
    "class Val_test(object):   \n",
    "    def __init__(self, net ,val_data):\n",
    "        self.net = net\n",
    "        self.val_data = val_data\n",
    "        self.overlaps_max = cfg.overlaps_max\n",
    "        self.overlaps_min = cfg.overlaps_min\n",
    "        self.ckpt_filename = tf.train.latest_checkpoint(os.path.join(cfg.OUTPUT_DIR))\n",
    "        self.test_output_dir = cfg.test_output_path\n",
    "        self.image_output_dir = cfg.image_output_dir\n",
    "        txtname = os.path.join(self.val_data.devkil_path, self.val_data.name, 'ImageSets', 'Main', self.val_data.phase+'.txt')\n",
    "        with open(txtname) as f:\n",
    "            self.image_index = [x.strip() for x in f.readlines()]\n",
    "\n",
    "    def test_model(self):\n",
    "        saver = tf.train.Saver()\n",
    "        _rois_coord = self.net.rois_coord[:,1:5]\n",
    "        #rois_coord = self.net.rois_coord\n",
    "        _pred_box = self.net.bbox_pred\n",
    "        _pred_score = self.net.cls_prob\n",
    "        #_pred_box_score_arg = tf.argmax(_pred_score, axis=1)\n",
    "        dect_total_result = [[[] for i in range(self.val_data.num_gtlabels)] for j in range(self.net.num_classes)]\n",
    "        with tf.Session() as sess:\n",
    "            saver.restore(sess, self.ckpt_filename)\n",
    "            for i in range (self.val_data.num_gtlabels):\n",
    "                print (i, ' image test compeleted')            \n",
    "                train_data = self.val_data.get()\n",
    "                image_height = np.array(train_data['image'].shape[1])\n",
    "                image_width = np.array(train_data['image'].shape[2])\n",
    "                feed_dict = {self.net.image: train_data['image'], self.net.image_width: image_width,\\\n",
    "                             self.net.image_height: image_height}\n",
    "                                \n",
    "                rois_coord, pred_box, pred_score= sess.run([_rois_coord, _pred_box, _pred_score],\\\n",
    "                                                                        feed_dict=feed_dict) \n",
    "\n",
    "                for k in range(1, self.net.num_classes):    \n",
    "                    #pre_class_arg = np.where(pred_score[:,k]>=0)[0]\n",
    "                    cls_pred_box_target = pred_box[:, k*4:(k+1)*4]\n",
    "                    cls_pred_box_target = cls_pred_box_target * np.array(cfg.bbox_nor_stdv) + np.array(cfg.bbox_nor_mean)\n",
    "                    cls_pred_box_coord = self.coord_transform_inv(rois_coord, cls_pred_box_target.astype(np.float32))\n",
    "                    cls_pred_box_coord = cls_pred_box_coord/train_data['scale'] + 1.0\n",
    "                    cls_pred_score = pred_score[:, k]\n",
    "                    #print(cls_pred_box_coord.shape, cls_pred_score.shape)\n",
    "                    cls_pred_score = cls_pred_score[:, np.newaxis]  \n",
    "                    cls_pred_target = np.concatenate((cls_pred_box_coord, cls_pred_score), axis=1)\n",
    "                    keep = py_cpu_nms(cls_pred_target, cfg.test_nms_thresh)\n",
    "                    cls_pred_target = cls_pred_target[keep, :]\n",
    "                    dect_total_result[k][i] = cls_pred_target\n",
    "                   # print (cls_pred_target)\n",
    "                image_scores = np.hstack([dect_total_result[j][i][:, -1] for j in range(1, self.net.num_classes)]) #\n",
    "                if len(image_scores) > cfg.test_max_per_image:\n",
    "                    image_thresh = np.sort(image_scores)[-cfg.test_max_per_image] #\n",
    "                    for j in range(1, self.net.num_classes):\n",
    "                        keep = np.where(dect_total_result[j][i][:, -1] >= image_thresh)[0]\n",
    "                        dect_total_result[j][i] = dect_total_result[j][i][keep, :] #\n",
    "            mean_ap = self.map_compute(dect_total_result)\n",
    "            print ('the mean_ap of pascal_voc 2007 is', mean_ap)\n",
    "        \n",
    "        \n",
    "    def coord_transform_inv (self, anchors, boxes):\n",
    "        anchors = anchors.astype(np.float32)\n",
    "        anchors = np.reshape(anchors, [-1,4])\n",
    "        anchor_x = (anchors[:,2] + anchors[:,0]) * 0.5\n",
    "        anchor_y = (anchors[:,3] + anchors[:,1]) * 0.5\n",
    "        acnhor_w = (anchors[:,2] - anchors[:,0]) + 1.0\n",
    "        acnhor_h = (anchors[:,3] - anchors[:,1]) + 1.0\n",
    "        boxes = np.reshape(boxes, [-1,4])\n",
    "        boxes_x = boxes[:,0]*acnhor_w + anchor_x\n",
    "        boxes_y = boxes[:,1]*acnhor_h + anchor_y\n",
    "        boxes_w = np.exp(boxes[:,2])*acnhor_w\n",
    "        boxes_h = np.exp(boxes[:,3])*acnhor_h\n",
    "        coord_x1 = boxes_x - boxes_w*0.5\n",
    "        coord_y1 = boxes_y - boxes_h*0.5\n",
    "        coord_x2 = boxes_x + boxes_w*0.5\n",
    "        coord_y2 = boxes_y + boxes_h*0.5\n",
    "        coord_result = np.stack([coord_x1, coord_y1, coord_x2, coord_y2], axis=1)\n",
    "        return coord_result              \n",
    "\n",
    "\n",
    "#computing map using pascal_voc 2010 algorithm\n",
    "    def map_compute(self, dect_boxes):\n",
    "        ap = []\n",
    "        for cls_ind, cls in enumerate(self.val_data.classes):\n",
    "            cls_obj = {}\n",
    "            num_cls_obj = 0\n",
    "            if cls == 'background':\n",
    "                 continue\n",
    "            if not os.path.exists(self.test_output_dir):\n",
    "                os.mkdir(self.test_output_dir)\n",
    "            cls_filename = os.path.join(self.test_output_dir, cls+'.txt')\n",
    "            with open(cls_filename, 'w') as f:\n",
    "                 for img_ind_dex, image_ind in enumerate(self.image_index):\n",
    "                      dect_box = dect_boxes[cls_ind][img_ind_dex]\n",
    "                      if dect_box == []:\n",
    "                           continue\n",
    "                      for i in range(dect_box.shape[0]):\n",
    "                           f.write('{:s} {:2f} {:2f} {:2f} {:2f} {:3f} \\n'.format\\\n",
    "                                   (image_ind, dect_box[i][0], dect_box[i][1], dect_box[i][2],\\\n",
    "                                    dect_box[i][3], dect_box[i][4]))\n",
    "                           \n",
    "            for gt_label in self.val_data.gt_labels:\n",
    "                 gt_label_cls_ind = np.where(gt_label['gt_classs']==cls_ind)[0]\n",
    "                 gt_label_pick_box = gt_label['boxes'][gt_label_cls_ind, :]\n",
    "                 gt_label_pick_cls = gt_label['gt_classs'][gt_label_cls_ind]\n",
    "                 diff_pick = gt_label['diff'][gt_label_cls_ind].astype(np.bool)\n",
    "                 dec_id = [False] * gt_label_cls_ind.size\n",
    "                 num_cls_obj = num_cls_obj + sum(~diff_pick)\n",
    "                 cls_obj[gt_label['image_index']] = {'bbox': gt_label_pick_box,\\\n",
    "                                                      'cls': gt_label_pick_cls,\\\n",
    "                                                      'dec_id': dec_id, 'diff': diff_pick}\n",
    "                 #print (num_cls_obj)\n",
    "            with open(cls_filename, 'r') as f:\n",
    "              lines = f.readlines()\n",
    "            splitlines = [x.strip().split(' ') for x in lines] \n",
    "            image_ids = [x[0] for x in splitlines]  \n",
    "            confidence = np.array([float(x[5]) for x in splitlines])\n",
    "            BB = np.array([[float(z) for z in x[1:5]] for x in splitlines]) #bounding box                 \n",
    "            \n",
    "            nd = len(image_ids)                   \n",
    "            tp = np.zeros(nd)         \n",
    "            fp = np.zeros(nd)\n",
    "            \n",
    "            if BB.shape[0] > 0:\n",
    "                 sorted_ind = np.argsort(-confidence) \n",
    "                 BB = BB[sorted_ind, :]\n",
    "                 image_ids = [image_ids[x] for x in sorted_ind] \n",
    "                 for d in range(nd): \n",
    "                      R = cls_obj[image_ids[d]] \n",
    "                      bb = BB[d, :].astype(float) \n",
    "                      ovmax = -np.inf \n",
    "                      BBGT = R['bbox'].astype(float) \n",
    "                      \n",
    "                      if BBGT.size > 0: \n",
    "                           ixmin = np.maximum(BBGT[:, 0], bb[0])\n",
    "                           iymin = np.maximum(BBGT[:, 1], bb[1])\n",
    "                           ixmax = np.minimum(BBGT[:, 2], bb[2])\n",
    "                           iymax = np.minimum(BBGT[:, 3], bb[3])\n",
    "                           iw = np.maximum(ixmax - ixmin + 1., 0.)\n",
    "                           ih = np.maximum(iymax - iymin + 1., 0.)\n",
    "                           inters = iw * ih\n",
    "                           uni = ((bb[2] - bb[0] + 1.) * (bb[3] - bb[1] + 1.) +\\\n",
    "                                  (BBGT[:, 2] - BBGT[:, 0] + 1.) *\\\n",
    "                                  (BBGT[:, 3] - BBGT[:, 1] + 1.) - inters)\n",
    "                           overlaps = inters / uni\n",
    "                           ovmax = np.max(overlaps) \n",
    "                           jmax = np.argmax(overlaps) \n",
    "                           \n",
    "                      if ovmax > cfg.test_fp_tp_thresh:\n",
    "                           if not R['diff'][jmax]:\n",
    "                               if not R['dec_id'][jmax]: \n",
    "                                    tp[d] = 1.\n",
    "                                    R['dec_id'][jmax] = 1 \n",
    "                               else:\n",
    "                                    fp[d] = 1.\n",
    "                      else:\n",
    "                           fp[d] = 1. \n",
    "            fp = np.cumsum(fp) \n",
    "            tp = np.cumsum(tp) \n",
    "            rec = tp / float(num_cls_obj) \n",
    "            prec = tp / np.maximum(tp + fp, np.finfo(np.float64).eps) \n",
    "            ap.append(self.val_data.voc_ap(rec, prec)) \t\n",
    "            print (np.mean(ap))\n",
    "        return sum(ap)/(self.net.num_classes - 1.0)\n",
    "    \n",
    "                   \n",
    "    def get_var_list(self, global_variables, ckpt_variables):\n",
    "        variables_to_restore = []\n",
    "        for key in global_variables:\n",
    "            if key.name.split(':')[0] in ckpt_variables:\n",
    "                variables_to_restore.append(key) \n",
    "        return variables_to_restore\n",
    "    \n",
    "    \n",
    "\n",
    "if __name__ == '__main__':\n",
    "    os.environ['CUDA_VISIBLE_DEVICES'] = cfg.GPU_ID\n",
    "    net = network.Net(is_training=False)\n",
    "    val_data = pascl.pascal_voc(cfg.test_imdb_name, 'test', fliped=False)\n",
    "    test = Val_test(net, val_data)\n",
    "    print ('start training')\n",
    "    test.test_model()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
