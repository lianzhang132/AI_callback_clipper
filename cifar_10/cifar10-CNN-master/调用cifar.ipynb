{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/pandas/compat/__init__.py:117: UserWarning: Could not import the lzma module. Your installed Python is incomplete. Attempting to use lzma compression will result in a RuntimeError.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /root/code/cifar_10/cifar10-CNN-master/cifar10_input.py:114: The name tf.gfile.Exists is deprecated. Please use tf.io.gfile.exists instead.\n",
      "\n",
      "WARNING:tensorflow:From /root/code/cifar_10/cifar10-CNN-master/cifar10_input.py:118: string_input_producer (from tensorflow.python.training.input) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.from_tensor_slices(string_tensor).shuffle(tf.shape(input_tensor, out_type=tf.int64)[0]).repeat(num_epochs)`. If `shuffle=False`, omit the `.shuffle(...)`.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/site-packages/tensorflow_core/python/training/input.py:277: input_producer (from tensorflow.python.training.input) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.from_tensor_slices(input_tensor).shuffle(tf.shape(input_tensor, out_type=tf.int64)[0]).repeat(num_epochs)`. If `shuffle=False`, omit the `.shuffle(...)`.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/site-packages/tensorflow_core/python/training/input.py:189: limit_epochs (from tensorflow.python.training.input) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.from_tensors(tensor).repeat(num_epochs)`.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/site-packages/tensorflow_core/python/training/input.py:198: QueueRunner.__init__ (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/site-packages/tensorflow_core/python/training/input.py:198: add_queue_runner (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "WARNING:tensorflow:From /root/code/cifar_10/cifar10-CNN-master/cifar10_input.py:40: FixedLengthRecordReader.__init__ (from tensorflow.python.ops.io_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.FixedLengthRecordDataset`.\n",
      "WARNING:tensorflow:From /root/code/cifar_10/cifar10-CNN-master/cifar10_input.py:126: The name tf.image.resize_image_with_crop_or_pad is deprecated. Please use tf.image.resize_with_crop_or_pad instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/site-packages/tensorflow_core/python/ops/image_ops_impl.py:1518: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Deprecated in favor of operator or tf.math.divide.\n",
      "WARNING:tensorflow:From /root/code/cifar_10/cifar10-CNN-master/cifar10_input.py:136: batch (from tensorflow.python.training.input) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.batch(batch_size)` (or `padded_batch(...)` if `dynamic_pad=True`).\n",
      "WARNING:tensorflow:From /root/code/cifar_10/cifar10-CNN-master/cifar10_input.py:137: The name tf.summary.image is deprecated. Please use tf.compat.v1.summary.image instead.\n",
      "\n",
      "这是eval_images,eval_lables  Tensor(\"batch:0\", shape=(128, 24, 24, 3), dtype=float32) Tensor(\"Reshape:0\", shape=(128,), dtype=int32)\n",
      "WARNING:tensorflow:From /root/code/cifar_10/cifar10-CNN-master/cifar10_model.py:31: The name tf.truncated_normal is deprecated. Please use tf.random.truncated_normal instead.\n",
      "\n",
      "WARNING:tensorflow:From /root/code/cifar_10/cifar10-CNN-master/cifar10_model.py:34: The name tf.summary.histogram is deprecated. Please use tf.compat.v1.summary.histogram instead.\n",
      "\n",
      "WARNING:tensorflow:From /root/code/cifar_10/cifar10-CNN-master/cifar10_model.py:38: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "构建完网络 Tensor(\"softmax_linear/Relu:0\", shape=(128, 10), dtype=float32)\n",
      "这是预测结果矩阵 Tensor(\"Softmax:0\", shape=(128, 10), dtype=float32)\n",
      "这是top_k_op   Tensor(\"in_top_k/InTopKV2:0\", shape=(128,), dtype=bool)\n",
      "INFO:tensorflow:Restoring parameters from signal_GPU/saver/model.ckpt\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import cifar10_input\n",
    "import cifar10_model\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from datetime import datetime\n",
    "# 验证\n",
    "def evaluation():\n",
    "    with tf.Graph().as_default():\n",
    "#         print(BATCH_SIZE)\n",
    "        n_test = cifar10_input.NUM_EXAMPLES_PER_EPOCH_FOR_EVAL\n",
    "        eval_images, eval_lables = cifar10_input.inputs('/root/code/cifar_10/cifar10-CNN-master/cifar10_data/cifar-10-batches-bin',128)\n",
    "        print('这是eval_images,eval_lables ',eval_images,eval_lables)\n",
    "        eval_logits = cifar10_model.inference(eval_images)\n",
    "        print('构建完网络',eval_logits)\n",
    "        result = tf.nn.softmax(eval_logits)\n",
    "        print(\"这是预测结果矩阵\",result)\n",
    "        # tf.nn.in_top_k(predictions, targets, k, name=None)\n",
    "        # 每个样本的预测结果的前k个最大的数里面是否包括包含targets预测中的标签，一般取1，\n",
    "        # 即取预测最大概率的索引与标签的对比\n",
    "        top_k_op = tf.nn.in_top_k(eval_logits, eval_lables, 1)\n",
    "        print('这是top_k_op  ',top_k_op)\n",
    "        saver = tf.train.Saver()\n",
    "        with tf.Session() as session:\n",
    "            ckpt = tf.train.get_checkpoint_state('signal_GPU/saver')\n",
    "            if ckpt and ckpt.model_checkpoint_path:\n",
    "                saver.restore(session, ckpt.model_checkpoint_path)\n",
    "            \n",
    "            predints1=session.run(eval_logits)\n",
    "            print('这是预测1',predints1)\n",
    "            predints2=session.run(result)\n",
    "            print('这是预测2',predints2)\n",
    "\n",
    "\n",
    "            \n",
    "#             result.append(str(predints[0]))\n",
    "            \n",
    "            coord = tf.train.Coordinator()\n",
    "            threads = tf.train.start_queue_runners(sess=session, coord=coord)\n",
    "            num_iter = int(n_test / BATCH_SIZE)\n",
    "            true_count = 0\n",
    "            for step in range(num_iter):\n",
    "                predictions = session.run(top_k_op)\n",
    "#                 print('这是predictions',predictions)\n",
    "                true_count = true_count + np.sum(predictions)\n",
    "            precision = true_count / (num_iter * BATCH_SIZE)\n",
    "            print('precision=', precision)\n",
    "            coord.request_stop()\n",
    "            coord.join(threads)\n",
    "evaluation()    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict10(sess, adds):\n",
    "    import json\n",
    "    num_imgs = len(adds)\n",
    "    result = []\n",
    "    for i in range(num_imgs):\n",
    "        data = json.loads(adds[i])\n",
    "        predints=sess.run('y_conv:0',feed_dict={\"x:0\":data,\"keep_prob:0\": 1.0})\n",
    "        result.append(str(predints[0]))\n",
    "    \n",
    "    return result"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
