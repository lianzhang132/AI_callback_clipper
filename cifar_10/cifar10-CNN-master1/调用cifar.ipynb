{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "这是eval_images,eval_lables  Tensor(\"batch:0\", shape=(128, 24, 24, 3), dtype=float32) Tensor(\"Reshape:0\", shape=(128,), dtype=int32)\n",
      "构建完网络 Tensor(\"softmax_linear/logits:0\", shape=(128, 10), dtype=float32)\n",
      "这是预测结果矩阵 Tensor(\"Softmax:0\", shape=(128, 10), dtype=float32)\n",
      "这是top_k_op   Tensor(\"in_top_k/InTopKV2:0\", shape=(128,), dtype=bool)\n",
      "INFO:tensorflow:Restoring parameters from signal_GPU/saver/model.ckpt\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import cifar10_input\n",
    "import cifar10_model\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from datetime import datetime\n",
    "# 验证\n",
    "def evaluation():\n",
    "    with tf.Graph().as_default():\n",
    "#         print(BATCH_SIZE)\n",
    "        n_test = cifar10_input.NUM_EXAMPLES_PER_EPOCH_FOR_EVAL\n",
    "        eval_images, eval_lables = cifar10_input.inputs('/root/code/cifar_10/cifar10-CNN-master/cifar10_data/cifar-10-batches-bin',128)\n",
    "        print('这是eval_images,eval_lables ',eval_images,eval_lables)\n",
    "        eval_logits = cifar10_model.inference(eval_images)\n",
    "        print('构建完网络',eval_logits)\n",
    "        result = tf.nn.softmax(eval_logits)\n",
    "        print(\"这是预测结果矩阵\",result)\n",
    "        # tf.nn.in_top_k(predictions, targets, k, name=None)\n",
    "        # 每个样本的预测结果的前k个最大的数里面是否包括包含targets预测中的标签，一般取1，\n",
    "        # 即取预测最大概率的索引与标签的对比\n",
    "        top_k_op = tf.nn.in_top_k(eval_logits, eval_lables, 1)\n",
    "        print('这是top_k_op  ',top_k_op)\n",
    "        saver = tf.train.Saver()\n",
    "        with tf.Session() as session:\n",
    "            ckpt = tf.train.get_checkpoint_state('signal_GPU/saver')\n",
    "            if ckpt and ckpt.model_checkpoint_path:\n",
    "                saver.restore(session, ckpt.model_checkpoint_path)\n",
    "            \n",
    "#             predints1=session.run(eval_logits)\n",
    "#             print('这是预测1',predints1)\n",
    "            predints2=session.run(result)\n",
    "            print('这是预测2',predints2)\n",
    "\n",
    "\n",
    "            \n",
    "#             result.append(str(predints[0]))\n",
    "            \n",
    "            coord = tf.train.Coordinator()\n",
    "            threads = tf.train.start_queue_runners(sess=session, coord=coord)\n",
    "            num_iter = int(n_test / BATCH_SIZE)\n",
    "            true_count = 0\n",
    "            for step in range(num_iter):\n",
    "                predictions = session.run(top_k_op)\n",
    "                print('这是predictions',predictions)\n",
    "                true_count = true_count + np.sum(predictions)\n",
    "            precision = true_count / (num_iter * BATCH_SIZE)\n",
    "            print('precision=', precision)\n",
    "            coord.request_stop()\n",
    "            coord.join(threads)\n",
    "evaluation()    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from signal_GPU/saver/model.ckpt\n",
      "这是eval_images,eval_lables  Tensor(\"batch_6:0\", shape=(128, 24, 24, 3), dtype=float32) Tensor(\"Reshape_14:0\", shape=(128,), dtype=int32)\n",
      "构建完网络 Tensor(\"softmax_linear_5/logits:0\", shape=(128, 10), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image, ImageFilter\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import cifar10_input\n",
    "import cifar10_model\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from datetime import datetime\n",
    "eval_images, eval_lables = cifar10_input.inputs('/root/code/cifar_10/cifar10-CNN-master/cifar10_data/cifar-10-batches-bin',128)\n",
    "\n",
    "with tf.name_scope('conv1'):\n",
    "    conv1_w = tf.Variable(tf.truncated_normal(shape=[5, 5, 3, 64], mean=0, stddev=5e-2), name='weights')\n",
    "    conv1_b = tf.Variable(tf.zeros(64), name='biases')\n",
    "    conv1 = tf.nn.relu(tf.nn.conv2d(eval_images, conv1_w, strides=[1, 1, 1, 1], padding='SAME') + conv1_b)\n",
    "tf.summary.histogram('conv1_w', conv1_w)\n",
    "tf.summary.histogram('conv1_b', conv1_b)\n",
    "\n",
    "# pooling_1\n",
    "pooling_1 = tf.nn.max_pool(conv1, ksize=[1, 3, 3, 1], strides=[1, 2, 2, 1],\n",
    "                           padding='SAME', name='pooling_1')\n",
    "# norm1\n",
    "norm1 = tf.nn.lrn(pooling_1, 4, bias=1.0, alpha=0.001 / 9.0, beta=0.75, name='norm_1')\n",
    "\n",
    "# conv2\n",
    "with tf.name_scope('conv2'):\n",
    "    conv2_w = tf.Variable(tf.truncated_normal(shape=[5, 5, 64, 64], mean=0, stddev=5e-2), name='weights')\n",
    "    conv2_b = tf.Variable(tf.zeros(64), name='biases')\n",
    "    conv2 = tf.nn.relu(tf.nn.conv2d(norm1, conv2_w, strides=[1, 1, 1, 1], padding='SAME') + conv2_b)\n",
    "tf.summary.histogram('conv2_w', conv2_w)\n",
    "tf.summary.histogram('conv2_b', conv2_b)\n",
    "\n",
    "# pooling_2\n",
    "pooling_2 = tf.nn.max_pool(conv2, ksize=[1, 3, 3, 1], strides=[1, 2, 2, 1],\n",
    "                           padding='SAME', name='pooling_2')\n",
    "# norm 2\n",
    "norm2 = tf.nn.lrn(pooling_2, 4, bias=1.0, alpha=0.001 / 9.0, beta=0.75, name='norm_2')\n",
    "\n",
    "#\n",
    "reshaped_output = tf.reshape(norm2, shape=[128, -1])\n",
    "dim = reshaped_output.shape[1].value\n",
    "\n",
    "# local 3\n",
    "with tf.name_scope('local3'):\n",
    "    local3_w = tf.Variable(tf.truncated_normal(shape=[dim, 384], mean=0, stddev=0.04), name='weights')\n",
    "    local3_b = tf.Variable(tf.zeros(384), name='biases')\n",
    "    local3 = tf.nn.relu(tf.matmul(reshaped_output, local3_w) + local3_b)\n",
    "tf.summary.histogram('local3_w', local3_w)\n",
    "tf.summary.histogram('local3_b', local3_b)\n",
    "\n",
    "# local 4\n",
    "with tf.name_scope('local4'):\n",
    "    local4_w = tf.Variable(tf.truncated_normal(shape=[384, 192], mean=0, stddev=0.04), name='weights')\n",
    "    local4_b = tf.Variable(tf.zeros(192), name='biases')\n",
    "    local4 = tf.nn.relu(tf.matmul(local3, local4_w) + local4_b)\n",
    "tf.summary.histogram('local4_w', local4_w)\n",
    "tf.summary.histogram('local4_b', local4_b)\n",
    "\n",
    "# softmax_linear\n",
    "with tf.name_scope('softmax_linear'):\n",
    "    output_w = tf.Variable(tf.truncated_normal(shape=[192, 10], mean=0, stddev=1 / 192.0))\n",
    "    output_b = tf.Variable(tf.zeros(10))\n",
    "#         logits = tf.nn.relu(tf.matmul(local4, output_w) + output_b,name='logits')\n",
    "    logits = tf.nn.softmax(tf.matmul(local4, output_w) + output_b,name='logits')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "with tf.Session() as sess:\n",
    "#     saver = tf.train.import_meta_graph('signal_GPU/saver/model.ckpt.meta')\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    saver.restore(sess,'signal_GPU/saver/model.ckpt')\n",
    "\n",
    "#     sess.run(tf.global_variables_initializer())\n",
    "#     saver.restore(sess, 'signal_GPU/saver/model.ckpt') #使用模型，参数和之前的代码保持一致\n",
    "\n",
    "    \n",
    "    n_test = cifar10_input.NUM_EXAMPLES_PER_EPOCH_FOR_EVAL\n",
    "    eval_images, eval_lables = cifar10_input.inputs('/root/code/cifar_10/cifar10-CNN-master/cifar10_data/cifar-10-batches-bin',128)\n",
    "    print('这是eval_images,eval_lables ',eval_images,eval_lables)\n",
    "    eval_logits = cifar10_model.inference(eval_images)\n",
    "    print('构建完网络',eval_logits)\n",
    "    predints=sess.run(logits)\n",
    "    print(predints)\n",
    "\n",
    "\n",
    "def predict10(sess, adds):\n",
    "    import json\n",
    "    num_imgs = len(adds)\n",
    "    result = []\n",
    "    for i in range(num_imgs):\n",
    "        data = json.loads(adds[i])\n",
    "        predints=sess.run('y_conv:0',feed_dict={\"x:0\":data,\"keep_prob:0\": 1.0})\n",
    "        result.append(str(predints[0]))\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
