{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "\n",
      "W_conv1,b_conv1是 <tf.Variable 'Variable:0' shape=(5, 5, 1, 32) dtype=float32_ref> <tf.Variable 'Variable_1:0' shape=(32,) dtype=float32_ref>\n",
      "\n",
      "x_image是 Tensor(\"Reshape:0\", shape=(?, 28, 28, 1), dtype=float32)\n",
      "\n",
      "h_conv1,h_pool1是 Tensor(\"Relu:0\", shape=(?, 28, 28, 32), dtype=float32) Tensor(\"MaxPool:0\", shape=(?, 14, 14, 32), dtype=float32)\n",
      "\n",
      " W_conv2,b_conv2是 <tf.Variable 'Variable_2:0' shape=(5, 5, 32, 64) dtype=float32_ref> <tf.Variable 'Variable_3:0' shape=(64,) dtype=float32_ref>\n",
      "\n",
      "h_conv2,h_pool2是 Tensor(\"Relu_1:0\", shape=(?, 14, 14, 64), dtype=float32) Tensor(\"MaxPool_1:0\", shape=(?, 7, 7, 64), dtype=float32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/tensorflow_core/python/client/session.py:1750: UserWarning: An interactive session is already active. This can cause out-of-memory errors in some cases. You must explicitly call `InteractiveSession.close()` to release resources held by the other session(s).\n",
      "  warnings.warn('An interactive session is already active. This can '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "W_fc1,b_fc1是 <tf.Variable 'Variable_4:0' shape=(3136, 1024) dtype=float32_ref> <tf.Variable 'Variable_5:0' shape=(1024,) dtype=float32_ref>\n",
      "step 0, training accuracy 0.16\n",
      "step 100, training accuracy 0.96\n",
      "step 200, training accuracy 0.88\n",
      "test accuracy 0.9243\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt \n",
    "#张量概念是矢量概念的推广，矢量是一阶张量。张量是一个可用来表示在一些矢量、\n",
    "#标量和其他张量之间的线性关系的多线性函数(可以理解成是向量、矩阵以及更高维结构的统称)。\n",
    "def show_single_image(img_arr):\n",
    "    plt.imshow(img_arr,cmap=\"binary\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# from tensorflow.examples.tutorials.mnist import input_data 老版本写法\n",
    "# mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)\n",
    "from tensorflow.contrib.learn.python.learn.datasets.mnist import read_data_sets\n",
    "mnist = read_data_sets(\"MNIST_data/\", one_hot=True)\n",
    "\n",
    "tf.reset_default_graph()\n",
    "# print(mnist)\n",
    "# show_single_image(mnist.test.images[1])\n",
    "\n",
    "sess = tf.InteractiveSession()\n",
    "\n",
    "x = tf.placeholder(\"float\", shape=[None, 784])\n",
    "y_ = tf.placeholder(\"float\", shape=[None, 10])\n",
    "\n",
    "\n",
    "def weight_variable(shape):\n",
    "#从截断的正态分布中输出随机值，生成的值服从具有指定平均值和标准偏差的正态分布，\n",
    "#如果生成的值大于平均值2个标准偏差的值则丢弃重新选择\n",
    "    initial = tf.truncated_normal(shape, stddev=0.1)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "def bias_variable(shape):\n",
    "#一个类，初始化器，它生成具有常量值的张量。由新张量的期望shape后面的参数value指定。参数value可以是常量值，\n",
    "#也可以是类型为dtype的值列表。如果value是一个列表，那么列表的长度必须小于或等于由张量的期望形状所暗示的元素的数量。\n",
    "#如果值中的元素总数小于张量形状所需的元素数，则值中的最后一个元素将用于填充剩余的元素。如果值中元素的总数大于张量形状所需元素的总数，\n",
    "#初始化器将产生一个ValueError。\n",
    "\n",
    "    initial = tf.constant(0.1, shape=shape)\n",
    "    return tf.Variable(initial)\n",
    "#计算给定4-D输入和滤波器张量的2-D卷积.\n",
    "\n",
    "\"\"\"\n",
    "将滤镜展平为具有形状[filter_height * filter_width * in_channels, output_channels]的二维矩阵.\n",
    "从输入张量中提取图像补丁,以形成形状为[batch, out_height, out_width, filter_height * filter_width * in_channels]的虚拟张量.\n",
    "对于每个补丁,右对乘滤波器矩阵和图像补丁矢量.\n",
    "\"\"\"\n",
    "def conv2d(x, W):\n",
    "    return tf.nn.conv2d(x, W, strides=[1,1,1,1], padding=\"SAME\")\n",
    "\n",
    "\"\"\"\n",
    "max pooling是CNN当中的最大值池化操作，其实用法和卷积很类似\n",
    "返回一个Tensor，类型不变，shape仍然是[batch, height, width, channels]这种形式\n",
    "\"\"\"\n",
    "def max_pool_2x2(x):\n",
    "    return tf.nn.max_pool(x, ksize=[1,2,2,1],\n",
    "                          strides=[1,2,2,1], padding=\"SAME\")\n",
    "\n",
    "\n",
    "W_conv1 = weight_variable([5,5,1,32])\n",
    "b_conv1 = bias_variable([32])\n",
    "print()\n",
    "print(\"W_conv1,b_conv1是\",W_conv1,b_conv1)\n",
    "\n",
    "x_image = tf.reshape(x, [-1,28,28,1])\n",
    "print()\n",
    "print(\"x_image是\",x_image)\n",
    "\n",
    "h_conv1 = tf.nn.relu(conv2d(x_image, W_conv1) + b_conv1)\n",
    "h_pool1 = max_pool_2x2(h_conv1)\n",
    "print()\n",
    "print(\"h_conv1,h_pool1是\",h_conv1,h_pool1)\n",
    "\n",
    "W_conv2 = weight_variable([5,5,32,64])\n",
    "b_conv2 = weight_variable([64])\n",
    "print()\n",
    "print(\" W_conv2,b_conv2是\", W_conv2,b_conv2)\n",
    "\n",
    "h_conv2 = tf.nn.relu(conv2d(h_pool1, W_conv2) + b_conv2)\n",
    "h_pool2 = max_pool_2x2(h_conv2)\n",
    "print()\n",
    "print(\"h_conv2,h_pool2是\",h_conv2,h_pool2)\n",
    "\n",
    "W_fc1 = weight_variable([7*7*64, 1024])\n",
    "b_fc1 = bias_variable([1024])\n",
    "print()\n",
    "print(\"W_fc1,b_fc1是\",W_fc1,b_fc1)\n",
    "\n",
    "h_pool2_flat = tf.reshape(h_pool2, [-1, 7*7*64])\n",
    "#tf.nn.relu(features, name = None)：这个函数的作用是计算激活函数 relu，即 max(features, 0)。\n",
    "#将大于0的保持不变，小于0的数置为0。\n",
    "#tf.matmul：将矩阵a乘以矩阵b，生成a * b\n",
    "h_fc1 = tf.nn.relu(tf.matmul(h_pool2_flat, W_fc1) + b_fc1)\n",
    "\n",
    "\n",
    "\n",
    "keep_prob = tf.placeholder(\"float\")\n",
    "#Dropout就是在不同的训练过程中随机扔掉一部分神经元 也就是让某个神经元的激活值以一定的概率p，\n",
    "#让其停止工作，为了防止或减轻过拟合而使用的函数 keep_prob：概率\n",
    "h_fc1_drop = tf.nn.dropout(h_fc1, keep_prob) #它一般用在全连接层\n",
    "\n",
    "W_fc2 = weight_variable([1024, 10])\n",
    "b_fc2 = bias_variable([10])\n",
    "\n",
    "#softmax函数将压缩每个类在0到1之间，并除以输出总和。它实际上可以表示某个类的输入概率。\n",
    "y_conv = tf.nn.softmax(tf.matmul(h_fc1_drop, W_fc2) + b_fc2)\n",
    "\n",
    "\n",
    "#self.prediction = tf.nn.softmax(wx_plus_b2)\n",
    "\n",
    "\n",
    "#tf.reduce_sum用于计算张量tensor沿着某一维度的和，可以在求和后降维。\n",
    "cross_entropy = -tf.reduce_sum(y_ * tf.log(y_conv))\n",
    "\n",
    "#tf.train.AdamOptimizer：此函数是Adam优化算法：是一个寻找全局最优点的优化算法，引入了二次方梯度校正。\n",
    "train_step = tf.train.AdamOptimizer(1e-4).minimize(cross_entropy)\n",
    "\n",
    "#tf.equal：逐个元素进行判断，如果相等就是True，不相等，就是False\n",
    "correct_predict = tf.equal(tf.argmax(y_conv, 1), tf.argmax(y_, 1))\n",
    "#tf.cast：tensorflow 中张量数据类型转换，比如读入的图片如果是int8类型的，\n",
    "#一般在要在训练前把图像的数据格式转换为float32。\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_predict, \"float\"))\n",
    "\n",
    "#tf.summary.scalar ：用来显示标量信息，一般在画loss,accuary时会用到这个函数\n",
    "tf.summary.scalar('cross_entropy', cross_entropy)#\n",
    "tf.summary.scalar('accuracy', accuracy)\n",
    "\n",
    "sess.run(tf.initialize_all_variables())\n",
    "#tfboard injection\n",
    "#merge_all 可以将所有summary全部保存到磁盘，以便tensorboard显示。\n",
    "#如果没有特殊要求，一般用这一句就可一显示训练时的各种信息了。\n",
    "merged = tf.summary.merge_all()\n",
    "\n",
    "\"\"\"\n",
    "tf.summary.FileWriter:\n",
    "指定一个文件用来保存图。\n",
    "log是事件文件所在的目录，这里是工程目录下的log目录。第二个参数是事件文件要记录的图，也就是TensorFlow默认的图。\n",
    "可以调用其add_summary()方法将训练过程数据保存在filewriter指定的文件中。\n",
    "\"\"\"\n",
    "writer = tf.summary.FileWriter(\"tblogs\", sess.graph)\n",
    "\n",
    "saver = tf.train.Saver(max_to_keep=1)  # 只保留最近一次的模型\n",
    "\n",
    "\n",
    "for i in range(201):\n",
    "    batch = mnist.train.next_batch(50)\n",
    "    if i%100 == 0:\n",
    "        train_accuracy = accuracy.eval(feed_dict={\n",
    "            x:batch[0], y_:batch[1], keep_prob:1.0})\n",
    "        print (\"step %d, training accuracy %g\" % (i, train_accuracy))\n",
    "        summary,_ = sess.run([merged,train_step],feed_dict={x:batch[0], y_:batch[1], keep_prob:0.5})\n",
    "        writer.add_summary(summary,i)\n",
    "        \n",
    "    else:\n",
    "        train_step.run(feed_dict={x:batch[0], y_:batch[1], keep_prob:0.5})\n",
    "    saver.save(sess, '/tmp/tf/mnist.ckpt')\n",
    "writer.flush()\n",
    "print (\"test accuracy %g\" % accuracy.eval(feed_dict={x:mnist.test.images, y_:mnist.test.labels, keep_prob:1.0}))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# train_step = tf.train.AdamOptimizer(1e-4).minimize(cross_entropy)\n",
    "本训练是对AdamOptimizer优化器 运行coss为cross_entropy的优化过程"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /tmp/tf/mnist.ckpt\n"
     ]
    }
   ],
   "source": [
    "saver = tf.train.Saver()\n",
    "sess = tf.Session() \n",
    "saver.restore(sess, \"/tmp/tf/mnist.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image, ImageFilter\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def imageprepare(): \n",
    "    im = Image.open('/root/code/3.jpg') #读取的图片所在路径，注意是28*28像素\n",
    "    plt.imshow(im)  #显示需要识别的图片\n",
    "    plt.show()\n",
    "    im = im.convert('L')\n",
    "    tv = list(im.getdata()) \n",
    "    tva = [(255-x)*1.0/255.0 for x in tv] \n",
    "    return tva"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[0.996078431372549,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.9921568627450981,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.996078431372549,\n",
       " 0.996078431372549,\n",
       " 1.0,\n",
       " 0.996078431372549,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.996078431372549,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.9882352941176471,\n",
       " 1.0,\n",
       " 0.996078431372549,\n",
       " 1.0,\n",
       " 0.996078431372549,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.9921568627450981,\n",
       " 1.0,\n",
       " 0.996078431372549,\n",
       " 0.9921568627450981,\n",
       " 0.996078431372549,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.996078431372549,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.996078431372549,\n",
       " 0.996078431372549,\n",
       " 0.996078431372549,\n",
       " 1.0,\n",
       " 0.9921568627450981,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.996078431372549,\n",
       " 1.0,\n",
       " 0.9921568627450981,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.9921568627450981,\n",
       " 1.0,\n",
       " 0.9882352941176471,\n",
       " 0.996078431372549,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.996078431372549,\n",
       " 0.9921568627450981,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.996078431372549,\n",
       " 1.0,\n",
       " 0.996078431372549,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.996078431372549,\n",
       " 0.9882352941176471,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.984313725490196,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.996078431372549,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.9921568627450981,\n",
       " 0.9882352941176471,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.9882352941176471,\n",
       " 1.0,\n",
       " 0.9882352941176471,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.996078431372549,\n",
       " 1.0,\n",
       " 0.996078431372549,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.984313725490196,\n",
       " 1.0,\n",
       " 0.996078431372549,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.9882352941176471,\n",
       " 1.0,\n",
       " 0.996078431372549,\n",
       " 0.9882352941176471,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.9921568627450981,\n",
       " 1.0,\n",
       " 0.9921568627450981,\n",
       " 0.9568627450980393,\n",
       " 0.9568627450980393,\n",
       " 0.45098039215686275,\n",
       " 0.00784313725490196,\n",
       " 0.0784313725490196,\n",
       " 0.5529411764705883,\n",
       " 0.9803921568627451,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.9882352941176471,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.9882352941176471,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.996078431372549,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.9921568627450981,\n",
       " 1.0,\n",
       " 0.996078431372549,\n",
       " 1.0,\n",
       " 0.7647058823529411,\n",
       " 0.43137254901960786,\n",
       " 0.043137254901960784,\n",
       " 0.01568627450980392,\n",
       " 0.00392156862745098,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.011764705882352941,\n",
       " 0.43529411764705883,\n",
       " 0.9725490196078431,\n",
       " 0.9921568627450981,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.9921568627450981,\n",
       " 0.9882352941176471,\n",
       " 1.0,\n",
       " 0.996078431372549,\n",
       " 1.0,\n",
       " 0.9647058823529412,\n",
       " 0.8588235294117647,\n",
       " 0.48627450980392156,\n",
       " 0.08627450980392157,\n",
       " 0.0,\n",
       " 0.0196078431372549,\n",
       " 0.011764705882352941,\n",
       " 0.6,\n",
       " 0.6470588235294118,\n",
       " 0.23921568627450981,\n",
       " 0.01568627450980392,\n",
       " 0.0,\n",
       " 0.7607843137254902,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.9921568627450981,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.996078431372549,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.9921568627450981,\n",
       " 1.0,\n",
       " 0.8705882352941177,\n",
       " 0.43529411764705883,\n",
       " 0.011764705882352941,\n",
       " 0.00392156862745098,\n",
       " 0.06666666666666667,\n",
       " 0.19607843137254902,\n",
       " 0.6274509803921569,\n",
       " 0.6627450980392157,\n",
       " 1.0,\n",
       " 0.9686274509803922,\n",
       " 0.3137254901960784,\n",
       " 0.0,\n",
       " 0.01568627450980392,\n",
       " 0.7607843137254902,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.9921568627450981,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.9921568627450981,\n",
       " 1.0,\n",
       " 0.3843137254901961,\n",
       " 0.00392156862745098,\n",
       " 0.00784313725490196,\n",
       " 0.19607843137254902,\n",
       " 0.7294117647058823,\n",
       " 0.9921568627450981,\n",
       " 0.996078431372549,\n",
       " 0.9921568627450981,\n",
       " 0.9882352941176471,\n",
       " 0.4666666666666667,\n",
       " 0.011764705882352941,\n",
       " 0.011764705882352941,\n",
       " 0.17254901960784313,\n",
       " 0.9333333333333333,\n",
       " 0.9882352941176471,\n",
       " 0.9921568627450981,\n",
       " 1.0,\n",
       " 0.996078431372549,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.996078431372549,\n",
       " 0.9921568627450981,\n",
       " 0.9921568627450981,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.984313725490196,\n",
       " 0.5607843137254902,\n",
       " 0.3058823529411765,\n",
       " 0.6313725490196078,\n",
       " 0.9294117647058824,\n",
       " 0.996078431372549,\n",
       " 0.996078431372549,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.807843137254902,\n",
       " 0.011764705882352941,\n",
       " 0.0,\n",
       " 0.00392156862745098,\n",
       " 0.6039215686274509,\n",
       " 0.996078431372549,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.9882352941176471,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.996078431372549,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.996078431372549,\n",
       " 0.9882352941176471,\n",
       " 1.0,\n",
       " 0.9882352941176471,\n",
       " 0.996078431372549,\n",
       " 1.0,\n",
       " 0.9921568627450981,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.996078431372549,\n",
       " 1.0,\n",
       " 0.3176470588235294,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.3333333333333333,\n",
       " 0.9529411764705882,\n",
       " 0.9882352941176471,\n",
       " 0.996078431372549,\n",
       " 0.996078431372549,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.996078431372549,\n",
       " 0.996078431372549,\n",
       " 1.0,\n",
       " 0.996078431372549,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.996078431372549,\n",
       " 0.9921568627450981,\n",
       " 1.0,\n",
       " 0.9921568627450981,\n",
       " 1.0,\n",
       " 0.5882352941176471,\n",
       " 0.00784313725490196,\n",
       " 0.011764705882352941,\n",
       " 0.07058823529411765,\n",
       " 0.788235294117647,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.9921568627450981,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.9921568627450981,\n",
       " 0.996078431372549,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.996078431372549,\n",
       " 1.0,\n",
       " 0.9921568627450981,\n",
       " 1.0,\n",
       " 0.9882352941176471,\n",
       " 0.9882352941176471,\n",
       " 1.0,\n",
       " 0.996078431372549,\n",
       " 0.3215686274509804,\n",
       " 0.0,\n",
       " 0.047058823529411764,\n",
       " 0.7294117647058823,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.9921568627450981,\n",
       " 0.9921568627450981,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.996078431372549,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.996078431372549,\n",
       " 0.996078431372549,\n",
       " 0.996078431372549,\n",
       " 0.9921568627450981,\n",
       " 0.996078431372549,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.996078431372549,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.996078431372549,\n",
       " 0.36470588235294116,\n",
       " 0.01568627450980392,\n",
       " 0.0,\n",
       " 0.01568627450980392,\n",
       " 0.4235294117647059,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.9921568627450981,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.996078431372549,\n",
       " 0.996078431372549,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.996078431372549,\n",
       " 0.9921568627450981,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.996078431372549,\n",
       " 0.9921568627450981,\n",
       " 1.0,\n",
       " 0.9882352941176471,\n",
       " 1.0,\n",
       " 0.9882352941176471,\n",
       " 0.9882352941176471,\n",
       " 0.3803921568627451,\n",
       " 0.0,\n",
       " 0.047058823529411764,\n",
       " 0.050980392156862744,\n",
       " 0.01568627450980392,\n",
       " 0.17647058823529413,\n",
       " 0.9568627450980393,\n",
       " 1.0,\n",
       " 0.996078431372549,\n",
       " 1.0,\n",
       " 0.9921568627450981,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.9921568627450981,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.996078431372549,\n",
       " 1.0,\n",
       " 0.996078431372549,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.9921568627450981,\n",
       " 0.596078431372549,\n",
       " 1.0,\n",
       " 0.996078431372549,\n",
       " 0.7411764705882353,\n",
       " 0.22745098039215686,\n",
       " 0.11372549019607843,\n",
       " 0.8196078431372549,\n",
       " 1.0,\n",
       " 0.9921568627450981,\n",
       " 1.0,\n",
       " 0.996078431372549,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.996078431372549,\n",
       " 0.996078431372549,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.996078431372549,\n",
       " 0.996078431372549,\n",
       " 1.0,\n",
       " 0.9921568627450981,\n",
       " 1.0,\n",
       " 0.9921568627450981,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.9921568627450981,\n",
       " 1.0,\n",
       " 0.803921568627451,\n",
       " 0.00784313725490196,\n",
       " 0.11764705882352941,\n",
       " 0.8784313725490196,\n",
       " 1.0,\n",
       " 0.996078431372549,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.996078431372549,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.9803921568627451,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.9882352941176471,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.9882352941176471,\n",
       " 0.9372549019607843,\n",
       " 0.2,\n",
       " 0.00784313725490196,\n",
       " 0.5019607843137255,\n",
       " 1.0,\n",
       " 0.984313725490196,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.996078431372549,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.9882352941176471,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.996078431372549,\n",
       " 0.9882352941176471,\n",
       " 1.0,\n",
       " 0.9921568627450981,\n",
       " 1.0,\n",
       " 0.9921568627450981,\n",
       " 1.0,\n",
       " 0.8549019607843137,\n",
       " 0.08235294117647059,\n",
       " 0.011764705882352941,\n",
       " 0.33725490196078434,\n",
       " 0.9921568627450981,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.9921568627450981,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.996078431372549,\n",
       " 1.0,\n",
       " 0.996078431372549,\n",
       " 0.9568627450980393,\n",
       " 0.7058823529411765,\n",
       " 0.9254901960784314,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.996078431372549,\n",
       " 1.0,\n",
       " 0.9372549019607843,\n",
       " 0.3686274509803922,\n",
       " 0.00784313725490196,\n",
       " 0.00784313725490196,\n",
       " 0.3254901960784314,\n",
       " 1.0,\n",
       " 0.984313725490196,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.9921568627450981,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.996078431372549,\n",
       " 1.0,\n",
       " 0.996078431372549,\n",
       " 0.9568627450980393,\n",
       " 0.24313725490196078,\n",
       " 0.1607843137254902,\n",
       " 0.6823529411764706,\n",
       " 0.9882352941176471,\n",
       " 1.0,\n",
       " 0.996078431372549,\n",
       " 1.0,\n",
       " 0.9686274509803922,\n",
       " 0.5686274509803921,\n",
       " 0.01568627450980392,\n",
       " 0.0,\n",
       " 0.01568627450980392,\n",
       " 0.19607843137254902,\n",
       " 0.9254901960784314,\n",
       " 1.0,\n",
       " 0.9921568627450981,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.996078431372549,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.9882352941176471,\n",
       " 0.4627450980392157,\n",
       " 0.00392156862745098,\n",
       " 0.050980392156862744,\n",
       " 0.5647058823529412,\n",
       " 0.611764705882353,\n",
       " 0.611764705882353,\n",
       " 0.3803921568627451,\n",
       " 0.12549019607843137,\n",
       " 0.00784313725490196,\n",
       " 0.00784313725490196,\n",
       " 0.011764705882352941,\n",
       " 0.12549019607843137,\n",
       " 0.8117647058823529,\n",
       " 0.996078431372549,\n",
       " 0.9921568627450981,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.996078431372549,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.984313725490196,\n",
       " 0.42745098039215684,\n",
       " 0.00392156862745098,\n",
       " 0.00392156862745098,\n",
       " 0.0196078431372549,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.01568627450980392,\n",
       " 0.00392156862745098,\n",
       " 0.00392156862745098,\n",
       " 0.3176470588235294,\n",
       " 0.8117647058823529,\n",
       " 0.996078431372549,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.996078431372549,\n",
       " 0.996078431372549,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.996078431372549,\n",
       " 0.996078431372549,\n",
       " 1.0,\n",
       " 0.9764705882352941,\n",
       " 0.8,\n",
       " 0.08627450980392157,\n",
       " 0.0,\n",
       " 0.01568627450980392,\n",
       " 0.25882352941176473,\n",
       " 0.20392156862745098,\n",
       " 0.30980392156862746,\n",
       " 0.796078431372549,\n",
       " 0.9803921568627451,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.996078431372549,\n",
       " 1.0,\n",
       " 0.9921568627450981,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imageprepare()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.client.session.Session at 0x7f27c7d8bc88>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unhashable type: 'numpy.ndarray'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-da62c8427d50>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mxs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"/root/code/3.jpg\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mpredict_mnist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-13-da62c8427d50>\u001b[0m in \u001b[0;36mpredict_mnist\u001b[0;34m(xs)\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'L'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m784\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_conv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mkeep_prob\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m         \u001b[0mpredicts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappenda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: unhashable type: 'numpy.ndarray'"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "def predict_mnist(xs):\n",
    "    predicts = []\n",
    "    for image_path in xs :\n",
    "        img = Image.open(image_path).convert('L')\n",
    "        x = np.reshape(img, [1, 784])\n",
    "        y = sess.run(y_conv, feed_dict={x: x,keep_prob: 1.0})\n",
    "        predicts.appenda(str(y))\n",
    "        print(image_path)\n",
    "        print(' Predict digit', np.argmax(y[0]))  # 提取出可能性最大的值\n",
    "    return predicts\n",
    " \n",
    "xs = [\"/root/code/3.jpg\"]\n",
    "predict_mnist(xs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unhashable type: 'numpy.ndarray'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-1888ad9aeb07>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m# xs = [\"/root/code/3.jpg\"]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/root/code/3.jpg'\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# 单张图片路径\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-24-1888ad9aeb07>\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(image_path)\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'L'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m784\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_conv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: unhashable type: 'numpy.ndarray'"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "def predict( image_path):\n",
    "        # 读取图片并灰度化\n",
    "        img = Image.open(image_path).convert('L')\n",
    "        x = np.reshape(img, [1, 784])\n",
    "        y = sess.run(y_conv, feed_dict={x})\n",
    "\n",
    "        print(image_path)\n",
    "        print(' Predict digit', np.argmax(y[0]))  # 提取出可能性最大的值\n",
    " \n",
    "# xs = [\"/root/code/3.jpg\"]\n",
    "predict('/root/code/3.jpg')  # 单张图片路径"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
